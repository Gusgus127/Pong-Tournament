{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Paradigms of Machine Learning\n\n## Project, Part 3:  Solving a “complex” ALE environment","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y ale-py gymnasium\n!pip install gymnasium==1.0.0\n!pip install ale-py==0.10.1\n!pip install stable-baselines3==2.4.0\n!pip install supersuit==3.9.3\n!pip install pettingzoo==1.24.3\n!pip install AutoROM==0.6.1\n!pip install multi-agent-ale-py==0.1.11\n!pip install wandb==0.19.0\n\n# Accept ROM license\n!AutoROM --accept-license","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T17:34:47.846840Z","iopub.execute_input":"2025-12-14T17:34:47.847114Z","iopub.status.idle":"2025-12-14T17:38:37.059068Z","shell.execute_reply.started":"2025-12-14T17:34:47.847084Z","shell.execute_reply":"2025-12-14T17:38:37.058295Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: ale-py 0.11.2\nUninstalling ale-py-0.11.2:\n  Successfully uninstalled ale-py-0.11.2\nFound existing installation: gymnasium 0.29.0\nUninstalling gymnasium-0.29.0:\n  Successfully uninstalled gymnasium-0.29.0\nCollecting gymnasium==1.0.0\n  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium==1.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: gymnasium\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires ale-py>=0.10.1, which is not installed.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gymnasium-1.0.0\nCollecting ale-py==0.10.1\n  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py==0.10.1) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20->ale-py==0.10.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nDownloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py\nSuccessfully installed ale-py-0.10.1\nCollecting stable-baselines3==2.4.0\n  Downloading stable_baselines3-2.4.0-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (1.0.0)\nRequirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (2.6.0+cu124)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (3.1.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (3.7.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3==2.4.0) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3==2.4.0) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.20.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3==2.4.0) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.4.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.4.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.4.0) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.4.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nDownloading stable_baselines3-2.4.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: stable-baselines3\n    Found existing installation: stable-baselines3 2.1.0\n    Uninstalling stable-baselines3-2.1.0:\n      Successfully uninstalled stable-baselines3-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.4.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.4.0\nCollecting supersuit==3.9.3\n  Downloading SuperSuit-3.9.3-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from supersuit==3.9.3) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from supersuit==3.9.3) (1.0.0)\nCollecting tinyscaler>=1.2.6 (from supersuit==3.9.3)\n  Downloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->supersuit==3.9.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nDownloading SuperSuit-3.9.3-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (563 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tinyscaler, supersuit\nSuccessfully installed supersuit-3.9.3 tinyscaler-1.2.8\nCollecting pettingzoo==1.24.3\n  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3) (1.0.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->pettingzoo==1.24.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pettingzoo\n  Attempting uninstall: pettingzoo\n    Found existing installation: pettingzoo 1.24.0\n    Uninstalling pettingzoo-1.24.0:\n      Successfully uninstalled pettingzoo-1.24.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires pettingzoo==1.24.0, but you have pettingzoo 1.24.3 which is incompatible.\nkaggle-environments 1.18.0 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pettingzoo-1.24.3\nCollecting AutoROM==0.6.1\n  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from AutoROM==0.6.1) (8.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from AutoROM==0.6.1) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (2025.10.5)\nDownloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\nInstalling collected packages: AutoROM\nSuccessfully installed AutoROM-0.6.1\nCollecting multi-agent-ale-py==0.1.11\n  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from multi-agent-ale-py==0.1.11) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->multi-agent-ale-py==0.1.11) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nBuilding wheels for collected packages: multi-agent-ale-py\n  Building wheel for multi-agent-ale-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for multi-agent-ale-py: filename=multi_agent_ale_py-0.1.11-cp311-cp311-linux_x86_64.whl size=721821 sha256=2ada9d8de75bb5b9f99b9d08ac09df1c6f15d7323e3fa6e87359b8e4f55edcc8\n  Stored in directory: /root/.cache/pip/wheels/1d/81/76/771ec8e34292c8a71dd6c4a52a1c0401f4d93cbfb54e02fce4\nSuccessfully built multi-agent-ale-py\nInstalling collected packages: multi-agent-ale-py\nSuccessfully installed multi-agent-ale-py-0.1.11\nCollecting wandb==0.19.0\n  Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (8.3.0)\nCollecting docker-pycreds>=0.4.0 (from wandb==0.19.0)\n  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (3.1.45)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (4.5.0)\nCollecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb==0.19.0)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (7.1.3)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.12.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (6.0.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.33.2)\nCollecting setproctitle (from wandb==0.19.0)\n  Downloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (4.15.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb==0.19.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.19.0) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (2025.10.5)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.19.0) (5.0.2)\nDownloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\nInstalling collected packages: setproctitle, protobuf, docker-pycreds, wandb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.21.0\n    Uninstalling wandb-0.21.0:\n      Successfully uninstalled wandb-0.21.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed docker-pycreds-0.4.0 protobuf-5.29.5 setproctitle-1.3.7 wandb-0.19.0\nAutoROM will download the Atari 2600 ROMs.\nThey will be installed to:\n\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n\t/usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms\n\nExisting ROMs will be overwritten.\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/adventure.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/adventure.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/air_raid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/air_raid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/alien.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/alien.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/amidar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/amidar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/assault.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/assault.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asterix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asterix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asteroids.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asteroids.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/backgammon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/backgammon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bank_heist.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/basic_math.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/basic_math.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/battle_zone.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/beam_rider.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/berzerk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/berzerk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/blackjack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/blackjack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bowling.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bowling.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/boxing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/boxing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/breakout.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/breakout.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/carnival.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/carnival.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/casino.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/casino.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/centipede.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/centipede.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/chopper_command.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/combat.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/combat.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crazy_climber.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crossbow.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crossbow.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/darkchambers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/defender.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/defender.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/demon_attack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/donkey_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/double_dunk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/earthworld.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/earthworld.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/elevator_action.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/enduro.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/enduro.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/entombed.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/entombed.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/et.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/et.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/fishing_derby.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/flag_capture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/freeway.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/freeway.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frogger.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frogger.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frostbite.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frostbite.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/galaxian.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/galaxian.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gopher.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gopher.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gravitar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gravitar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hangman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hangman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/haunted_house.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hero.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hero.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/human_cannonball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ice_hockey.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/jamesbond.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/journey_escape.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/joust.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/joust.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kaboom.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kaboom.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kangaroo.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/keystone_kapers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/king_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/king_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/klax.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/klax.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/koolaid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/koolaid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/krull.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/krull.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kung_fu_master.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/laser_gates.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/lost_luggage.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mario_bros.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/maze_craze.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/miniature_golf.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/montezuma_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mr_do.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mr_do.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ms_pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/name_this_game.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/othello.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/othello.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/phoenix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/phoenix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pooyan.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pooyan.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/private_eye.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/private_eye.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/qbert.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/qbert.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/riverraid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/riverraid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/road_runner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/road_runner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/robotank.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/robotank.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/seaquest.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/seaquest.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/sir_lancelot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/skiing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/skiing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/solaris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/solaris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_invaders.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_war.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_war.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/star_gunner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/superman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/superman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/surround.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/surround.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tennis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tennis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tetris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tetris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/time_pilot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/trondead.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/trondead.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/turmoil.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/turmoil.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tutankham.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tutankham.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/up_n_down.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/venture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/venture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_checkers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_chess.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_chess.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_cube.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_cube.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_pinball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/warlords.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/warlords.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/wizard_of_wor.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/word_zapper.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/yars_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/zaxxon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\nDone!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport gymnasium as gym\nimport ale_py\nimport supersuit as ss\nfrom stable_baselines3 import PPO, DQN, A2C\nfrom stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage, VecMonitor\nfrom stable_baselines3.common.env_util import make_atari_env\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Create directory for results\nos.makedirs(\"./results\", exist_ok=True)\nos.makedirs(\"./logs\", exist_ok=True)\nos.makedirs(\"./models\", exist_ok=True)\n\n# 1. Configuration\nENV_NAME = \"MsPacmanNoFrameskip-v4\"\nN_ENVS = 8\nN_STACK = 4\nTOTAL_TIMESTEPS = 1000000\n\n# Create the vectorized environment with monitoring\nprint(\"Creating environment...\")\nenv = make_atari_env(ENV_NAME, n_envs=N_ENVS, seed=42)\nenv = VecFrameStack(env, n_stack=N_STACK)\nenv = VecMonitor(env)  # Track episode rewards\n\nprint(f\"Observation shape: {env.observation_space.shape}\")\n\n# Create separate evaluation environment\ndef make_eval_env():\n    env = make_atari_env(ENV_NAME, n_envs=1, seed=123)\n    env = VecFrameStack(env, n_stack=N_STACK)\n    return env\n\neval_env = make_eval_env()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:05:25.773485Z","iopub.execute_input":"2025-12-14T19:05:25.773759Z","iopub.status.idle":"2025-12-14T19:05:27.167326Z","shell.execute_reply.started":"2025-12-14T19:05:25.773739Z","shell.execute_reply":"2025-12-14T19:05:27.166674Z"}},"outputs":[{"name":"stdout","text":"Creating environment...\nObservation shape: (84, 84, 4)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## PPO (On-Policy)","metadata":{}},{"cell_type":"code","source":"import optuna\n\ndef objective_ppo(trial):\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True)\n    n_steps = trial.suggest_categorical(\"n_steps\", [128, 256, 512])\n    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256])\n    gamma = trial.suggest_float(\"gamma\", 0.97, 0.999)\n    clip_range = trial.suggest_float(\"clip_range\", 0.05, 0.2)\n\n    if (n_steps * 4) % batch_size != 0:\n        raise optuna.exceptions.TrialPruned()\n\n    env = make_atari_env(ENV_NAME, n_envs=4, seed=42)\n    env = VecFrameStack(env, n_stack=N_STACK)\n    env = VecMonitor(env)\n\n    model = PPO(\n        \"CnnPolicy\",\n        env,\n        learning_rate=learning_rate,\n        n_steps=n_steps,\n        batch_size=batch_size,\n        n_epochs=4,\n        gamma=gamma,\n        clip_range=clip_range,\n        ent_coef=0.01,\n        verbose=0,\n        policy_kwargs={\"normalize_images\": False}\n    )\n\n    model.learn(total_timesteps=100000)\n\n    eval_env = make_atari_env(ENV_NAME, n_envs=1, seed=42)\n    eval_env = VecFrameStack(eval_env, n_stack=N_STACK)\n    mean_reward, _ = evaluate_policy(model, eval_env, n_eval_episodes=10)\n\n    env.close(); eval_env.close()\n    return mean_reward\n\n\nN_TRIALS = 15\n\nstudy_ppo = optuna.create_study(direction=\"maximize\", study_name=\"ppo_ms_pacman\")\nstudy_ppo.optimize(objective_ppo, n_trials=N_TRIALS, show_progress_bar=True)\nprint(\"\\nPPO Best hyperparameters:\", study_ppo.best_params)\nprint(\"PPO Best value:\", study_ppo.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:05:34.891215Z","iopub.execute_input":"2025-12-14T19:05:34.891798Z","iopub.status.idle":"2025-12-14T19:58:57.557134Z","shell.execute_reply.started":"2025-12-14T19:05:34.891776Z","shell.execute_reply":"2025-12-14T19:58:57.556342Z"}},"outputs":[{"name":"stderr","text":"[I 2025-12-14 19:05:34,896] A new study created in memory with name: ppo_ms_pacman\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc0632daa0e4e549d5bacf00256571e"}},"metadata":{}},{"name":"stdout","text":"[I 2025-12-14 19:09:05,827] Trial 0 finished with value: 60.0 and parameters: {'learning_rate': 0.000143760344912829, 'n_steps': 256, 'batch_size': 128, 'gamma': 0.9845921942012119, 'clip_range': 0.16160551416945956}. Best is trial 0 with value: 60.0.\n[I 2025-12-14 19:12:30,553] Trial 1 finished with value: 60.0 and parameters: {'learning_rate': 2.6019179052256328e-05, 'n_steps': 512, 'batch_size': 256, 'gamma': 0.9771278944268161, 'clip_range': 0.07320082301139605}. Best is trial 0 with value: 60.0.\n[I 2025-12-14 19:16:01,581] Trial 2 finished with value: 384.0 and parameters: {'learning_rate': 1.0422263717372322e-05, 'n_steps': 512, 'batch_size': 128, 'gamma': 0.9938251767702659, 'clip_range': 0.1505751357967328}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:19:36,887] Trial 3 finished with value: 240.0 and parameters: {'learning_rate': 0.00037432278525618545, 'n_steps': 128, 'batch_size': 256, 'gamma': 0.9881786559303081, 'clip_range': 0.1872806187937862}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:23:09,772] Trial 4 finished with value: 120.0 and parameters: {'learning_rate': 0.00014945202637451981, 'n_steps': 256, 'batch_size': 128, 'gamma': 0.9936508166204356, 'clip_range': 0.09856961339585847}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:26:44,785] Trial 5 finished with value: 189.0 and parameters: {'learning_rate': 1.3730845082489834e-05, 'n_steps': 128, 'batch_size': 256, 'gamma': 0.9820350451260434, 'clip_range': 0.16725876179873428}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:30:19,478] Trial 6 finished with value: 70.0 and parameters: {'learning_rate': 1.5164190565595104e-05, 'n_steps': 128, 'batch_size': 128, 'gamma': 0.9743403868252848, 'clip_range': 0.18863652556567506}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:33:57,560] Trial 7 finished with value: 210.0 and parameters: {'learning_rate': 7.078582330959451e-05, 'n_steps': 512, 'batch_size': 128, 'gamma': 0.9897259760668503, 'clip_range': 0.13066171049667358}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:37:31,637] Trial 8 finished with value: 60.0 and parameters: {'learning_rate': 2.936940366541366e-05, 'n_steps': 256, 'batch_size': 128, 'gamma': 0.9906922302094748, 'clip_range': 0.09745934035640014}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:41:04,280] Trial 9 finished with value: 60.0 and parameters: {'learning_rate': 1.2933931707929442e-05, 'n_steps': 256, 'batch_size': 256, 'gamma': 0.9835757092436672, 'clip_range': 0.12473627814063504}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:44:42,099] Trial 10 finished with value: 90.0 and parameters: {'learning_rate': 4.2192191271845786e-05, 'n_steps': 512, 'batch_size': 128, 'gamma': 0.9982849222256639, 'clip_range': 0.14267810953296403}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:48:20,530] Trial 11 finished with value: 219.0 and parameters: {'learning_rate': 0.0003146811893051116, 'n_steps': 128, 'batch_size': 256, 'gamma': 0.9965842672150288, 'clip_range': 0.19927205187248462}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:51:47,423] Trial 12 finished with value: 210.0 and parameters: {'learning_rate': 0.0004607701731161676, 'n_steps': 512, 'batch_size': 256, 'gamma': 0.9880615322426038, 'clip_range': 0.17228865017118283}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:55:19,223] Trial 13 finished with value: 170.0 and parameters: {'learning_rate': 0.00010794043406200223, 'n_steps': 128, 'batch_size': 256, 'gamma': 0.9935617318019142, 'clip_range': 0.14800481904237237}. Best is trial 2 with value: 384.0.\n[I 2025-12-14 19:58:57,551] Trial 14 finished with value: 562.0 and parameters: {'learning_rate': 0.00022778208300915553, 'n_steps': 512, 'batch_size': 128, 'gamma': 0.9863072168689243, 'clip_range': 0.18083474180084866}. Best is trial 14 with value: 562.0.\n\nPPO Best hyperparameters: {'learning_rate': 0.00022778208300915553, 'n_steps': 512, 'batch_size': 128, 'gamma': 0.9863072168689243, 'clip_range': 0.18083474180084866}\nPPO Best value: 562.0\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(\"Training PPO...\")\n\nppo_best_params = study_ppo.best_params\n\nppo_model = PPO(\n    \"CnnPolicy\",\n    env,\n    learning_rate=ppo_best_params[\"learning_rate\"],\n    n_steps=ppo_best_params[\"n_steps\"],\n    batch_size=ppo_best_params[\"batch_size\"],\n    n_epochs=4,\n    gamma=ppo_best_params[\"gamma\"],\n    clip_range=ppo_best_params[\"clip_range\"],\n    ent_coef=0.01,\n    verbose=1,\n    tensorboard_log=\"./logs/optimized/\",\n    policy_kwargs={\"normalize_images\": False}\n)\n\n# Train with evaluation callback\nppo_eval_callback = EvalCallback(\n    make_eval_env(),\n    best_model_save_path=\"./models/best_ppo/\",\n    log_path=\"./logs/ppo_eval/\",\n    eval_freq=2000,\n    deterministic=True,\n    render=False\n)\n\nppo_model.learn(\n    total_timesteps=TOTAL_TIMESTEPS,\n    callback=[ppo_eval_callback],\n    progress_bar=True,\n    tb_log_name=\"ppo_training\"\n)\n\nppo_model.save(\"./models/ppo_ms_pacman_final\")\nprint(\"PPO training complete and saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:58:57.558763Z","iopub.execute_input":"2025-12-14T19:58:57.559219Z","iopub.status.idle":"2025-12-14T20:37:12.138318Z","shell.execute_reply.started":"2025-12-14T19:58:57.559199Z","shell.execute_reply":"2025-12-14T20:37:12.137563Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Training PPO...\nUsing cuda device\nWrapping the env in a VecTransposeImage.\nLogging to ./logs/optimized/ppo_training_3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x78109e284e50> != <stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x78109def4190>\n  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 163      |\n|    ep_rew_mean     | 9.14     |\n| time/              |          |\n|    fps             | 570      |\n|    iterations      | 1        |\n|    time_elapsed    | 7        |\n|    total_timesteps | 4096     |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 162         |\n|    ep_rew_mean          | 8.93        |\n| time/                   |             |\n|    fps                  | 569         |\n|    iterations           | 2           |\n|    time_elapsed         | 14          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.047422845 |\n|    clip_fraction        | 0.712       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | -1.06       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 7.8         |\n|    n_updates            | 4           |\n|    policy_gradient_loss | 0.182       |\n|    value_loss           | 2.05e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 175         |\n|    ep_rew_mean          | 9.22        |\n| time/                   |             |\n|    fps                  | 567         |\n|    iterations           | 3           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.018805504 |\n|    clip_fraction        | 0.307       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.1        |\n|    explained_variance   | 0.583       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 2.54        |\n|    n_updates            | 8           |\n|    policy_gradient_loss | 0.00134     |\n|    value_loss           | 9.29        |\n-----------------------------------------\nEval num_timesteps=16000, episode_reward=160.00 +/- 0.00\nEpisode length: 3029.80 +/- 189.08\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.03e+03    |\n|    mean_reward          | 160         |\n| time/                   |             |\n|    total_timesteps      | 16000       |\n| train/                  |             |\n|    approx_kl            | 0.021152016 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.09       |\n|    explained_variance   | 0.646       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 1.28        |\n|    n_updates            | 12          |\n|    policy_gradient_loss | 0.000732    |\n|    value_loss           | 3.96        |\n-----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 177      |\n|    ep_rew_mean     | 9.3      |\n| time/              |          |\n|    fps             | 429      |\n|    iterations      | 4        |\n|    time_elapsed    | 38       |\n|    total_timesteps | 16384    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 177         |\n|    ep_rew_mean          | 9.1         |\n| time/                   |             |\n|    fps                  | 451         |\n|    iterations           | 5           |\n|    time_elapsed         | 45          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.022154985 |\n|    clip_fraction        | 0.318       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.09       |\n|    explained_variance   | 0.733       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.446       |\n|    n_updates            | 16          |\n|    policy_gradient_loss | -0.000298   |\n|    value_loss           | 1.88        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 183         |\n|    ep_rew_mean          | 9.68        |\n| time/                   |             |\n|    fps                  | 468         |\n|    iterations           | 6           |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 24576       |\n| train/                  |             |\n|    approx_kl            | 0.018722864 |\n|    clip_fraction        | 0.296       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.1        |\n|    explained_variance   | 0.46        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.349       |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0123     |\n|    value_loss           | 1.14        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 184         |\n|    ep_rew_mean          | 9.83        |\n| time/                   |             |\n|    fps                  | 481         |\n|    iterations           | 7           |\n|    time_elapsed         | 59          |\n|    total_timesteps      | 28672       |\n| train/                  |             |\n|    approx_kl            | 0.015211502 |\n|    clip_fraction        | 0.259       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.09       |\n|    explained_variance   | 0.361       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.338       |\n|    n_updates            | 24          |\n|    policy_gradient_loss | -0.00627    |\n|    value_loss           | 0.873       |\n-----------------------------------------\nEval num_timesteps=32000, episode_reward=844.00 +/- 165.00\nEpisode length: 2778.60 +/- 333.84\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.78e+03    |\n|    mean_reward          | 844         |\n| time/                   |             |\n|    total_timesteps      | 32000       |\n| train/                  |             |\n|    approx_kl            | 0.016496208 |\n|    clip_fraction        | 0.26        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.1        |\n|    explained_variance   | 0.338       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.305       |\n|    n_updates            | 28          |\n|    policy_gradient_loss | -0.00868    |\n|    value_loss           | 0.853       |\n-----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 180      |\n|    ep_rew_mean     | 9.59     |\n| time/              |          |\n|    fps             | 437      |\n|    iterations      | 8        |\n|    time_elapsed    | 74       |\n|    total_timesteps | 32768    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 177         |\n|    ep_rew_mean          | 9.4         |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 9           |\n|    time_elapsed         | 82          |\n|    total_timesteps      | 36864       |\n| train/                  |             |\n|    approx_kl            | 0.019105243 |\n|    clip_fraction        | 0.269       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.11       |\n|    explained_variance   | 0.322       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.183       |\n|    n_updates            | 32          |\n|    policy_gradient_loss | -0.0129     |\n|    value_loss           | 0.725       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 173         |\n|    ep_rew_mean          | 8.79        |\n| time/                   |             |\n|    fps                  | 458         |\n|    iterations           | 10          |\n|    time_elapsed         | 89          |\n|    total_timesteps      | 40960       |\n| train/                  |             |\n|    approx_kl            | 0.015468038 |\n|    clip_fraction        | 0.261       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.11       |\n|    explained_variance   | 0.462       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.106       |\n|    n_updates            | 36          |\n|    policy_gradient_loss | -0.0151     |\n|    value_loss           | 0.555       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 171         |\n|    ep_rew_mean          | 8.75        |\n| time/                   |             |\n|    fps                  | 466         |\n|    iterations           | 11          |\n|    time_elapsed         | 96          |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.015165838 |\n|    clip_fraction        | 0.25        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.11       |\n|    explained_variance   | 0.502       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0322      |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0175     |\n|    value_loss           | 0.559       |\n-----------------------------------------\nEval num_timesteps=48000, episode_reward=320.00 +/- 58.99\nEpisode length: 1665.00 +/- 203.40\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 1.66e+03    |\n|    mean_reward          | 320         |\n| time/                   |             |\n|    total_timesteps      | 48000       |\n| train/                  |             |\n|    approx_kl            | 0.018582387 |\n|    clip_fraction        | 0.278       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.12       |\n|    explained_variance   | 0.518       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.147       |\n|    n_updates            | 44          |\n|    policy_gradient_loss | -0.0197     |\n|    value_loss           | 0.518       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 165      |\n|    ep_rew_mean     | 8.42     |\n| time/              |          |\n|    fps             | 452      |\n|    iterations      | 12       |\n|    time_elapsed    | 108      |\n|    total_timesteps | 49152    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 169         |\n|    ep_rew_mean          | 9.26        |\n| time/                   |             |\n|    fps                  | 459         |\n|    iterations           | 13          |\n|    time_elapsed         | 115         |\n|    total_timesteps      | 53248       |\n| train/                  |             |\n|    approx_kl            | 0.016267987 |\n|    clip_fraction        | 0.268       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.1        |\n|    explained_variance   | 0.534       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.118       |\n|    n_updates            | 48          |\n|    policy_gradient_loss | -0.0172     |\n|    value_loss           | 0.628       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 172         |\n|    ep_rew_mean          | 9.86        |\n| time/                   |             |\n|    fps                  | 466         |\n|    iterations           | 14          |\n|    time_elapsed         | 122         |\n|    total_timesteps      | 57344       |\n| train/                  |             |\n|    approx_kl            | 0.017283633 |\n|    clip_fraction        | 0.283       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.1        |\n|    explained_variance   | 0.631       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0656      |\n|    n_updates            | 52          |\n|    policy_gradient_loss | -0.0185     |\n|    value_loss           | 0.515       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 178        |\n|    ep_rew_mean          | 10.1       |\n| time/                   |            |\n|    fps                  | 472        |\n|    iterations           | 15         |\n|    time_elapsed         | 130        |\n|    total_timesteps      | 61440      |\n| train/                  |            |\n|    approx_kl            | 0.02240083 |\n|    clip_fraction        | 0.31       |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -2.09      |\n|    explained_variance   | 0.564      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.142      |\n|    n_updates            | 56         |\n|    policy_gradient_loss | -0.0173    |\n|    value_loss           | 0.548      |\n----------------------------------------\nEval num_timesteps=64000, episode_reward=660.00 +/- 193.18\nEpisode length: 2450.60 +/- 211.26\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.45e+03    |\n|    mean_reward          | 660         |\n| time/                   |             |\n|    total_timesteps      | 64000       |\n| train/                  |             |\n|    approx_kl            | 0.019149844 |\n|    clip_fraction        | 0.3         |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.08       |\n|    explained_variance   | 0.647       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.136       |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.0191     |\n|    value_loss           | 0.535       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 184      |\n|    ep_rew_mean     | 11.2     |\n| time/              |          |\n|    fps             | 454      |\n|    iterations      | 16       |\n|    time_elapsed    | 144      |\n|    total_timesteps | 65536    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 184         |\n|    ep_rew_mean          | 10.9        |\n| time/                   |             |\n|    fps                  | 459         |\n|    iterations           | 17          |\n|    time_elapsed         | 151         |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.020914372 |\n|    clip_fraction        | 0.303       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.06       |\n|    explained_variance   | 0.634       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0767      |\n|    n_updates            | 64          |\n|    policy_gradient_loss | -0.0186     |\n|    value_loss           | 0.569       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 187        |\n|    ep_rew_mean          | 11.1       |\n| time/                   |            |\n|    fps                  | 464        |\n|    iterations           | 18         |\n|    time_elapsed         | 158        |\n|    total_timesteps      | 73728      |\n| train/                  |            |\n|    approx_kl            | 0.02312348 |\n|    clip_fraction        | 0.322      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -2.06      |\n|    explained_variance   | 0.748      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0292     |\n|    n_updates            | 68         |\n|    policy_gradient_loss | -0.0217    |\n|    value_loss           | 0.455      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 181         |\n|    ep_rew_mean          | 11          |\n| time/                   |             |\n|    fps                  | 469         |\n|    iterations           | 19          |\n|    time_elapsed         | 165         |\n|    total_timesteps      | 77824       |\n| train/                  |             |\n|    approx_kl            | 0.024745889 |\n|    clip_fraction        | 0.326       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.05       |\n|    explained_variance   | 0.685       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.105       |\n|    n_updates            | 72          |\n|    policy_gradient_loss | -0.02       |\n|    value_loss           | 0.582       |\n-----------------------------------------\nEval num_timesteps=80000, episode_reward=746.00 +/- 194.69\nEpisode length: 2863.40 +/- 314.90\n---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 2.86e+03  |\n|    mean_reward          | 746       |\n| time/                   |           |\n|    total_timesteps      | 80000     |\n| train/                  |           |\n|    approx_kl            | 0.0214349 |\n|    clip_fraction        | 0.323     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -2.04     |\n|    explained_variance   | 0.669     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.244     |\n|    n_updates            | 76        |\n|    policy_gradient_loss | -0.0143   |\n|    value_loss           | 0.526     |\n---------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 184      |\n|    ep_rew_mean     | 11.7     |\n| time/              |          |\n|    fps             | 451      |\n|    iterations      | 20       |\n|    time_elapsed    | 181      |\n|    total_timesteps | 81920    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 190         |\n|    ep_rew_mean          | 11.9        |\n| time/                   |             |\n|    fps                  | 456         |\n|    iterations           | 21          |\n|    time_elapsed         | 188         |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.026045527 |\n|    clip_fraction        | 0.339       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.04       |\n|    explained_variance   | 0.677       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.107       |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.0199     |\n|    value_loss           | 0.554       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 193         |\n|    ep_rew_mean          | 12.8        |\n| time/                   |             |\n|    fps                  | 460         |\n|    iterations           | 22          |\n|    time_elapsed         | 195         |\n|    total_timesteps      | 90112       |\n| train/                  |             |\n|    approx_kl            | 0.024822637 |\n|    clip_fraction        | 0.343       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.03       |\n|    explained_variance   | 0.726       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.199       |\n|    n_updates            | 84          |\n|    policy_gradient_loss | -0.018      |\n|    value_loss           | 0.599       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 198         |\n|    ep_rew_mean          | 14.1        |\n| time/                   |             |\n|    fps                  | 464         |\n|    iterations           | 23          |\n|    time_elapsed         | 202         |\n|    total_timesteps      | 94208       |\n| train/                  |             |\n|    approx_kl            | 0.025311274 |\n|    clip_fraction        | 0.357       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.01       |\n|    explained_variance   | 0.723       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.175       |\n|    n_updates            | 88          |\n|    policy_gradient_loss | -0.0175     |\n|    value_loss           | 0.615       |\n-----------------------------------------\nEval num_timesteps=96000, episode_reward=476.00 +/- 54.99\nEpisode length: 2474.60 +/- 362.83\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.47e+03   |\n|    mean_reward          | 476        |\n| time/                   |            |\n|    total_timesteps      | 96000      |\n| train/                  |            |\n|    approx_kl            | 0.02339269 |\n|    clip_fraction        | 0.347      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.99      |\n|    explained_variance   | 0.735      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.177      |\n|    n_updates            | 92         |\n|    policy_gradient_loss | -0.0143    |\n|    value_loss           | 0.769      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 204      |\n|    ep_rew_mean     | 14.6     |\n| time/              |          |\n|    fps             | 452      |\n|    iterations      | 24       |\n|    time_elapsed    | 217      |\n|    total_timesteps | 98304    |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 202        |\n|    ep_rew_mean          | 14.7       |\n| time/                   |            |\n|    fps                  | 455        |\n|    iterations           | 25         |\n|    time_elapsed         | 224        |\n|    total_timesteps      | 102400     |\n| train/                  |            |\n|    approx_kl            | 0.02599942 |\n|    clip_fraction        | 0.376      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -2         |\n|    explained_variance   | 0.721      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0507     |\n|    n_updates            | 96         |\n|    policy_gradient_loss | -0.0207    |\n|    value_loss           | 0.664      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 194         |\n|    ep_rew_mean          | 14.5        |\n| time/                   |             |\n|    fps                  | 459         |\n|    iterations           | 26          |\n|    time_elapsed         | 231         |\n|    total_timesteps      | 106496      |\n| train/                  |             |\n|    approx_kl            | 0.024212822 |\n|    clip_fraction        | 0.361       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.02       |\n|    explained_variance   | 0.792       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0843      |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.0198     |\n|    value_loss           | 0.62        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 203         |\n|    ep_rew_mean          | 15.5        |\n| time/                   |             |\n|    fps                  | 462         |\n|    iterations           | 27          |\n|    time_elapsed         | 239         |\n|    total_timesteps      | 110592      |\n| train/                  |             |\n|    approx_kl            | 0.026174013 |\n|    clip_fraction        | 0.36        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.99       |\n|    explained_variance   | 0.766       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.312       |\n|    n_updates            | 104         |\n|    policy_gradient_loss | -0.018      |\n|    value_loss           | 0.847       |\n-----------------------------------------\nEval num_timesteps=112000, episode_reward=798.00 +/- 319.77\nEpisode length: 2681.00 +/- 281.71\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.68e+03    |\n|    mean_reward          | 798         |\n| time/                   |             |\n|    total_timesteps      | 112000      |\n| train/                  |             |\n|    approx_kl            | 0.026244745 |\n|    clip_fraction        | 0.378       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.99       |\n|    explained_variance   | 0.799       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.123       |\n|    n_updates            | 108         |\n|    policy_gradient_loss | -0.0173     |\n|    value_loss           | 0.761       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 202      |\n|    ep_rew_mean     | 15.3     |\n| time/              |          |\n|    fps             | 451      |\n|    iterations      | 28       |\n|    time_elapsed    | 254      |\n|    total_timesteps | 114688   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 204        |\n|    ep_rew_mean          | 15.2       |\n| time/                   |            |\n|    fps                  | 454        |\n|    iterations           | 29         |\n|    time_elapsed         | 261        |\n|    total_timesteps      | 118784     |\n| train/                  |            |\n|    approx_kl            | 0.02901486 |\n|    clip_fraction        | 0.408      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.98      |\n|    explained_variance   | 0.763      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.127      |\n|    n_updates            | 112        |\n|    policy_gradient_loss | -0.0144    |\n|    value_loss           | 0.742      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 217         |\n|    ep_rew_mean          | 16.4        |\n| time/                   |             |\n|    fps                  | 456         |\n|    iterations           | 30          |\n|    time_elapsed         | 268         |\n|    total_timesteps      | 122880      |\n| train/                  |             |\n|    approx_kl            | 0.028477151 |\n|    clip_fraction        | 0.386       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.97       |\n|    explained_variance   | 0.811       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.337       |\n|    n_updates            | 116         |\n|    policy_gradient_loss | -0.0155     |\n|    value_loss           | 0.812       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 231         |\n|    ep_rew_mean          | 17.9        |\n| time/                   |             |\n|    fps                  | 459         |\n|    iterations           | 31          |\n|    time_elapsed         | 276         |\n|    total_timesteps      | 126976      |\n| train/                  |             |\n|    approx_kl            | 0.026547823 |\n|    clip_fraction        | 0.338       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -2.03       |\n|    explained_variance   | 0.669       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.165       |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.0243     |\n|    value_loss           | 0.558       |\n-----------------------------------------\nEval num_timesteps=128000, episode_reward=714.00 +/- 303.95\nEpisode length: 2135.40 +/- 163.28\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.14e+03    |\n|    mean_reward          | 714         |\n| time/                   |             |\n|    total_timesteps      | 128000      |\n| train/                  |             |\n|    approx_kl            | 0.030676644 |\n|    clip_fraction        | 0.387       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.98       |\n|    explained_variance   | 0.817       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.181       |\n|    n_updates            | 124         |\n|    policy_gradient_loss | -0.021      |\n|    value_loss           | 0.633       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 237      |\n|    ep_rew_mean     | 18       |\n| time/              |          |\n|    fps             | 451      |\n|    iterations      | 32       |\n|    time_elapsed    | 290      |\n|    total_timesteps | 131072   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 244         |\n|    ep_rew_mean          | 18.7        |\n| time/                   |             |\n|    fps                  | 454         |\n|    iterations           | 33          |\n|    time_elapsed         | 297         |\n|    total_timesteps      | 135168      |\n| train/                  |             |\n|    approx_kl            | 0.032106765 |\n|    clip_fraction        | 0.386       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.97       |\n|    explained_variance   | 0.828       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.254       |\n|    n_updates            | 128         |\n|    policy_gradient_loss | -0.0155     |\n|    value_loss           | 0.705       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 241         |\n|    ep_rew_mean          | 18.1        |\n| time/                   |             |\n|    fps                  | 457         |\n|    iterations           | 34          |\n|    time_elapsed         | 304         |\n|    total_timesteps      | 139264      |\n| train/                  |             |\n|    approx_kl            | 0.028068986 |\n|    clip_fraction        | 0.367       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.96       |\n|    explained_variance   | 0.784       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.213       |\n|    n_updates            | 132         |\n|    policy_gradient_loss | -0.00929    |\n|    value_loss           | 0.915       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 239        |\n|    ep_rew_mean          | 19.2       |\n| time/                   |            |\n|    fps                  | 459        |\n|    iterations           | 35         |\n|    time_elapsed         | 311        |\n|    total_timesteps      | 143360     |\n| train/                  |            |\n|    approx_kl            | 0.03376331 |\n|    clip_fraction        | 0.401      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.95      |\n|    explained_variance   | 0.748      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0766     |\n|    n_updates            | 136        |\n|    policy_gradient_loss | -0.0157    |\n|    value_loss           | 0.815      |\n----------------------------------------\nEval num_timesteps=144000, episode_reward=760.00 +/- 294.96\nEpisode length: 2127.40 +/- 288.24\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.13e+03    |\n|    mean_reward          | 760         |\n| time/                   |             |\n|    total_timesteps      | 144000      |\n| train/                  |             |\n|    approx_kl            | 0.031963952 |\n|    clip_fraction        | 0.401       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.95       |\n|    explained_variance   | 0.773       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0675      |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.0184     |\n|    value_loss           | 0.686       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 219      |\n|    ep_rew_mean     | 17.3     |\n| time/              |          |\n|    fps             | 452      |\n|    iterations      | 36       |\n|    time_elapsed    | 325      |\n|    total_timesteps | 147456   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 214         |\n|    ep_rew_mean          | 16.7        |\n| time/                   |             |\n|    fps                  | 455         |\n|    iterations           | 37          |\n|    time_elapsed         | 332         |\n|    total_timesteps      | 151552      |\n| train/                  |             |\n|    approx_kl            | 0.026596665 |\n|    clip_fraction        | 0.377       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.92       |\n|    explained_variance   | 0.843       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.177       |\n|    n_updates            | 144         |\n|    policy_gradient_loss | -0.0164     |\n|    value_loss           | 0.693       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 214        |\n|    ep_rew_mean          | 16.7       |\n| time/                   |            |\n|    fps                  | 457        |\n|    iterations           | 38         |\n|    time_elapsed         | 340        |\n|    total_timesteps      | 155648     |\n| train/                  |            |\n|    approx_kl            | 0.02649957 |\n|    clip_fraction        | 0.353      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.94      |\n|    explained_variance   | 0.875      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.407      |\n|    n_updates            | 148        |\n|    policy_gradient_loss | -0.0163    |\n|    value_loss           | 0.838      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 211         |\n|    ep_rew_mean          | 16.4        |\n| time/                   |             |\n|    fps                  | 459         |\n|    iterations           | 39          |\n|    time_elapsed         | 347         |\n|    total_timesteps      | 159744      |\n| train/                  |             |\n|    approx_kl            | 0.026905926 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.96       |\n|    explained_variance   | 0.859       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.12        |\n|    n_updates            | 152         |\n|    policy_gradient_loss | -0.0177     |\n|    value_loss           | 0.603       |\n-----------------------------------------\nEval num_timesteps=160000, episode_reward=470.00 +/- 40.00\nEpisode length: 2258.60 +/- 12.80\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.26e+03   |\n|    mean_reward          | 470        |\n| time/                   |            |\n|    total_timesteps      | 160000     |\n| train/                  |            |\n|    approx_kl            | 0.02863301 |\n|    clip_fraction        | 0.377      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.93      |\n|    explained_variance   | 0.84       |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.237      |\n|    n_updates            | 156        |\n|    policy_gradient_loss | -0.0152    |\n|    value_loss           | 0.803      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 214      |\n|    ep_rew_mean     | 16.8     |\n| time/              |          |\n|    fps             | 452      |\n|    iterations      | 40       |\n|    time_elapsed    | 361      |\n|    total_timesteps | 163840   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 214         |\n|    ep_rew_mean          | 16.9        |\n| time/                   |             |\n|    fps                  | 454         |\n|    iterations           | 41          |\n|    time_elapsed         | 369         |\n|    total_timesteps      | 167936      |\n| train/                  |             |\n|    approx_kl            | 0.026403263 |\n|    clip_fraction        | 0.381       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.95       |\n|    explained_variance   | 0.829       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.231       |\n|    n_updates            | 160         |\n|    policy_gradient_loss | -0.013      |\n|    value_loss           | 0.727       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 212         |\n|    ep_rew_mean          | 17.1        |\n| time/                   |             |\n|    fps                  | 457         |\n|    iterations           | 42          |\n|    time_elapsed         | 376         |\n|    total_timesteps      | 172032      |\n| train/                  |             |\n|    approx_kl            | 0.023491224 |\n|    clip_fraction        | 0.328       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.91       |\n|    explained_variance   | 0.859       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.278       |\n|    n_updates            | 164         |\n|    policy_gradient_loss | -0.0127     |\n|    value_loss           | 1.01        |\n-----------------------------------------\nEval num_timesteps=176000, episode_reward=646.00 +/- 170.83\nEpisode length: 2909.80 +/- 153.60\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.91e+03    |\n|    mean_reward          | 646         |\n| time/                   |             |\n|    total_timesteps      | 176000      |\n| train/                  |             |\n|    approx_kl            | 0.028836302 |\n|    clip_fraction        | 0.367       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.92       |\n|    explained_variance   | 0.906       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.121       |\n|    n_updates            | 168         |\n|    policy_gradient_loss | -0.0184     |\n|    value_loss           | 0.786       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 214      |\n|    ep_rew_mean     | 17.2     |\n| time/              |          |\n|    fps             | 448      |\n|    iterations      | 43       |\n|    time_elapsed    | 392      |\n|    total_timesteps | 176128   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 217         |\n|    ep_rew_mean          | 18          |\n| time/                   |             |\n|    fps                  | 450         |\n|    iterations           | 44          |\n|    time_elapsed         | 399         |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.026269514 |\n|    clip_fraction        | 0.348       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.95       |\n|    explained_variance   | 0.885       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.152       |\n|    n_updates            | 172         |\n|    policy_gradient_loss | -0.0198     |\n|    value_loss           | 0.705       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 220         |\n|    ep_rew_mean          | 18.4        |\n| time/                   |             |\n|    fps                  | 453         |\n|    iterations           | 45          |\n|    time_elapsed         | 406         |\n|    total_timesteps      | 184320      |\n| train/                  |             |\n|    approx_kl            | 0.027465805 |\n|    clip_fraction        | 0.375       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.92       |\n|    explained_variance   | 0.875       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.15        |\n|    n_updates            | 176         |\n|    policy_gradient_loss | -0.0152     |\n|    value_loss           | 0.853       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 225         |\n|    ep_rew_mean          | 19.3        |\n| time/                   |             |\n|    fps                  | 455         |\n|    iterations           | 46          |\n|    time_elapsed         | 414         |\n|    total_timesteps      | 188416      |\n| train/                  |             |\n|    approx_kl            | 0.023885366 |\n|    clip_fraction        | 0.345       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.96       |\n|    explained_variance   | 0.897       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.218       |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.0205     |\n|    value_loss           | 0.616       |\n-----------------------------------------\nEval num_timesteps=192000, episode_reward=1222.00 +/- 400.77\nEpisode length: 3212.20 +/- 609.19\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.21e+03    |\n|    mean_reward          | 1.22e+03    |\n| time/                   |             |\n|    total_timesteps      | 192000      |\n| train/                  |             |\n|    approx_kl            | 0.024928354 |\n|    clip_fraction        | 0.35        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.94       |\n|    explained_variance   | 0.911       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.305       |\n|    n_updates            | 184         |\n|    policy_gradient_loss | -0.0165     |\n|    value_loss           | 0.727       |\n-----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 231      |\n|    ep_rew_mean     | 19.6     |\n| time/              |          |\n|    fps             | 446      |\n|    iterations      | 47       |\n|    time_elapsed    | 430      |\n|    total_timesteps | 192512   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 227         |\n|    ep_rew_mean          | 19.3        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 48          |\n|    time_elapsed         | 438         |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.030353263 |\n|    clip_fraction        | 0.357       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.89       |\n|    explained_variance   | 0.915       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.32        |\n|    n_updates            | 188         |\n|    policy_gradient_loss | -0.0196     |\n|    value_loss           | 0.775       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 226         |\n|    ep_rew_mean          | 19.3        |\n| time/                   |             |\n|    fps                  | 450         |\n|    iterations           | 49          |\n|    time_elapsed         | 445         |\n|    total_timesteps      | 200704      |\n| train/                  |             |\n|    approx_kl            | 0.030791137 |\n|    clip_fraction        | 0.377       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.89       |\n|    explained_variance   | 0.908       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.595       |\n|    n_updates            | 192         |\n|    policy_gradient_loss | -0.0153     |\n|    value_loss           | 0.834       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 229        |\n|    ep_rew_mean          | 19.6       |\n| time/                   |            |\n|    fps                  | 452        |\n|    iterations           | 50         |\n|    time_elapsed         | 452        |\n|    total_timesteps      | 204800     |\n| train/                  |            |\n|    approx_kl            | 0.02599144 |\n|    clip_fraction        | 0.367      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.86      |\n|    explained_variance   | 0.912      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.125      |\n|    n_updates            | 196        |\n|    policy_gradient_loss | -0.0205    |\n|    value_loss           | 0.767      |\n----------------------------------------\nEval num_timesteps=208000, episode_reward=822.00 +/- 279.24\nEpisode length: 3485.80 +/- 924.93\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.49e+03   |\n|    mean_reward          | 822        |\n| time/                   |            |\n|    total_timesteps      | 208000     |\n| train/                  |            |\n|    approx_kl            | 0.03248716 |\n|    clip_fraction        | 0.401      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.9       |\n|    explained_variance   | 0.894      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0398     |\n|    n_updates            | 200        |\n|    policy_gradient_loss | -0.0212    |\n|    value_loss           | 0.604      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 229      |\n|    ep_rew_mean     | 20.2     |\n| time/              |          |\n|    fps             | 444      |\n|    iterations      | 51       |\n|    time_elapsed    | 470      |\n|    total_timesteps | 208896   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 225         |\n|    ep_rew_mean          | 19.8        |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 52          |\n|    time_elapsed         | 477         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.029090319 |\n|    clip_fraction        | 0.385       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.83       |\n|    explained_variance   | 0.901       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.162       |\n|    n_updates            | 204         |\n|    policy_gradient_loss | -0.0127     |\n|    value_loss           | 0.858       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 220        |\n|    ep_rew_mean          | 19.4       |\n| time/                   |            |\n|    fps                  | 447        |\n|    iterations           | 53         |\n|    time_elapsed         | 484        |\n|    total_timesteps      | 217088     |\n| train/                  |            |\n|    approx_kl            | 0.03322555 |\n|    clip_fraction        | 0.403      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.84      |\n|    explained_variance   | 0.909      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.132      |\n|    n_updates            | 208        |\n|    policy_gradient_loss | -0.0167    |\n|    value_loss           | 0.762      |\n----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 219       |\n|    ep_rew_mean          | 18.9      |\n| time/                   |           |\n|    fps                  | 449       |\n|    iterations           | 54        |\n|    time_elapsed         | 492       |\n|    total_timesteps      | 221184    |\n| train/                  |           |\n|    approx_kl            | 0.0282514 |\n|    clip_fraction        | 0.356     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.83     |\n|    explained_variance   | 0.908     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.539     |\n|    n_updates            | 212       |\n|    policy_gradient_loss | -0.0187   |\n|    value_loss           | 0.764     |\n---------------------------------------\nEval num_timesteps=224000, episode_reward=836.00 +/- 238.04\nEpisode length: 2322.60 +/- 297.85\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.32e+03    |\n|    mean_reward          | 836         |\n| time/                   |             |\n|    total_timesteps      | 224000      |\n| train/                  |             |\n|    approx_kl            | 0.024873447 |\n|    clip_fraction        | 0.326       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.82       |\n|    explained_variance   | 0.925       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.272       |\n|    n_updates            | 216         |\n|    policy_gradient_loss | -0.0164     |\n|    value_loss           | 0.945       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 210      |\n|    ep_rew_mean     | 18.5     |\n| time/              |          |\n|    fps             | 445      |\n|    iterations      | 55       |\n|    time_elapsed    | 506      |\n|    total_timesteps | 225280   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 205         |\n|    ep_rew_mean          | 18          |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 56          |\n|    time_elapsed         | 513         |\n|    total_timesteps      | 229376      |\n| train/                  |             |\n|    approx_kl            | 0.028046545 |\n|    clip_fraction        | 0.345       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.84       |\n|    explained_variance   | 0.938       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.4         |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.0191     |\n|    value_loss           | 0.739       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 198         |\n|    ep_rew_mean          | 17.5        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 57          |\n|    time_elapsed         | 520         |\n|    total_timesteps      | 233472      |\n| train/                  |             |\n|    approx_kl            | 0.028126162 |\n|    clip_fraction        | 0.338       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.84       |\n|    explained_variance   | 0.908       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.191       |\n|    n_updates            | 224         |\n|    policy_gradient_loss | -0.0196     |\n|    value_loss           | 0.813       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 214         |\n|    ep_rew_mean          | 18.9        |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 58          |\n|    time_elapsed         | 528         |\n|    total_timesteps      | 237568      |\n| train/                  |             |\n|    approx_kl            | 0.028293867 |\n|    clip_fraction        | 0.351       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.76       |\n|    explained_variance   | 0.932       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.335       |\n|    n_updates            | 228         |\n|    policy_gradient_loss | -0.0131     |\n|    value_loss           | 0.892       |\n-----------------------------------------\nEval num_timesteps=240000, episode_reward=500.00 +/- 20.00\nEpisode length: 2412.20 +/- 9.60\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.41e+03    |\n|    mean_reward          | 500         |\n| time/                   |             |\n|    total_timesteps      | 240000      |\n| train/                  |             |\n|    approx_kl            | 0.027888235 |\n|    clip_fraction        | 0.35        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.84       |\n|    explained_variance   | 0.932       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.138       |\n|    n_updates            | 232         |\n|    policy_gradient_loss | -0.0185     |\n|    value_loss           | 0.56        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 214      |\n|    ep_rew_mean     | 18.6     |\n| time/              |          |\n|    fps             | 445      |\n|    iterations      | 59       |\n|    time_elapsed    | 542      |\n|    total_timesteps | 241664   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 220         |\n|    ep_rew_mean          | 19.2        |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 60          |\n|    time_elapsed         | 549         |\n|    total_timesteps      | 245760      |\n| train/                  |             |\n|    approx_kl            | 0.027880305 |\n|    clip_fraction        | 0.361       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.8        |\n|    explained_variance   | 0.937       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.24        |\n|    n_updates            | 236         |\n|    policy_gradient_loss | -0.0163     |\n|    value_loss           | 0.689       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 228         |\n|    ep_rew_mean          | 20.5        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 61          |\n|    time_elapsed         | 557         |\n|    total_timesteps      | 249856      |\n| train/                  |             |\n|    approx_kl            | 0.026273599 |\n|    clip_fraction        | 0.343       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.76       |\n|    explained_variance   | 0.923       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.368       |\n|    n_updates            | 240         |\n|    policy_gradient_loss | -0.00997    |\n|    value_loss           | 1.02        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 21.3        |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 62          |\n|    time_elapsed         | 564         |\n|    total_timesteps      | 253952      |\n| train/                  |             |\n|    approx_kl            | 0.033808462 |\n|    clip_fraction        | 0.391       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.8        |\n|    explained_variance   | 0.914       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.159       |\n|    n_updates            | 244         |\n|    policy_gradient_loss | -0.0237     |\n|    value_loss           | 0.851       |\n-----------------------------------------\nEval num_timesteps=256000, episode_reward=640.00 +/- 131.91\nEpisode length: 2351.40 +/- 268.37\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.35e+03    |\n|    mean_reward          | 640         |\n| time/                   |             |\n|    total_timesteps      | 256000      |\n| train/                  |             |\n|    approx_kl            | 0.031128895 |\n|    clip_fraction        | 0.38        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.83       |\n|    explained_variance   | 0.931       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.195       |\n|    n_updates            | 248         |\n|    policy_gradient_loss | -0.0164     |\n|    value_loss           | 0.779       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 227      |\n|    ep_rew_mean     | 20.7     |\n| time/              |          |\n|    fps             | 445      |\n|    iterations      | 63       |\n|    time_elapsed    | 578      |\n|    total_timesteps | 258048   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 217         |\n|    ep_rew_mean          | 20.6        |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 64          |\n|    time_elapsed         | 585         |\n|    total_timesteps      | 262144      |\n| train/                  |             |\n|    approx_kl            | 0.031074882 |\n|    clip_fraction        | 0.379       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.81       |\n|    explained_variance   | 0.924       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.464       |\n|    n_updates            | 252         |\n|    policy_gradient_loss | -0.0208     |\n|    value_loss           | 0.935       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 211         |\n|    ep_rew_mean          | 20.5        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 65          |\n|    time_elapsed         | 593         |\n|    total_timesteps      | 266240      |\n| train/                  |             |\n|    approx_kl            | 0.033123955 |\n|    clip_fraction        | 0.378       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.82       |\n|    explained_variance   | 0.912       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.579       |\n|    n_updates            | 256         |\n|    policy_gradient_loss | -0.0179     |\n|    value_loss           | 0.875       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 198        |\n|    ep_rew_mean          | 18.7       |\n| time/                   |            |\n|    fps                  | 450        |\n|    iterations           | 66         |\n|    time_elapsed         | 600        |\n|    total_timesteps      | 270336     |\n| train/                  |            |\n|    approx_kl            | 0.03308624 |\n|    clip_fraction        | 0.372      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.75      |\n|    explained_variance   | 0.9        |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.382      |\n|    n_updates            | 260        |\n|    policy_gradient_loss | -0.0162    |\n|    value_loss           | 1.16       |\n----------------------------------------\nEval num_timesteps=272000, episode_reward=700.00 +/- 215.31\nEpisode length: 2157.80 +/- 58.92\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.16e+03    |\n|    mean_reward          | 700         |\n| time/                   |             |\n|    total_timesteps      | 272000      |\n| train/                  |             |\n|    approx_kl            | 0.033299863 |\n|    clip_fraction        | 0.372       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.922       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.189       |\n|    n_updates            | 264         |\n|    policy_gradient_loss | -0.0182     |\n|    value_loss           | 0.999       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 199      |\n|    ep_rew_mean     | 19.4     |\n| time/              |          |\n|    fps             | 447      |\n|    iterations      | 67       |\n|    time_elapsed    | 613      |\n|    total_timesteps | 274432   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 199        |\n|    ep_rew_mean          | 20.1       |\n| time/                   |            |\n|    fps                  | 448        |\n|    iterations           | 68         |\n|    time_elapsed         | 620        |\n|    total_timesteps      | 278528     |\n| train/                  |            |\n|    approx_kl            | 0.03635152 |\n|    clip_fraction        | 0.408      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.81      |\n|    explained_variance   | 0.913      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.117      |\n|    n_updates            | 268        |\n|    policy_gradient_loss | -0.0177    |\n|    value_loss           | 0.822      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 208         |\n|    ep_rew_mean          | 20.6        |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 69          |\n|    time_elapsed         | 628         |\n|    total_timesteps      | 282624      |\n| train/                  |             |\n|    approx_kl            | 0.031252395 |\n|    clip_fraction        | 0.366       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.73       |\n|    explained_variance   | 0.925       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.341       |\n|    n_updates            | 272         |\n|    policy_gradient_loss | -0.0156     |\n|    value_loss           | 0.939       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 220         |\n|    ep_rew_mean          | 22.6        |\n| time/                   |             |\n|    fps                  | 451         |\n|    iterations           | 70          |\n|    time_elapsed         | 635         |\n|    total_timesteps      | 286720      |\n| train/                  |             |\n|    approx_kl            | 0.037891757 |\n|    clip_fraction        | 0.382       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.8        |\n|    explained_variance   | 0.931       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.316       |\n|    n_updates            | 276         |\n|    policy_gradient_loss | -0.0149     |\n|    value_loss           | 0.814       |\n-----------------------------------------\nEval num_timesteps=288000, episode_reward=766.00 +/- 163.05\nEpisode length: 2831.40 +/- 517.51\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.83e+03    |\n|    mean_reward          | 766         |\n| time/                   |             |\n|    total_timesteps      | 288000      |\n| train/                  |             |\n|    approx_kl            | 0.028888322 |\n|    clip_fraction        | 0.383       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.78       |\n|    explained_variance   | 0.948       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0961      |\n|    n_updates            | 280         |\n|    policy_gradient_loss | -0.0202     |\n|    value_loss           | 0.708       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 229      |\n|    ep_rew_mean     | 23.9     |\n| time/              |          |\n|    fps             | 446      |\n|    iterations      | 71       |\n|    time_elapsed    | 650      |\n|    total_timesteps | 290816   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 235         |\n|    ep_rew_mean          | 23.7        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 72          |\n|    time_elapsed         | 658         |\n|    total_timesteps      | 294912      |\n| train/                  |             |\n|    approx_kl            | 0.029079508 |\n|    clip_fraction        | 0.383       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.81       |\n|    explained_variance   | 0.943       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.61        |\n|    n_updates            | 284         |\n|    policy_gradient_loss | -0.0115     |\n|    value_loss           | 0.817       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 251        |\n|    ep_rew_mean          | 26.1       |\n| time/                   |            |\n|    fps                  | 449        |\n|    iterations           | 73         |\n|    time_elapsed         | 665        |\n|    total_timesteps      | 299008     |\n| train/                  |            |\n|    approx_kl            | 0.02743604 |\n|    clip_fraction        | 0.365      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.77      |\n|    explained_variance   | 0.953      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.309      |\n|    n_updates            | 288        |\n|    policy_gradient_loss | -0.0147    |\n|    value_loss           | 0.772      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 243         |\n|    ep_rew_mean          | 24.2        |\n| time/                   |             |\n|    fps                  | 450         |\n|    iterations           | 74          |\n|    time_elapsed         | 672         |\n|    total_timesteps      | 303104      |\n| train/                  |             |\n|    approx_kl            | 0.034617394 |\n|    clip_fraction        | 0.403       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.9        |\n|    explained_variance   | 0.939       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.273       |\n|    n_updates            | 292         |\n|    policy_gradient_loss | -0.0262     |\n|    value_loss           | 0.593       |\n-----------------------------------------\nEval num_timesteps=304000, episode_reward=1594.00 +/- 44.54\nEpisode length: 2706.60 +/- 75.96\n---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 2.71e+03  |\n|    mean_reward          | 1.59e+03  |\n| time/                   |           |\n|    total_timesteps      | 304000    |\n| train/                  |           |\n|    approx_kl            | 0.0288332 |\n|    clip_fraction        | 0.342     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.72     |\n|    explained_variance   | 0.957     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.0771    |\n|    n_updates            | 296       |\n|    policy_gradient_loss | -0.0144   |\n|    value_loss           | 0.894     |\n---------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 248      |\n|    ep_rew_mean     | 24.7     |\n| time/              |          |\n|    fps             | 446      |\n|    iterations      | 75       |\n|    time_elapsed    | 687      |\n|    total_timesteps | 307200   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 252         |\n|    ep_rew_mean          | 25.8        |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 76          |\n|    time_elapsed         | 695         |\n|    total_timesteps      | 311296      |\n| train/                  |             |\n|    approx_kl            | 0.030482668 |\n|    clip_fraction        | 0.348       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.78       |\n|    explained_variance   | 0.946       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.184       |\n|    n_updates            | 300         |\n|    policy_gradient_loss | -0.0136     |\n|    value_loss           | 0.86        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 258         |\n|    ep_rew_mean          | 26.4        |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 77          |\n|    time_elapsed         | 702         |\n|    total_timesteps      | 315392      |\n| train/                  |             |\n|    approx_kl            | 0.028683547 |\n|    clip_fraction        | 0.369       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.77       |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.449       |\n|    n_updates            | 304         |\n|    policy_gradient_loss | -0.0163     |\n|    value_loss           | 0.821       |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 252       |\n|    ep_rew_mean          | 25.5      |\n| time/                   |           |\n|    fps                  | 450       |\n|    iterations           | 78        |\n|    time_elapsed         | 709       |\n|    total_timesteps      | 319488    |\n| train/                  |           |\n|    approx_kl            | 0.0344287 |\n|    clip_fraction        | 0.391     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.81     |\n|    explained_variance   | 0.945     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.43      |\n|    n_updates            | 308       |\n|    policy_gradient_loss | -0.0216   |\n|    value_loss           | 0.693     |\n---------------------------------------\nEval num_timesteps=320000, episode_reward=1284.00 +/- 221.68\nEpisode length: 2778.60 +/- 668.61\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.78e+03   |\n|    mean_reward          | 1.28e+03   |\n| time/                   |            |\n|    total_timesteps      | 320000     |\n| train/                  |            |\n|    approx_kl            | 0.03210208 |\n|    clip_fraction        | 0.398      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.76      |\n|    explained_variance   | 0.93       |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.336      |\n|    n_updates            | 312        |\n|    policy_gradient_loss | -0.0116    |\n|    value_loss           | 1.12       |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 251      |\n|    ep_rew_mean     | 26       |\n| time/              |          |\n|    fps             | 446      |\n|    iterations      | 79       |\n|    time_elapsed    | 724      |\n|    total_timesteps | 323584   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 257         |\n|    ep_rew_mean          | 26.6        |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 80          |\n|    time_elapsed         | 732         |\n|    total_timesteps      | 327680      |\n| train/                  |             |\n|    approx_kl            | 0.030142952 |\n|    clip_fraction        | 0.38        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.74       |\n|    explained_variance   | 0.939       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.283       |\n|    n_updates            | 316         |\n|    policy_gradient_loss | -0.0125     |\n|    value_loss           | 0.85        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 253         |\n|    ep_rew_mean          | 26.6        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 81          |\n|    time_elapsed         | 739         |\n|    total_timesteps      | 331776      |\n| train/                  |             |\n|    approx_kl            | 0.029246513 |\n|    clip_fraction        | 0.37        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.953       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.687       |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.0137     |\n|    value_loss           | 0.906       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 251         |\n|    ep_rew_mean          | 26.2        |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 82          |\n|    time_elapsed         | 746         |\n|    total_timesteps      | 335872      |\n| train/                  |             |\n|    approx_kl            | 0.028661117 |\n|    clip_fraction        | 0.356       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.75       |\n|    explained_variance   | 0.925       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.603       |\n|    n_updates            | 324         |\n|    policy_gradient_loss | -0.0165     |\n|    value_loss           | 0.921       |\n-----------------------------------------\nEval num_timesteps=336000, episode_reward=1200.00 +/- 124.58\nEpisode length: 2889.00 +/- 251.76\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.89e+03    |\n|    mean_reward          | 1.2e+03     |\n| time/                   |             |\n|    total_timesteps      | 336000      |\n| train/                  |             |\n|    approx_kl            | 0.028279483 |\n|    clip_fraction        | 0.356       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.949       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.66        |\n|    n_updates            | 328         |\n|    policy_gradient_loss | -0.0177     |\n|    value_loss           | 0.881       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 245      |\n|    ep_rew_mean     | 25.4     |\n| time/              |          |\n|    fps             | 445      |\n|    iterations      | 83       |\n|    time_elapsed    | 762      |\n|    total_timesteps | 339968   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 255        |\n|    ep_rew_mean          | 26.1       |\n| time/                   |            |\n|    fps                  | 446        |\n|    iterations           | 84         |\n|    time_elapsed         | 769        |\n|    total_timesteps      | 344064     |\n| train/                  |            |\n|    approx_kl            | 0.03425457 |\n|    clip_fraction        | 0.385      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.77      |\n|    explained_variance   | 0.945      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.243      |\n|    n_updates            | 332        |\n|    policy_gradient_loss | -0.0165    |\n|    value_loss           | 0.767      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 252         |\n|    ep_rew_mean          | 25.6        |\n| time/                   |             |\n|    fps                  | 448         |\n|    iterations           | 85          |\n|    time_elapsed         | 777         |\n|    total_timesteps      | 348160      |\n| train/                  |             |\n|    approx_kl            | 0.029288601 |\n|    clip_fraction        | 0.373       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.83       |\n|    explained_variance   | 0.955       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.247       |\n|    n_updates            | 336         |\n|    policy_gradient_loss | -0.0185     |\n|    value_loss           | 0.727       |\n-----------------------------------------\nEval num_timesteps=352000, episode_reward=1160.00 +/- 293.94\nEpisode length: 3274.60 +/- 713.29\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.27e+03   |\n|    mean_reward          | 1.16e+03   |\n| time/                   |            |\n|    total_timesteps      | 352000     |\n| train/                  |            |\n|    approx_kl            | 0.03508202 |\n|    clip_fraction        | 0.37       |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.68      |\n|    explained_variance   | 0.929      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.163      |\n|    n_updates            | 340        |\n|    policy_gradient_loss | -0.0163    |\n|    value_loss           | 1.09       |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 253      |\n|    ep_rew_mean     | 25.5     |\n| time/              |          |\n|    fps             | 443      |\n|    iterations      | 86       |\n|    time_elapsed    | 793      |\n|    total_timesteps | 352256   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 256        |\n|    ep_rew_mean          | 26.3       |\n| time/                   |            |\n|    fps                  | 444        |\n|    iterations           | 87         |\n|    time_elapsed         | 801        |\n|    total_timesteps      | 356352     |\n| train/                  |            |\n|    approx_kl            | 0.03362294 |\n|    clip_fraction        | 0.341      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.74      |\n|    explained_variance   | 0.949      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.283      |\n|    n_updates            | 344        |\n|    policy_gradient_loss | -0.0128    |\n|    value_loss           | 1.05       |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 250        |\n|    ep_rew_mean          | 24.8       |\n| time/                   |            |\n|    fps                  | 445        |\n|    iterations           | 88         |\n|    time_elapsed         | 808        |\n|    total_timesteps      | 360448     |\n| train/                  |            |\n|    approx_kl            | 0.03683547 |\n|    clip_fraction        | 0.386      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.81      |\n|    explained_variance   | 0.942      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0851     |\n|    n_updates            | 348        |\n|    policy_gradient_loss | -0.0249    |\n|    value_loss           | 0.566      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 249         |\n|    ep_rew_mean          | 25          |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 89          |\n|    time_elapsed         | 815         |\n|    total_timesteps      | 364544      |\n| train/                  |             |\n|    approx_kl            | 0.041596953 |\n|    clip_fraction        | 0.375       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.919       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.295       |\n|    n_updates            | 352         |\n|    policy_gradient_loss | -0.0122     |\n|    value_loss           | 0.906       |\n-----------------------------------------\nEval num_timesteps=368000, episode_reward=874.00 +/- 117.23\nEpisode length: 2401.00 +/- 534.65\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.4e+03     |\n|    mean_reward          | 874         |\n| time/                   |             |\n|    total_timesteps      | 368000      |\n| train/                  |             |\n|    approx_kl            | 0.031805247 |\n|    clip_fraction        | 0.381       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.931       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.317       |\n|    n_updates            | 356         |\n|    policy_gradient_loss | -0.0147     |\n|    value_loss           | 1.03        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 242      |\n|    ep_rew_mean     | 24.7     |\n| time/              |          |\n|    fps             | 444      |\n|    iterations      | 90       |\n|    time_elapsed    | 829      |\n|    total_timesteps | 368640   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 239         |\n|    ep_rew_mean          | 24.6        |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 91          |\n|    time_elapsed         | 837         |\n|    total_timesteps      | 372736      |\n| train/                  |             |\n|    approx_kl            | 0.035551377 |\n|    clip_fraction        | 0.373       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.77       |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0392      |\n|    n_updates            | 360         |\n|    policy_gradient_loss | -0.0221     |\n|    value_loss           | 0.69        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 230         |\n|    ep_rew_mean          | 24.5        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 92          |\n|    time_elapsed         | 844         |\n|    total_timesteps      | 376832      |\n| train/                  |             |\n|    approx_kl            | 0.029593643 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.65       |\n|    explained_variance   | 0.944       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.298       |\n|    n_updates            | 364         |\n|    policy_gradient_loss | -0.0161     |\n|    value_loss           | 1.03        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 237         |\n|    ep_rew_mean          | 25.4        |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 93          |\n|    time_elapsed         | 851         |\n|    total_timesteps      | 380928      |\n| train/                  |             |\n|    approx_kl            | 0.028647741 |\n|    clip_fraction        | 0.333       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.948       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.607       |\n|    n_updates            | 368         |\n|    policy_gradient_loss | -0.0159     |\n|    value_loss           | 1.11        |\n-----------------------------------------\nEval num_timesteps=384000, episode_reward=1188.00 +/- 51.54\nEpisode length: 2788.20 +/- 376.38\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.79e+03    |\n|    mean_reward          | 1.19e+03    |\n| time/                   |             |\n|    total_timesteps      | 384000      |\n| train/                  |             |\n|    approx_kl            | 0.031022437 |\n|    clip_fraction        | 0.353       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.957       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.12        |\n|    n_updates            | 372         |\n|    policy_gradient_loss | -0.0177     |\n|    value_loss           | 0.858       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 234      |\n|    ep_rew_mean     | 24.9     |\n| time/              |          |\n|    fps             | 444      |\n|    iterations      | 94       |\n|    time_elapsed    | 866      |\n|    total_timesteps | 385024   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 25          |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 95          |\n|    time_elapsed         | 874         |\n|    total_timesteps      | 389120      |\n| train/                  |             |\n|    approx_kl            | 0.032755308 |\n|    clip_fraction        | 0.355       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.66       |\n|    explained_variance   | 0.954       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.269       |\n|    n_updates            | 376         |\n|    policy_gradient_loss | -0.0151     |\n|    value_loss           | 1           |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 25.4        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 96          |\n|    time_elapsed         | 881         |\n|    total_timesteps      | 393216      |\n| train/                  |             |\n|    approx_kl            | 0.041614614 |\n|    clip_fraction        | 0.38        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.925       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.441       |\n|    n_updates            | 380         |\n|    policy_gradient_loss | -0.00643    |\n|    value_loss           | 1.16        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 227         |\n|    ep_rew_mean          | 24          |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 97          |\n|    time_elapsed         | 888         |\n|    total_timesteps      | 397312      |\n| train/                  |             |\n|    approx_kl            | 0.034296747 |\n|    clip_fraction        | 0.374       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.943       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0936      |\n|    n_updates            | 384         |\n|    policy_gradient_loss | -0.0138     |\n|    value_loss           | 1.1         |\n-----------------------------------------\nEval num_timesteps=400000, episode_reward=1288.00 +/- 180.49\nEpisode length: 2868.20 +/- 169.07\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.87e+03    |\n|    mean_reward          | 1.29e+03    |\n| time/                   |             |\n|    total_timesteps      | 400000      |\n| train/                  |             |\n|    approx_kl            | 0.045193944 |\n|    clip_fraction        | 0.395       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.917       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.16        |\n|    n_updates            | 388         |\n|    policy_gradient_loss | -0.0127     |\n|    value_loss           | 1.15        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 233      |\n|    ep_rew_mean     | 24.7     |\n| time/              |          |\n|    fps             | 443      |\n|    iterations      | 98       |\n|    time_elapsed    | 904      |\n|    total_timesteps | 401408   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 227        |\n|    ep_rew_mean          | 24.3       |\n| time/                   |            |\n|    fps                  | 444        |\n|    iterations           | 99         |\n|    time_elapsed         | 911        |\n|    total_timesteps      | 405504     |\n| train/                  |            |\n|    approx_kl            | 0.03837926 |\n|    clip_fraction        | 0.342      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.66      |\n|    explained_variance   | 0.938      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.319      |\n|    n_updates            | 392        |\n|    policy_gradient_loss | -0.0138    |\n|    value_loss           | 1.03       |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 233        |\n|    ep_rew_mean          | 24.4       |\n| time/                   |            |\n|    fps                  | 445        |\n|    iterations           | 100        |\n|    time_elapsed         | 918        |\n|    total_timesteps      | 409600     |\n| train/                  |            |\n|    approx_kl            | 0.03479255 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.7       |\n|    explained_variance   | 0.948      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.307      |\n|    n_updates            | 396        |\n|    policy_gradient_loss | -0.0172    |\n|    value_loss           | 0.886      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 238         |\n|    ep_rew_mean          | 25.2        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 101         |\n|    time_elapsed         | 925         |\n|    total_timesteps      | 413696      |\n| train/                  |             |\n|    approx_kl            | 0.031406842 |\n|    clip_fraction        | 0.384       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.365       |\n|    n_updates            | 400         |\n|    policy_gradient_loss | -0.0173     |\n|    value_loss           | 0.923       |\n-----------------------------------------\nEval num_timesteps=416000, episode_reward=934.00 +/- 29.39\nEpisode length: 2177.00 +/- 293.94\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.18e+03    |\n|    mean_reward          | 934         |\n| time/                   |             |\n|    total_timesteps      | 416000      |\n| train/                  |             |\n|    approx_kl            | 0.035503525 |\n|    clip_fraction        | 0.398       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.945       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.168       |\n|    n_updates            | 404         |\n|    policy_gradient_loss | -0.015      |\n|    value_loss           | 0.736       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 244      |\n|    ep_rew_mean     | 25.6     |\n| time/              |          |\n|    fps             | 444      |\n|    iterations      | 102      |\n|    time_elapsed    | 939      |\n|    total_timesteps | 417792   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 25.6        |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 103         |\n|    time_elapsed         | 946         |\n|    total_timesteps      | 421888      |\n| train/                  |             |\n|    approx_kl            | 0.031146843 |\n|    clip_fraction        | 0.34        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.74       |\n|    explained_variance   | 0.922       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.495       |\n|    n_updates            | 408         |\n|    policy_gradient_loss | -0.0181     |\n|    value_loss           | 0.814       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 24.8        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 104         |\n|    time_elapsed         | 954         |\n|    total_timesteps      | 425984      |\n| train/                  |             |\n|    approx_kl            | 0.027427826 |\n|    clip_fraction        | 0.337       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.948       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.454       |\n|    n_updates            | 412         |\n|    policy_gradient_loss | -0.0194     |\n|    value_loss           | 1.01        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 253         |\n|    ep_rew_mean          | 25.6        |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 105         |\n|    time_elapsed         | 961         |\n|    total_timesteps      | 430080      |\n| train/                  |             |\n|    approx_kl            | 0.032678314 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.74       |\n|    explained_variance   | 0.941       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.424       |\n|    n_updates            | 416         |\n|    policy_gradient_loss | -0.0197     |\n|    value_loss           | 0.745       |\n-----------------------------------------\nEval num_timesteps=432000, episode_reward=1208.00 +/- 14.70\nEpisode length: 2909.80 +/- 23.52\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.91e+03   |\n|    mean_reward          | 1.21e+03   |\n| time/                   |            |\n|    total_timesteps      | 432000     |\n| train/                  |            |\n|    approx_kl            | 0.03421817 |\n|    clip_fraction        | 0.385      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.76      |\n|    explained_variance   | 0.932      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.124      |\n|    n_updates            | 420        |\n|    policy_gradient_loss | -0.0209    |\n|    value_loss           | 0.553      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 253      |\n|    ep_rew_mean     | 25.5     |\n| time/              |          |\n|    fps             | 444      |\n|    iterations      | 106      |\n|    time_elapsed    | 977      |\n|    total_timesteps | 434176   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 241         |\n|    ep_rew_mean          | 24          |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 107         |\n|    time_elapsed         | 984         |\n|    total_timesteps      | 438272      |\n| train/                  |             |\n|    approx_kl            | 0.037211575 |\n|    clip_fraction        | 0.343       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.58       |\n|    explained_variance   | 0.936       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.21        |\n|    n_updates            | 424         |\n|    policy_gradient_loss | -0.00859    |\n|    value_loss           | 1.01        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 235         |\n|    ep_rew_mean          | 24.2        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 108         |\n|    time_elapsed         | 991         |\n|    total_timesteps      | 442368      |\n| train/                  |             |\n|    approx_kl            | 0.026576363 |\n|    clip_fraction        | 0.328       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.61       |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.273       |\n|    n_updates            | 428         |\n|    policy_gradient_loss | -0.0176     |\n|    value_loss           | 0.9         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 231         |\n|    ep_rew_mean          | 23.2        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 109         |\n|    time_elapsed         | 998         |\n|    total_timesteps      | 446464      |\n| train/                  |             |\n|    approx_kl            | 0.037840914 |\n|    clip_fraction        | 0.369       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.74       |\n|    explained_variance   | 0.924       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0721      |\n|    n_updates            | 432         |\n|    policy_gradient_loss | -0.0103     |\n|    value_loss           | 0.794       |\n-----------------------------------------\nEval num_timesteps=448000, episode_reward=1044.00 +/- 264.54\nEpisode length: 3025.00 +/- 352.73\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.02e+03   |\n|    mean_reward          | 1.04e+03   |\n| time/                   |            |\n|    total_timesteps      | 448000     |\n| train/                  |            |\n|    approx_kl            | 0.03152899 |\n|    clip_fraction        | 0.377      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.68      |\n|    explained_variance   | 0.943      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.648      |\n|    n_updates            | 436        |\n|    policy_gradient_loss | -0.0159    |\n|    value_loss           | 0.824      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 239      |\n|    ep_rew_mean     | 25       |\n| time/              |          |\n|    fps             | 443      |\n|    iterations      | 110      |\n|    time_elapsed    | 1015     |\n|    total_timesteps | 450560   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 231         |\n|    ep_rew_mean          | 23.8        |\n| time/                   |             |\n|    fps                  | 444         |\n|    iterations           | 111         |\n|    time_elapsed         | 1022        |\n|    total_timesteps      | 454656      |\n| train/                  |             |\n|    approx_kl            | 0.027061164 |\n|    clip_fraction        | 0.337       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.958       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.379       |\n|    n_updates            | 440         |\n|    policy_gradient_loss | -0.0214     |\n|    value_loss           | 0.82        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 234         |\n|    ep_rew_mean          | 23.9        |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 112         |\n|    time_elapsed         | 1029        |\n|    total_timesteps      | 458752      |\n| train/                  |             |\n|    approx_kl            | 0.033522405 |\n|    clip_fraction        | 0.339       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.941       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.312       |\n|    n_updates            | 444         |\n|    policy_gradient_loss | -0.0162     |\n|    value_loss           | 0.782       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 244         |\n|    ep_rew_mean          | 25.5        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 113         |\n|    time_elapsed         | 1036        |\n|    total_timesteps      | 462848      |\n| train/                  |             |\n|    approx_kl            | 0.033229098 |\n|    clip_fraction        | 0.342       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.959       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.39        |\n|    n_updates            | 448         |\n|    policy_gradient_loss | -0.0156     |\n|    value_loss           | 0.818       |\n-----------------------------------------\nEval num_timesteps=464000, episode_reward=946.00 +/- 240.30\nEpisode length: 3004.20 +/- 87.72\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3e+03       |\n|    mean_reward          | 946         |\n| time/                   |             |\n|    total_timesteps      | 464000      |\n| train/                  |             |\n|    approx_kl            | 0.031907894 |\n|    clip_fraction        | 0.339       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.66       |\n|    explained_variance   | 0.958       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.178       |\n|    n_updates            | 452         |\n|    policy_gradient_loss | -0.0162     |\n|    value_loss           | 0.732       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 238      |\n|    ep_rew_mean     | 24.3     |\n| time/              |          |\n|    fps             | 443      |\n|    iterations      | 114      |\n|    time_elapsed    | 1052     |\n|    total_timesteps | 466944   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 253        |\n|    ep_rew_mean          | 26.5       |\n| time/                   |            |\n|    fps                  | 444        |\n|    iterations           | 115        |\n|    time_elapsed         | 1059       |\n|    total_timesteps      | 471040     |\n| train/                  |            |\n|    approx_kl            | 0.02649674 |\n|    clip_fraction        | 0.312      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.58      |\n|    explained_variance   | 0.963      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.56       |\n|    n_updates            | 456        |\n|    policy_gradient_loss | -0.0128    |\n|    value_loss           | 0.873      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 243         |\n|    ep_rew_mean          | 25.2        |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 116         |\n|    time_elapsed         | 1067        |\n|    total_timesteps      | 475136      |\n| train/                  |             |\n|    approx_kl            | 0.038091682 |\n|    clip_fraction        | 0.365       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.77       |\n|    explained_variance   | 0.953       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.146       |\n|    n_updates            | 460         |\n|    policy_gradient_loss | -0.016      |\n|    value_loss           | 0.718       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 251         |\n|    ep_rew_mean          | 25.8        |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 117         |\n|    time_elapsed         | 1074        |\n|    total_timesteps      | 479232      |\n| train/                  |             |\n|    approx_kl            | 0.029412322 |\n|    clip_fraction        | 0.315       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.53       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.399       |\n|    n_updates            | 464         |\n|    policy_gradient_loss | -0.0126     |\n|    value_loss           | 1.18        |\n-----------------------------------------\nEval num_timesteps=480000, episode_reward=1154.00 +/- 109.47\nEpisode length: 3087.40 +/- 741.64\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.09e+03   |\n|    mean_reward          | 1.15e+03   |\n| time/                   |            |\n|    total_timesteps      | 480000     |\n| train/                  |            |\n|    approx_kl            | 0.03187846 |\n|    clip_fraction        | 0.354      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.75      |\n|    explained_variance   | 0.951      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.107      |\n|    n_updates            | 468        |\n|    policy_gradient_loss | -0.0221    |\n|    value_loss           | 0.708      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 247      |\n|    ep_rew_mean     | 25.6     |\n| time/              |          |\n|    fps             | 443      |\n|    iterations      | 118      |\n|    time_elapsed    | 1090     |\n|    total_timesteps | 483328   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 246        |\n|    ep_rew_mean          | 25.2       |\n| time/                   |            |\n|    fps                  | 443        |\n|    iterations           | 119        |\n|    time_elapsed         | 1097       |\n|    total_timesteps      | 487424     |\n| train/                  |            |\n|    approx_kl            | 0.03293649 |\n|    clip_fraction        | 0.356      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.71      |\n|    explained_variance   | 0.945      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0984     |\n|    n_updates            | 472        |\n|    policy_gradient_loss | -0.0165    |\n|    value_loss           | 0.738      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 242         |\n|    ep_rew_mean          | 24.3        |\n| time/                   |             |\n|    fps                  | 444         |\n|    iterations           | 120         |\n|    time_elapsed         | 1105        |\n|    total_timesteps      | 491520      |\n| train/                  |             |\n|    approx_kl            | 0.032546006 |\n|    clip_fraction        | 0.33        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.932       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.116       |\n|    n_updates            | 476         |\n|    policy_gradient_loss | -0.0151     |\n|    value_loss           | 0.928       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 225        |\n|    ep_rew_mean          | 23.4       |\n| time/                   |            |\n|    fps                  | 445        |\n|    iterations           | 121        |\n|    time_elapsed         | 1112       |\n|    total_timesteps      | 495616     |\n| train/                  |            |\n|    approx_kl            | 0.03296397 |\n|    clip_fraction        | 0.362      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.65      |\n|    explained_variance   | 0.936      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.491      |\n|    n_updates            | 480        |\n|    policy_gradient_loss | -0.013     |\n|    value_loss           | 1.04       |\n----------------------------------------\nEval num_timesteps=496000, episode_reward=1244.00 +/- 376.33\nEpisode length: 3356.20 +/- 126.75\n---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 3.36e+03  |\n|    mean_reward          | 1.24e+03  |\n| time/                   |           |\n|    total_timesteps      | 496000    |\n| train/                  |           |\n|    approx_kl            | 0.0345734 |\n|    clip_fraction        | 0.342     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.58     |\n|    explained_variance   | 0.917     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.299     |\n|    n_updates            | 484       |\n|    policy_gradient_loss | -0.00822  |\n|    value_loss           | 1.19      |\n---------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 231      |\n|    ep_rew_mean     | 22.5     |\n| time/              |          |\n|    fps             | 442      |\n|    iterations      | 122      |\n|    time_elapsed    | 1129     |\n|    total_timesteps | 499712   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 223         |\n|    ep_rew_mean          | 22.1        |\n| time/                   |             |\n|    fps                  | 443         |\n|    iterations           | 123         |\n|    time_elapsed         | 1136        |\n|    total_timesteps      | 503808      |\n| train/                  |             |\n|    approx_kl            | 0.036174517 |\n|    clip_fraction        | 0.377       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.902       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.279       |\n|    n_updates            | 488         |\n|    policy_gradient_loss | -0.0186     |\n|    value_loss           | 0.935       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 228        |\n|    ep_rew_mean          | 22.7       |\n| time/                   |            |\n|    fps                  | 443        |\n|    iterations           | 124        |\n|    time_elapsed         | 1144       |\n|    total_timesteps      | 507904     |\n| train/                  |            |\n|    approx_kl            | 0.04245716 |\n|    clip_fraction        | 0.404      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.73      |\n|    explained_variance   | 0.889      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.0803     |\n|    n_updates            | 492        |\n|    policy_gradient_loss | -0.0169    |\n|    value_loss           | 0.595      |\n----------------------------------------\nEval num_timesteps=512000, episode_reward=1278.00 +/- 446.07\nEpisode length: 3783.40 +/- 204.80\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.78e+03    |\n|    mean_reward          | 1.28e+03    |\n| time/                   |             |\n|    total_timesteps      | 512000      |\n| train/                  |             |\n|    approx_kl            | 0.031138387 |\n|    clip_fraction        | 0.345       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.54       |\n|    explained_variance   | 0.947       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.237       |\n|    n_updates            | 496         |\n|    policy_gradient_loss | -0.0154     |\n|    value_loss           | 0.978       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 232      |\n|    ep_rew_mean     | 22.6     |\n| time/              |          |\n|    fps             | 440      |\n|    iterations      | 125      |\n|    time_elapsed    | 1162     |\n|    total_timesteps | 512000   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 241         |\n|    ep_rew_mean          | 23.8        |\n| time/                   |             |\n|    fps                  | 441         |\n|    iterations           | 126         |\n|    time_elapsed         | 1169        |\n|    total_timesteps      | 516096      |\n| train/                  |             |\n|    approx_kl            | 0.031033605 |\n|    clip_fraction        | 0.356       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.64       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.736       |\n|    n_updates            | 500         |\n|    policy_gradient_loss | -0.013      |\n|    value_loss           | 0.936       |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 252       |\n|    ep_rew_mean          | 23.9      |\n| time/                   |           |\n|    fps                  | 442       |\n|    iterations           | 127       |\n|    time_elapsed         | 1176      |\n|    total_timesteps      | 520192    |\n| train/                  |           |\n|    approx_kl            | 0.0401131 |\n|    clip_fraction        | 0.377     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.8      |\n|    explained_variance   | 0.911     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.0252    |\n|    n_updates            | 504       |\n|    policy_gradient_loss | -0.0204   |\n|    value_loss           | 0.513     |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 23.9        |\n| time/                   |             |\n|    fps                  | 442         |\n|    iterations           | 128         |\n|    time_elapsed         | 1184        |\n|    total_timesteps      | 524288      |\n| train/                  |             |\n|    approx_kl            | 0.031373985 |\n|    clip_fraction        | 0.346       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.23        |\n|    n_updates            | 508         |\n|    policy_gradient_loss | -0.0133     |\n|    value_loss           | 0.892       |\n-----------------------------------------\nEval num_timesteps=528000, episode_reward=1062.00 +/- 382.12\nEpisode length: 3564.20 +/- 721.13\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.56e+03    |\n|    mean_reward          | 1.06e+03    |\n| time/                   |             |\n|    total_timesteps      | 528000      |\n| train/                  |             |\n|    approx_kl            | 0.038652577 |\n|    clip_fraction        | 0.375       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.915       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.29        |\n|    n_updates            | 512         |\n|    policy_gradient_loss | -0.0202     |\n|    value_loss           | 0.85        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 249      |\n|    ep_rew_mean     | 23.9     |\n| time/              |          |\n|    fps             | 439      |\n|    iterations      | 129      |\n|    time_elapsed    | 1202     |\n|    total_timesteps | 528384   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 251         |\n|    ep_rew_mean          | 24.1        |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 130         |\n|    time_elapsed         | 1209        |\n|    total_timesteps      | 532480      |\n| train/                  |             |\n|    approx_kl            | 0.036526315 |\n|    clip_fraction        | 0.404       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.924       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.132       |\n|    n_updates            | 516         |\n|    policy_gradient_loss | -0.0107     |\n|    value_loss           | 0.811       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 249         |\n|    ep_rew_mean          | 24.7        |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 131         |\n|    time_elapsed         | 1216        |\n|    total_timesteps      | 536576      |\n| train/                  |             |\n|    approx_kl            | 0.036183503 |\n|    clip_fraction        | 0.386       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.938       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.352       |\n|    n_updates            | 520         |\n|    policy_gradient_loss | -0.0184     |\n|    value_loss           | 0.864       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 239         |\n|    ep_rew_mean          | 23.5        |\n| time/                   |             |\n|    fps                  | 441         |\n|    iterations           | 132         |\n|    time_elapsed         | 1224        |\n|    total_timesteps      | 540672      |\n| train/                  |             |\n|    approx_kl            | 0.028769251 |\n|    clip_fraction        | 0.308       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.53       |\n|    explained_variance   | 0.953       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.37        |\n|    n_updates            | 524         |\n|    policy_gradient_loss | -0.0122     |\n|    value_loss           | 0.938       |\n-----------------------------------------\nEval num_timesteps=544000, episode_reward=1698.00 +/- 124.00\nEpisode length: 3748.20 +/- 345.60\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.75e+03    |\n|    mean_reward          | 1.7e+03     |\n| time/                   |             |\n|    total_timesteps      | 544000      |\n| train/                  |             |\n|    approx_kl            | 0.032084618 |\n|    clip_fraction        | 0.337       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.61       |\n|    explained_variance   | 0.944       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.337       |\n|    n_updates            | 528         |\n|    policy_gradient_loss | -0.0197     |\n|    value_loss           | 0.857       |\n-----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 246      |\n|    ep_rew_mean     | 24.8     |\n| time/              |          |\n|    fps             | 438      |\n|    iterations      | 133      |\n|    time_elapsed    | 1242     |\n|    total_timesteps | 544768   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 250         |\n|    ep_rew_mean          | 25.6        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 134         |\n|    time_elapsed         | 1249        |\n|    total_timesteps      | 548864      |\n| train/                  |             |\n|    approx_kl            | 0.035372604 |\n|    clip_fraction        | 0.366       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.121       |\n|    n_updates            | 532         |\n|    policy_gradient_loss | -0.0168     |\n|    value_loss           | 0.697       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 251         |\n|    ep_rew_mean          | 26.1        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 135         |\n|    time_elapsed         | 1257        |\n|    total_timesteps      | 552960      |\n| train/                  |             |\n|    approx_kl            | 0.026713762 |\n|    clip_fraction        | 0.312       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.961       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.156       |\n|    n_updates            | 536         |\n|    policy_gradient_loss | -0.0164     |\n|    value_loss           | 1.01        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 248        |\n|    ep_rew_mean          | 24.9       |\n| time/                   |            |\n|    fps                  | 440        |\n|    iterations           | 136        |\n|    time_elapsed         | 1264       |\n|    total_timesteps      | 557056     |\n| train/                  |            |\n|    approx_kl            | 0.03508866 |\n|    clip_fraction        | 0.368      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.64      |\n|    explained_variance   | 0.945      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.146      |\n|    n_updates            | 540        |\n|    policy_gradient_loss | -0.0196    |\n|    value_loss           | 0.81       |\n----------------------------------------\nEval num_timesteps=560000, episode_reward=1152.00 +/- 164.00\nEpisode length: 2497.00 +/- 331.28\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.5e+03     |\n|    mean_reward          | 1.15e+03    |\n| time/                   |             |\n|    total_timesteps      | 560000      |\n| train/                  |             |\n|    approx_kl            | 0.032730777 |\n|    clip_fraction        | 0.356       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.61       |\n|    explained_variance   | 0.958       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.237       |\n|    n_updates            | 544         |\n|    policy_gradient_loss | -0.0208     |\n|    value_loss           | 0.77        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 254      |\n|    ep_rew_mean     | 26.2     |\n| time/              |          |\n|    fps             | 438      |\n|    iterations      | 137      |\n|    time_elapsed    | 1278     |\n|    total_timesteps | 561152   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 256         |\n|    ep_rew_mean          | 26.8        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 138         |\n|    time_elapsed         | 1285        |\n|    total_timesteps      | 565248      |\n| train/                  |             |\n|    approx_kl            | 0.032812905 |\n|    clip_fraction        | 0.388       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.941       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.449       |\n|    n_updates            | 548         |\n|    policy_gradient_loss | -0.0146     |\n|    value_loss           | 0.731       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 265         |\n|    ep_rew_mean          | 27.6        |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 139         |\n|    time_elapsed         | 1293        |\n|    total_timesteps      | 569344      |\n| train/                  |             |\n|    approx_kl            | 0.030040119 |\n|    clip_fraction        | 0.316       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.48       |\n|    explained_variance   | 0.965       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.648       |\n|    n_updates            | 552         |\n|    policy_gradient_loss | -0.0116     |\n|    value_loss           | 0.904       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 260         |\n|    ep_rew_mean          | 27.8        |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 140         |\n|    time_elapsed         | 1300        |\n|    total_timesteps      | 573440      |\n| train/                  |             |\n|    approx_kl            | 0.038082737 |\n|    clip_fraction        | 0.367       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.73       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.353       |\n|    n_updates            | 556         |\n|    policy_gradient_loss | -0.0223     |\n|    value_loss           | 0.566       |\n-----------------------------------------\nEval num_timesteps=576000, episode_reward=1030.00 +/- 16.73\nEpisode length: 2940.20 +/- 474.22\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.94e+03    |\n|    mean_reward          | 1.03e+03    |\n| time/                   |             |\n|    total_timesteps      | 576000      |\n| train/                  |             |\n|    approx_kl            | 0.030071946 |\n|    clip_fraction        | 0.318       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.55       |\n|    explained_variance   | 0.957       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.418       |\n|    n_updates            | 560         |\n|    policy_gradient_loss | -0.0149     |\n|    value_loss           | 0.881       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 265      |\n|    ep_rew_mean     | 28.7     |\n| time/              |          |\n|    fps             | 438      |\n|    iterations      | 141      |\n|    time_elapsed    | 1316     |\n|    total_timesteps | 577536   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 260         |\n|    ep_rew_mean          | 27.6        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 142         |\n|    time_elapsed         | 1323        |\n|    total_timesteps      | 581632      |\n| train/                  |             |\n|    approx_kl            | 0.031857662 |\n|    clip_fraction        | 0.355       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.194       |\n|    n_updates            | 564         |\n|    policy_gradient_loss | -0.0205     |\n|    value_loss           | 0.672       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 262        |\n|    ep_rew_mean          | 28         |\n| time/                   |            |\n|    fps                  | 440        |\n|    iterations           | 143        |\n|    time_elapsed         | 1330       |\n|    total_timesteps      | 585728     |\n| train/                  |            |\n|    approx_kl            | 0.03018978 |\n|    clip_fraction        | 0.328      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.58      |\n|    explained_variance   | 0.956      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.406      |\n|    n_updates            | 568        |\n|    policy_gradient_loss | -0.0165    |\n|    value_loss           | 0.882      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 261         |\n|    ep_rew_mean          | 29          |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 144         |\n|    time_elapsed         | 1337        |\n|    total_timesteps      | 589824      |\n| train/                  |             |\n|    approx_kl            | 0.036915757 |\n|    clip_fraction        | 0.342       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.924       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.514       |\n|    n_updates            | 572         |\n|    policy_gradient_loss | -0.0105     |\n|    value_loss           | 0.981       |\n-----------------------------------------\nEval num_timesteps=592000, episode_reward=1558.00 +/- 208.65\nEpisode length: 3215.40 +/- 409.22\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.22e+03    |\n|    mean_reward          | 1.56e+03    |\n| time/                   |             |\n|    total_timesteps      | 592000      |\n| train/                  |             |\n|    approx_kl            | 0.025384981 |\n|    clip_fraction        | 0.299       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.96        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.826       |\n|    n_updates            | 576         |\n|    policy_gradient_loss | -0.0133     |\n|    value_loss           | 0.879       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 241      |\n|    ep_rew_mean     | 26.7     |\n| time/              |          |\n|    fps             | 438      |\n|    iterations      | 145      |\n|    time_elapsed    | 1354     |\n|    total_timesteps | 593920   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 248        |\n|    ep_rew_mean          | 28.1       |\n| time/                   |            |\n|    fps                  | 439        |\n|    iterations           | 146        |\n|    time_elapsed         | 1361       |\n|    total_timesteps      | 598016     |\n| train/                  |            |\n|    approx_kl            | 0.02661169 |\n|    clip_fraction        | 0.289      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.46      |\n|    explained_variance   | 0.955      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.31       |\n|    n_updates            | 580        |\n|    policy_gradient_loss | -0.013     |\n|    value_loss           | 1.04       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 237         |\n|    ep_rew_mean          | 26.5        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 147         |\n|    time_elapsed         | 1368        |\n|    total_timesteps      | 602112      |\n| train/                  |             |\n|    approx_kl            | 0.038884804 |\n|    clip_fraction        | 0.378       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.125       |\n|    n_updates            | 584         |\n|    policy_gradient_loss | -0.0188     |\n|    value_loss           | 0.769       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 243         |\n|    ep_rew_mean          | 28.1        |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 148         |\n|    time_elapsed         | 1376        |\n|    total_timesteps      | 606208      |\n| train/                  |             |\n|    approx_kl            | 0.033515096 |\n|    clip_fraction        | 0.357       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.51       |\n|    explained_variance   | 0.954       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0747      |\n|    n_updates            | 588         |\n|    policy_gradient_loss | -0.0133     |\n|    value_loss           | 0.747       |\n-----------------------------------------\nEval num_timesteps=608000, episode_reward=1188.00 +/- 119.73\nEpisode length: 3050.60 +/- 666.38\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.05e+03    |\n|    mean_reward          | 1.19e+03    |\n| time/                   |             |\n|    total_timesteps      | 608000      |\n| train/                  |             |\n|    approx_kl            | 0.032089256 |\n|    clip_fraction        | 0.349       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.94        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.357       |\n|    n_updates            | 592         |\n|    policy_gradient_loss | -0.0171     |\n|    value_loss           | 0.86        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 251      |\n|    ep_rew_mean     | 28.8     |\n| time/              |          |\n|    fps             | 438      |\n|    iterations      | 149      |\n|    time_elapsed    | 1392     |\n|    total_timesteps | 610304   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 252         |\n|    ep_rew_mean          | 28.3        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 150         |\n|    time_elapsed         | 1399        |\n|    total_timesteps      | 614400      |\n| train/                  |             |\n|    approx_kl            | 0.024445798 |\n|    clip_fraction        | 0.316       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.96        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.228       |\n|    n_updates            | 596         |\n|    policy_gradient_loss | -0.0125     |\n|    value_loss           | 0.928       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 264        |\n|    ep_rew_mean          | 29.8       |\n| time/                   |            |\n|    fps                  | 439        |\n|    iterations           | 151        |\n|    time_elapsed         | 1406       |\n|    total_timesteps      | 618496     |\n| train/                  |            |\n|    approx_kl            | 0.03280772 |\n|    clip_fraction        | 0.35       |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.55      |\n|    explained_variance   | 0.956      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.185      |\n|    n_updates            | 600        |\n|    policy_gradient_loss | -0.0177    |\n|    value_loss           | 0.813      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 266         |\n|    ep_rew_mean          | 28.6        |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 152         |\n|    time_elapsed         | 1414        |\n|    total_timesteps      | 622592      |\n| train/                  |             |\n|    approx_kl            | 0.035154037 |\n|    clip_fraction        | 0.37        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.6        |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0495      |\n|    n_updates            | 604         |\n|    policy_gradient_loss | -0.0159     |\n|    value_loss           | 0.688       |\n-----------------------------------------\nEval num_timesteps=624000, episode_reward=1286.00 +/- 212.00\nEpisode length: 3436.20 +/- 38.40\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.44e+03    |\n|    mean_reward          | 1.29e+03    |\n| time/                   |             |\n|    total_timesteps      | 624000      |\n| train/                  |             |\n|    approx_kl            | 0.030082662 |\n|    clip_fraction        | 0.356       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.58       |\n|    explained_variance   | 0.958       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.107       |\n|    n_updates            | 608         |\n|    policy_gradient_loss | -0.018      |\n|    value_loss           | 0.794       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 268      |\n|    ep_rew_mean     | 29.6     |\n| time/              |          |\n|    fps             | 437      |\n|    iterations      | 153      |\n|    time_elapsed    | 1431     |\n|    total_timesteps | 626688   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 259        |\n|    ep_rew_mean          | 28.5       |\n| time/                   |            |\n|    fps                  | 438        |\n|    iterations           | 154        |\n|    time_elapsed         | 1438       |\n|    total_timesteps      | 630784     |\n| train/                  |            |\n|    approx_kl            | 0.02667489 |\n|    clip_fraction        | 0.323      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.54      |\n|    explained_variance   | 0.955      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.226      |\n|    n_updates            | 612        |\n|    policy_gradient_loss | -0.0161    |\n|    value_loss           | 0.873      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 259         |\n|    ep_rew_mean          | 28.6        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 155         |\n|    time_elapsed         | 1445        |\n|    total_timesteps      | 634880      |\n| train/                  |             |\n|    approx_kl            | 0.030994533 |\n|    clip_fraction        | 0.315       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.44       |\n|    explained_variance   | 0.952       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.503       |\n|    n_updates            | 616         |\n|    policy_gradient_loss | -0.0139     |\n|    value_loss           | 0.948       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 261         |\n|    ep_rew_mean          | 28.6        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 156         |\n|    time_elapsed         | 1452        |\n|    total_timesteps      | 638976      |\n| train/                  |             |\n|    approx_kl            | 0.031146744 |\n|    clip_fraction        | 0.354       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.96        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0546      |\n|    n_updates            | 620         |\n|    policy_gradient_loss | -0.0214     |\n|    value_loss           | 0.646       |\n-----------------------------------------\nEval num_timesteps=640000, episode_reward=1444.00 +/- 285.77\nEpisode length: 2866.60 +/- 328.00\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.87e+03   |\n|    mean_reward          | 1.44e+03   |\n| time/                   |            |\n|    total_timesteps      | 640000     |\n| train/                  |            |\n|    approx_kl            | 0.03534787 |\n|    clip_fraction        | 0.355      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.66      |\n|    explained_variance   | 0.959      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.287      |\n|    n_updates            | 624        |\n|    policy_gradient_loss | -0.0148    |\n|    value_loss           | 0.705      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 259      |\n|    ep_rew_mean     | 28.9     |\n| time/              |          |\n|    fps             | 437      |\n|    iterations      | 157      |\n|    time_elapsed    | 1468     |\n|    total_timesteps | 643072   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 27.5        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 158         |\n|    time_elapsed         | 1475        |\n|    total_timesteps      | 647168      |\n| train/                  |             |\n|    approx_kl            | 0.034298792 |\n|    clip_fraction        | 0.372       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.59       |\n|    explained_variance   | 0.952       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.567       |\n|    n_updates            | 628         |\n|    policy_gradient_loss | -0.0157     |\n|    value_loss           | 0.821       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 245         |\n|    ep_rew_mean          | 26.6        |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 159         |\n|    time_elapsed         | 1483        |\n|    total_timesteps      | 651264      |\n| train/                  |             |\n|    approx_kl            | 0.040090583 |\n|    clip_fraction        | 0.382       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.59       |\n|    explained_variance   | 0.932       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.388       |\n|    n_updates            | 632         |\n|    policy_gradient_loss | -0.0143     |\n|    value_loss           | 0.81        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 260        |\n|    ep_rew_mean          | 29.4       |\n| time/                   |            |\n|    fps                  | 439        |\n|    iterations           | 160        |\n|    time_elapsed         | 1490       |\n|    total_timesteps      | 655360     |\n| train/                  |            |\n|    approx_kl            | 0.03058451 |\n|    clip_fraction        | 0.355      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.58      |\n|    explained_variance   | 0.946      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.533      |\n|    n_updates            | 636        |\n|    policy_gradient_loss | -0.0123    |\n|    value_loss           | 1.02       |\n----------------------------------------\nEval num_timesteps=656000, episode_reward=1350.00 +/- 146.97\nEpisode length: 3860.20 +/- 3.92\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.86e+03    |\n|    mean_reward          | 1.35e+03    |\n| time/                   |             |\n|    total_timesteps      | 656000      |\n| train/                  |             |\n|    approx_kl            | 0.035566214 |\n|    clip_fraction        | 0.379       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.216       |\n|    n_updates            | 640         |\n|    policy_gradient_loss | -0.0198     |\n|    value_loss           | 0.704       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 259      |\n|    ep_rew_mean     | 29       |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 161      |\n|    time_elapsed    | 1509     |\n|    total_timesteps | 659456   |\n---------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 254       |\n|    ep_rew_mean          | 28.5      |\n| time/                   |           |\n|    fps                  | 437       |\n|    iterations           | 162       |\n|    time_elapsed         | 1516      |\n|    total_timesteps      | 663552    |\n| train/                  |           |\n|    approx_kl            | 0.0359921 |\n|    clip_fraction        | 0.387     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.59     |\n|    explained_variance   | 0.96      |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.123     |\n|    n_updates            | 644       |\n|    policy_gradient_loss | -0.0157   |\n|    value_loss           | 0.739     |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 255         |\n|    ep_rew_mean          | 28.6        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 163         |\n|    time_elapsed         | 1524        |\n|    total_timesteps      | 667648      |\n| train/                  |             |\n|    approx_kl            | 0.035487026 |\n|    clip_fraction        | 0.394       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.93        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.346       |\n|    n_updates            | 648         |\n|    policy_gradient_loss | -0.0218     |\n|    value_loss           | 0.869       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 253         |\n|    ep_rew_mean          | 28.1        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 164         |\n|    time_elapsed         | 1531        |\n|    total_timesteps      | 671744      |\n| train/                  |             |\n|    approx_kl            | 0.035531923 |\n|    clip_fraction        | 0.378       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.949       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.134       |\n|    n_updates            | 652         |\n|    policy_gradient_loss | -0.0209     |\n|    value_loss           | 0.754       |\n-----------------------------------------\nEval num_timesteps=672000, episode_reward=1338.00 +/- 173.94\nEpisode length: 3039.40 +/- 270.56\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.04e+03    |\n|    mean_reward          | 1.34e+03    |\n| time/                   |             |\n|    total_timesteps      | 672000      |\n| train/                  |             |\n|    approx_kl            | 0.042350527 |\n|    clip_fraction        | 0.348       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.57       |\n|    explained_variance   | 0.944       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.209       |\n|    n_updates            | 656         |\n|    policy_gradient_loss | -0.0272     |\n|    value_loss           | 0.886       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 259      |\n|    ep_rew_mean     | 28.1     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 165      |\n|    time_elapsed    | 1547     |\n|    total_timesteps | 675840   |\n---------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 260       |\n|    ep_rew_mean          | 28.3      |\n| time/                   |           |\n|    fps                  | 437       |\n|    iterations           | 166       |\n|    time_elapsed         | 1555      |\n|    total_timesteps      | 679936    |\n| train/                  |           |\n|    approx_kl            | 0.0348707 |\n|    clip_fraction        | 0.364     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.62     |\n|    explained_variance   | 0.934     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.601     |\n|    n_updates            | 660       |\n|    policy_gradient_loss | -0.0156   |\n|    value_loss           | 1.09      |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 264         |\n|    ep_rew_mean          | 28.5        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 167         |\n|    time_elapsed         | 1562        |\n|    total_timesteps      | 684032      |\n| train/                  |             |\n|    approx_kl            | 0.041188117 |\n|    clip_fraction        | 0.424       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.952       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0935      |\n|    n_updates            | 664         |\n|    policy_gradient_loss | -0.022      |\n|    value_loss           | 0.489       |\n-----------------------------------------\nEval num_timesteps=688000, episode_reward=1214.00 +/- 215.56\nEpisode length: 2599.40 +/- 403.68\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.6e+03    |\n|    mean_reward          | 1.21e+03   |\n| time/                   |            |\n|    total_timesteps      | 688000     |\n| train/                  |            |\n|    approx_kl            | 0.03769041 |\n|    clip_fraction        | 0.348      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.55      |\n|    explained_variance   | 0.956      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.656      |\n|    n_updates            | 668        |\n|    policy_gradient_loss | -0.0174    |\n|    value_loss           | 0.946      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 258      |\n|    ep_rew_mean     | 27.7     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 168      |\n|    time_elapsed    | 1577     |\n|    total_timesteps | 688128   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 253        |\n|    ep_rew_mean          | 27.4       |\n| time/                   |            |\n|    fps                  | 436        |\n|    iterations           | 169        |\n|    time_elapsed         | 1584       |\n|    total_timesteps      | 692224     |\n| train/                  |            |\n|    approx_kl            | 0.04169529 |\n|    clip_fraction        | 0.4        |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.75      |\n|    explained_variance   | 0.931      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.221      |\n|    n_updates            | 672        |\n|    policy_gradient_loss | -0.0206    |\n|    value_loss           | 0.649      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 26.3        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 170         |\n|    time_elapsed         | 1591        |\n|    total_timesteps      | 696320      |\n| train/                  |             |\n|    approx_kl            | 0.030241469 |\n|    clip_fraction        | 0.359       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.47       |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.131       |\n|    n_updates            | 676         |\n|    policy_gradient_loss | -0.0134     |\n|    value_loss           | 0.929       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 241        |\n|    ep_rew_mean          | 26.3       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 171        |\n|    time_elapsed         | 1599       |\n|    total_timesteps      | 700416     |\n| train/                  |            |\n|    approx_kl            | 0.03388145 |\n|    clip_fraction        | 0.356      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.54      |\n|    explained_variance   | 0.94       |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.348      |\n|    n_updates            | 680        |\n|    policy_gradient_loss | -0.00923   |\n|    value_loss           | 1.14       |\n----------------------------------------\nEval num_timesteps=704000, episode_reward=938.00 +/- 37.09\nEpisode length: 2567.40 +/- 72.69\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.57e+03    |\n|    mean_reward          | 938         |\n| time/                   |             |\n|    total_timesteps      | 704000      |\n| train/                  |             |\n|    approx_kl            | 0.042647712 |\n|    clip_fraction        | 0.402       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.922       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.16        |\n|    n_updates            | 684         |\n|    policy_gradient_loss | -0.0158     |\n|    value_loss           | 0.831       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 230      |\n|    ep_rew_mean     | 24.8     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 172      |\n|    time_elapsed    | 1614     |\n|    total_timesteps | 704512   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 219         |\n|    ep_rew_mean          | 24.2        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 173         |\n|    time_elapsed         | 1621        |\n|    total_timesteps      | 708608      |\n| train/                  |             |\n|    approx_kl            | 0.027278416 |\n|    clip_fraction        | 0.331       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.955       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.619       |\n|    n_updates            | 688         |\n|    policy_gradient_loss | -0.0129     |\n|    value_loss           | 0.949       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 226         |\n|    ep_rew_mean          | 26          |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 174         |\n|    time_elapsed         | 1628        |\n|    total_timesteps      | 712704      |\n| train/                  |             |\n|    approx_kl            | 0.035724424 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.949       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.503       |\n|    n_updates            | 692         |\n|    policy_gradient_loss | -0.0177     |\n|    value_loss           | 0.862       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 221         |\n|    ep_rew_mean          | 25.1        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 175         |\n|    time_elapsed         | 1635        |\n|    total_timesteps      | 716800      |\n| train/                  |             |\n|    approx_kl            | 0.035272695 |\n|    clip_fraction        | 0.348       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.61       |\n|    explained_variance   | 0.959       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0753      |\n|    n_updates            | 696         |\n|    policy_gradient_loss | -0.0219     |\n|    value_loss           | 0.773       |\n-----------------------------------------\nEval num_timesteps=720000, episode_reward=1072.00 +/- 62.42\nEpisode length: 2767.40 +/- 549.09\n--------------------------------------\n| eval/                   |          |\n|    mean_ep_length       | 2.77e+03 |\n|    mean_reward          | 1.07e+03 |\n| time/                   |          |\n|    total_timesteps      | 720000   |\n| train/                  |          |\n|    approx_kl            | 0.033498 |\n|    clip_fraction        | 0.341    |\n|    clip_range           | 0.181    |\n|    entropy_loss         | -1.59    |\n|    explained_variance   | 0.956    |\n|    learning_rate        | 0.000228 |\n|    loss                 | 0.356    |\n|    n_updates            | 700      |\n|    policy_gradient_loss | -0.0205  |\n|    value_loss           | 0.822    |\n--------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 231      |\n|    ep_rew_mean     | 26.3     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 176      |\n|    time_elapsed    | 1651     |\n|    total_timesteps | 720896   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 228        |\n|    ep_rew_mean          | 26.1       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 177        |\n|    time_elapsed         | 1658       |\n|    total_timesteps      | 724992     |\n| train/                  |            |\n|    approx_kl            | 0.03497148 |\n|    clip_fraction        | 0.38       |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.62      |\n|    explained_variance   | 0.96       |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.475      |\n|    n_updates            | 704        |\n|    policy_gradient_loss | -0.0159    |\n|    value_loss           | 0.741      |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 246        |\n|    ep_rew_mean          | 27.6       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 178        |\n|    time_elapsed         | 1665       |\n|    total_timesteps      | 729088     |\n| train/                  |            |\n|    approx_kl            | 0.03385455 |\n|    clip_fraction        | 0.356      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.58      |\n|    explained_variance   | 0.957      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.699      |\n|    n_updates            | 708        |\n|    policy_gradient_loss | -0.02      |\n|    value_loss           | 0.861      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 246         |\n|    ep_rew_mean          | 26.9        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 179         |\n|    time_elapsed         | 1672        |\n|    total_timesteps      | 733184      |\n| train/                  |             |\n|    approx_kl            | 0.037148032 |\n|    clip_fraction        | 0.379       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.958       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.239       |\n|    n_updates            | 712         |\n|    policy_gradient_loss | -0.0143     |\n|    value_loss           | 0.653       |\n-----------------------------------------\nEval num_timesteps=736000, episode_reward=1486.00 +/- 612.52\nEpisode length: 2977.00 +/- 231.20\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.98e+03    |\n|    mean_reward          | 1.49e+03    |\n| time/                   |             |\n|    total_timesteps      | 736000      |\n| train/                  |             |\n|    approx_kl            | 0.044555802 |\n|    clip_fraction        | 0.39        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.919       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.326       |\n|    n_updates            | 716         |\n|    policy_gradient_loss | -0.0201     |\n|    value_loss           | 0.935       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 244      |\n|    ep_rew_mean     | 26.3     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 180      |\n|    time_elapsed    | 1688     |\n|    total_timesteps | 737280   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 249        |\n|    ep_rew_mean          | 26.6       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 181        |\n|    time_elapsed         | 1695       |\n|    total_timesteps      | 741376     |\n| train/                  |            |\n|    approx_kl            | 0.04046461 |\n|    clip_fraction        | 0.367      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.61      |\n|    explained_variance   | 0.926      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.187      |\n|    n_updates            | 720        |\n|    policy_gradient_loss | -0.0137    |\n|    value_loss           | 0.891      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 248         |\n|    ep_rew_mean          | 26.2        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 182         |\n|    time_elapsed         | 1702        |\n|    total_timesteps      | 745472      |\n| train/                  |             |\n|    approx_kl            | 0.033924486 |\n|    clip_fraction        | 0.333       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.962       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.353       |\n|    n_updates            | 724         |\n|    policy_gradient_loss | -0.0135     |\n|    value_loss           | 0.974       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 242         |\n|    ep_rew_mean          | 25.5        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 183         |\n|    time_elapsed         | 1709        |\n|    total_timesteps      | 749568      |\n| train/                  |             |\n|    approx_kl            | 0.029233685 |\n|    clip_fraction        | 0.352       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.955       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.565       |\n|    n_updates            | 728         |\n|    policy_gradient_loss | -0.0152     |\n|    value_loss           | 1.01        |\n-----------------------------------------\nEval num_timesteps=752000, episode_reward=1452.00 +/- 177.70\nEpisode length: 3205.80 +/- 276.09\n---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 3.21e+03  |\n|    mean_reward          | 1.45e+03  |\n| time/                   |           |\n|    total_timesteps      | 752000    |\n| train/                  |           |\n|    approx_kl            | 0.0333662 |\n|    clip_fraction        | 0.359     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.61     |\n|    explained_variance   | 0.962     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.0415    |\n|    n_updates            | 732       |\n|    policy_gradient_loss | -0.0209   |\n|    value_loss           | 0.697     |\n---------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 231      |\n|    ep_rew_mean     | 25.3     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 184      |\n|    time_elapsed    | 1726     |\n|    total_timesteps | 753664   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 229         |\n|    ep_rew_mean          | 25.4        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 185         |\n|    time_elapsed         | 1733        |\n|    total_timesteps      | 757760      |\n| train/                  |             |\n|    approx_kl            | 0.036751077 |\n|    clip_fraction        | 0.363       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.5        |\n|    explained_variance   | 0.953       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.354       |\n|    n_updates            | 736         |\n|    policy_gradient_loss | -0.0143     |\n|    value_loss           | 0.985       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 236        |\n|    ep_rew_mean          | 26.8       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 186        |\n|    time_elapsed         | 1740       |\n|    total_timesteps      | 761856     |\n| train/                  |            |\n|    approx_kl            | 0.03370955 |\n|    clip_fraction        | 0.355      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.58      |\n|    explained_variance   | 0.956      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.225      |\n|    n_updates            | 740        |\n|    policy_gradient_loss | -0.0236    |\n|    value_loss           | 0.719      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 26.4        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 187         |\n|    time_elapsed         | 1748        |\n|    total_timesteps      | 765952      |\n| train/                  |             |\n|    approx_kl            | 0.032092236 |\n|    clip_fraction        | 0.348       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.55       |\n|    explained_variance   | 0.958       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.453       |\n|    n_updates            | 744         |\n|    policy_gradient_loss | -0.0198     |\n|    value_loss           | 0.89        |\n-----------------------------------------\nEval num_timesteps=768000, episode_reward=1716.00 +/- 346.62\nEpisode length: 3159.40 +/- 578.87\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.16e+03   |\n|    mean_reward          | 1.72e+03   |\n| time/                   |            |\n|    total_timesteps      | 768000     |\n| train/                  |            |\n|    approx_kl            | 0.04380074 |\n|    clip_fraction        | 0.384      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.58      |\n|    explained_variance   | 0.939      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.272      |\n|    n_updates            | 748        |\n|    policy_gradient_loss | -0.0124    |\n|    value_loss           | 0.858      |\n----------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 241      |\n|    ep_rew_mean     | 28.3     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 188      |\n|    time_elapsed    | 1765     |\n|    total_timesteps | 770048   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 241         |\n|    ep_rew_mean          | 27.8        |\n| time/                   |             |\n|    fps                  | 436         |\n|    iterations           | 189         |\n|    time_elapsed         | 1772        |\n|    total_timesteps      | 774144      |\n| train/                  |             |\n|    approx_kl            | 0.043521672 |\n|    clip_fraction        | 0.408       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.933       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.305       |\n|    n_updates            | 752         |\n|    policy_gradient_loss | -0.0203     |\n|    value_loss           | 0.747       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 243        |\n|    ep_rew_mean          | 28         |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 190        |\n|    time_elapsed         | 1779       |\n|    total_timesteps      | 778240     |\n| train/                  |            |\n|    approx_kl            | 0.03745365 |\n|    clip_fraction        | 0.371      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.52      |\n|    explained_variance   | 0.955      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.179      |\n|    n_updates            | 756        |\n|    policy_gradient_loss | -0.00923   |\n|    value_loss           | 1          |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 235         |\n|    ep_rew_mean          | 26.6        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 191         |\n|    time_elapsed         | 1787        |\n|    total_timesteps      | 782336      |\n| train/                  |             |\n|    approx_kl            | 0.040487945 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.953       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.169       |\n|    n_updates            | 760         |\n|    policy_gradient_loss | -0.0171     |\n|    value_loss           | 0.811       |\n-----------------------------------------\nEval num_timesteps=784000, episode_reward=1424.00 +/- 555.43\nEpisode length: 3202.60 +/- 716.92\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.2e+03     |\n|    mean_reward          | 1.42e+03    |\n| time/                   |             |\n|    total_timesteps      | 784000      |\n| train/                  |             |\n|    approx_kl            | 0.037357137 |\n|    clip_fraction        | 0.335       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.44       |\n|    explained_variance   | 0.959       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.788       |\n|    n_updates            | 764         |\n|    policy_gradient_loss | -0.00915    |\n|    value_loss           | 1.09        |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 237      |\n|    ep_rew_mean     | 27.1     |\n| time/              |          |\n|    fps             | 435      |\n|    iterations      | 192      |\n|    time_elapsed    | 1803     |\n|    total_timesteps | 786432   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 240         |\n|    ep_rew_mean          | 28          |\n| time/                   |             |\n|    fps                  | 436         |\n|    iterations           | 193         |\n|    time_elapsed         | 1811        |\n|    total_timesteps      | 790528      |\n| train/                  |             |\n|    approx_kl            | 0.035463016 |\n|    clip_fraction        | 0.37        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.963       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.263       |\n|    n_updates            | 768         |\n|    policy_gradient_loss | -0.0149     |\n|    value_loss           | 0.721       |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 236       |\n|    ep_rew_mean          | 26.9      |\n| time/                   |           |\n|    fps                  | 436       |\n|    iterations           | 194       |\n|    time_elapsed         | 1818      |\n|    total_timesteps      | 794624    |\n| train/                  |           |\n|    approx_kl            | 0.0378932 |\n|    clip_fraction        | 0.39      |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.64     |\n|    explained_variance   | 0.936     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.189     |\n|    n_updates            | 772       |\n|    policy_gradient_loss | -0.0122   |\n|    value_loss           | 0.734     |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 243         |\n|    ep_rew_mean          | 27.1        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 195         |\n|    time_elapsed         | 1825        |\n|    total_timesteps      | 798720      |\n| train/                  |             |\n|    approx_kl            | 0.032041978 |\n|    clip_fraction        | 0.346       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.54       |\n|    explained_variance   | 0.957       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.422       |\n|    n_updates            | 776         |\n|    policy_gradient_loss | -0.0171     |\n|    value_loss           | 0.875       |\n-----------------------------------------\nEval num_timesteps=800000, episode_reward=1428.00 +/- 275.56\nEpisode length: 2780.20 +/- 636.34\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.78e+03    |\n|    mean_reward          | 1.43e+03    |\n| time/                   |             |\n|    total_timesteps      | 800000      |\n| train/                  |             |\n|    approx_kl            | 0.036394455 |\n|    clip_fraction        | 0.38        |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0961      |\n|    n_updates            | 780         |\n|    policy_gradient_loss | -0.0185     |\n|    value_loss           | 0.815       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 245      |\n|    ep_rew_mean     | 27.8     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 196      |\n|    time_elapsed    | 1840     |\n|    total_timesteps | 802816   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 260         |\n|    ep_rew_mean          | 29.2        |\n| time/                   |             |\n|    fps                  | 436         |\n|    iterations           | 197         |\n|    time_elapsed         | 1848        |\n|    total_timesteps      | 806912      |\n| train/                  |             |\n|    approx_kl            | 0.043240923 |\n|    clip_fraction        | 0.377       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.955       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.325       |\n|    n_updates            | 784         |\n|    policy_gradient_loss | -0.0199     |\n|    value_loss           | 0.886       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 248        |\n|    ep_rew_mean          | 27.4       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 198        |\n|    time_elapsed         | 1855       |\n|    total_timesteps      | 811008     |\n| train/                  |            |\n|    approx_kl            | 0.03877095 |\n|    clip_fraction        | 0.379      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.54      |\n|    explained_variance   | 0.953      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.338      |\n|    n_updates            | 788        |\n|    policy_gradient_loss | -0.0135    |\n|    value_loss           | 0.807      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 245         |\n|    ep_rew_mean          | 26.4        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 199         |\n|    time_elapsed         | 1862        |\n|    total_timesteps      | 815104      |\n| train/                  |             |\n|    approx_kl            | 0.033869833 |\n|    clip_fraction        | 0.392       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.949       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.225       |\n|    n_updates            | 792         |\n|    policy_gradient_loss | -0.0114     |\n|    value_loss           | 0.794       |\n-----------------------------------------\nEval num_timesteps=816000, episode_reward=1364.00 +/- 222.85\nEpisode length: 2685.80 +/- 313.60\n---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 2.69e+03  |\n|    mean_reward          | 1.36e+03  |\n| time/                   |           |\n|    total_timesteps      | 816000    |\n| train/                  |           |\n|    approx_kl            | 0.0401263 |\n|    clip_fraction        | 0.364     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.53     |\n|    explained_variance   | 0.938     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.74      |\n|    n_updates            | 796       |\n|    policy_gradient_loss | -0.0133   |\n|    value_loss           | 1.05      |\n---------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 250      |\n|    ep_rew_mean     | 27.6     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 200      |\n|    time_elapsed    | 1877     |\n|    total_timesteps | 819200   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 243        |\n|    ep_rew_mean          | 26.9       |\n| time/                   |            |\n|    fps                  | 436        |\n|    iterations           | 201        |\n|    time_elapsed         | 1884       |\n|    total_timesteps      | 823296     |\n| train/                  |            |\n|    approx_kl            | 0.04106347 |\n|    clip_fraction        | 0.402      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.68      |\n|    explained_variance   | 0.945      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.305      |\n|    n_updates            | 800        |\n|    policy_gradient_loss | -0.0221    |\n|    value_loss           | 0.591      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 237         |\n|    ep_rew_mean          | 25.8        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 202         |\n|    time_elapsed         | 1892        |\n|    total_timesteps      | 827392      |\n| train/                  |             |\n|    approx_kl            | 0.038135022 |\n|    clip_fraction        | 0.385       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.53       |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.406       |\n|    n_updates            | 804         |\n|    policy_gradient_loss | -0.0174     |\n|    value_loss           | 0.946       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 239        |\n|    ep_rew_mean          | 26.4       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 203        |\n|    time_elapsed         | 1899       |\n|    total_timesteps      | 831488     |\n| train/                  |            |\n|    approx_kl            | 0.03316077 |\n|    clip_fraction        | 0.334      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.54      |\n|    explained_variance   | 0.952      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.463      |\n|    n_updates            | 808        |\n|    policy_gradient_loss | -0.0143    |\n|    value_loss           | 0.99       |\n----------------------------------------\nEval num_timesteps=832000, episode_reward=1112.00 +/- 39.19\nEpisode length: 2085.80 +/- 35.27\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.09e+03    |\n|    mean_reward          | 1.11e+03    |\n| time/                   |             |\n|    total_timesteps      | 832000      |\n| train/                  |             |\n|    approx_kl            | 0.042463444 |\n|    clip_fraction        | 0.386       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.927       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.102       |\n|    n_updates            | 812         |\n|    policy_gradient_loss | -0.0188     |\n|    value_loss           | 0.625       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 238      |\n|    ep_rew_mean     | 25.6     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 204      |\n|    time_elapsed    | 1912     |\n|    total_timesteps | 835584   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 252        |\n|    ep_rew_mean          | 28.3       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 205        |\n|    time_elapsed         | 1920       |\n|    total_timesteps      | 839680     |\n| train/                  |            |\n|    approx_kl            | 0.04012207 |\n|    clip_fraction        | 0.363      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.51      |\n|    explained_variance   | 0.925      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.489      |\n|    n_updates            | 816        |\n|    policy_gradient_loss | -0.0173    |\n|    value_loss           | 1.11       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 238         |\n|    ep_rew_mean          | 25.8        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 206         |\n|    time_elapsed         | 1927        |\n|    total_timesteps      | 843776      |\n| train/                  |             |\n|    approx_kl            | 0.037551377 |\n|    clip_fraction        | 0.365       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.62       |\n|    explained_variance   | 0.953       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.122       |\n|    n_updates            | 820         |\n|    policy_gradient_loss | -0.0214     |\n|    value_loss           | 0.717       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 24.8        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 207         |\n|    time_elapsed         | 1934        |\n|    total_timesteps      | 847872      |\n| train/                  |             |\n|    approx_kl            | 0.039510623 |\n|    clip_fraction        | 0.362       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.54       |\n|    explained_variance   | 0.91        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.44        |\n|    n_updates            | 824         |\n|    policy_gradient_loss | -0.0114     |\n|    value_loss           | 1.02        |\n-----------------------------------------\nEval num_timesteps=848000, episode_reward=1092.00 +/- 58.79\nEpisode length: 2101.80 +/- 35.27\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.1e+03    |\n|    mean_reward          | 1.09e+03   |\n| time/                   |            |\n|    total_timesteps      | 848000     |\n| train/                  |            |\n|    approx_kl            | 0.04106815 |\n|    clip_fraction        | 0.373      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.5       |\n|    explained_variance   | 0.943      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.208      |\n|    n_updates            | 828        |\n|    policy_gradient_loss | -0.0177    |\n|    value_loss           | 0.968      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 243      |\n|    ep_rew_mean     | 26.3     |\n| time/              |          |\n|    fps             | 437      |\n|    iterations      | 208      |\n|    time_elapsed    | 1948     |\n|    total_timesteps | 851968   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 25.4        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 209         |\n|    time_elapsed         | 1955        |\n|    total_timesteps      | 856064      |\n| train/                  |             |\n|    approx_kl            | 0.046816904 |\n|    clip_fraction        | 0.384       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.94        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.23        |\n|    n_updates            | 832         |\n|    policy_gradient_loss | -0.0188     |\n|    value_loss           | 0.765       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 239         |\n|    ep_rew_mean          | 26.1        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 210         |\n|    time_elapsed         | 1962        |\n|    total_timesteps      | 860160      |\n| train/                  |             |\n|    approx_kl            | 0.042935908 |\n|    clip_fraction        | 0.379       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.48       |\n|    explained_variance   | 0.937       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.271       |\n|    n_updates            | 836         |\n|    policy_gradient_loss | -0.0124     |\n|    value_loss           | 1.05        |\n-----------------------------------------\nEval num_timesteps=864000, episode_reward=1634.00 +/- 284.93\nEpisode length: 3345.00 +/- 636.67\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.34e+03    |\n|    mean_reward          | 1.63e+03    |\n| time/                   |             |\n|    total_timesteps      | 864000      |\n| train/                  |             |\n|    approx_kl            | 0.040906377 |\n|    clip_fraction        | 0.423       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.942       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.519       |\n|    n_updates            | 840         |\n|    policy_gradient_loss | -0.0204     |\n|    value_loss           | 0.709       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 220      |\n|    ep_rew_mean     | 24.2     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 211      |\n|    time_elapsed    | 1979     |\n|    total_timesteps | 864256   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 225        |\n|    ep_rew_mean          | 24.8       |\n| time/                   |            |\n|    fps                  | 436        |\n|    iterations           | 212        |\n|    time_elapsed         | 1987       |\n|    total_timesteps      | 868352     |\n| train/                  |            |\n|    approx_kl            | 0.03212692 |\n|    clip_fraction        | 0.356      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.46      |\n|    explained_variance   | 0.946      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.796      |\n|    n_updates            | 844        |\n|    policy_gradient_loss | -0.0173    |\n|    value_loss           | 1.21       |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 215        |\n|    ep_rew_mean          | 23.9       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 213        |\n|    time_elapsed         | 1994       |\n|    total_timesteps      | 872448     |\n| train/                  |            |\n|    approx_kl            | 0.03282146 |\n|    clip_fraction        | 0.344      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.56      |\n|    explained_variance   | 0.956      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.456      |\n|    n_updates            | 848        |\n|    policy_gradient_loss | -0.0176    |\n|    value_loss           | 0.907      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 225         |\n|    ep_rew_mean          | 25.2        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 214         |\n|    time_elapsed         | 2001        |\n|    total_timesteps      | 876544      |\n| train/                  |             |\n|    approx_kl            | 0.038599793 |\n|    clip_fraction        | 0.357       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.49       |\n|    explained_variance   | 0.944       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.351       |\n|    n_updates            | 852         |\n|    policy_gradient_loss | -0.0159     |\n|    value_loss           | 0.898       |\n-----------------------------------------\nEval num_timesteps=880000, episode_reward=1100.00 +/- 46.48\nEpisode length: 2666.60 +/- 273.89\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.67e+03    |\n|    mean_reward          | 1.1e+03     |\n| time/                   |             |\n|    total_timesteps      | 880000      |\n| train/                  |             |\n|    approx_kl            | 0.037426353 |\n|    clip_fraction        | 0.386       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.081       |\n|    n_updates            | 856         |\n|    policy_gradient_loss | -0.0219     |\n|    value_loss           | 0.575       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 227      |\n|    ep_rew_mean     | 26.2     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 215      |\n|    time_elapsed    | 2016     |\n|    total_timesteps | 880640   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 230         |\n|    ep_rew_mean          | 26.2        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 216         |\n|    time_elapsed         | 2024        |\n|    total_timesteps      | 884736      |\n| train/                  |             |\n|    approx_kl            | 0.033842772 |\n|    clip_fraction        | 0.346       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.51       |\n|    explained_variance   | 0.951       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.389       |\n|    n_updates            | 860         |\n|    policy_gradient_loss | -0.0198     |\n|    value_loss           | 0.923       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 234         |\n|    ep_rew_mean          | 26.4        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 217         |\n|    time_elapsed         | 2031        |\n|    total_timesteps      | 888832      |\n| train/                  |             |\n|    approx_kl            | 0.036245756 |\n|    clip_fraction        | 0.358       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.62       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.00672     |\n|    n_updates            | 864         |\n|    policy_gradient_loss | -0.0207     |\n|    value_loss           | 0.715       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 240        |\n|    ep_rew_mean          | 27.5       |\n| time/                   |            |\n|    fps                  | 438        |\n|    iterations           | 218        |\n|    time_elapsed         | 2038       |\n|    total_timesteps      | 892928     |\n| train/                  |            |\n|    approx_kl            | 0.03271504 |\n|    clip_fraction        | 0.357      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.51      |\n|    explained_variance   | 0.938      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.278      |\n|    n_updates            | 868        |\n|    policy_gradient_loss | -0.0162    |\n|    value_loss           | 0.822      |\n----------------------------------------\nEval num_timesteps=896000, episode_reward=1326.00 +/- 182.49\nEpisode length: 2785.00 +/- 420.01\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.78e+03   |\n|    mean_reward          | 1.33e+03   |\n| time/                   |            |\n|    total_timesteps      | 896000     |\n| train/                  |            |\n|    approx_kl            | 0.03550138 |\n|    clip_fraction        | 0.396      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.63      |\n|    explained_variance   | 0.941      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.144      |\n|    n_updates            | 872        |\n|    policy_gradient_loss | -0.0214    |\n|    value_loss           | 0.659      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 247      |\n|    ep_rew_mean     | 28.1     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 219      |\n|    time_elapsed    | 2054     |\n|    total_timesteps | 897024   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 236        |\n|    ep_rew_mean          | 26.5       |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 220        |\n|    time_elapsed         | 2061       |\n|    total_timesteps      | 901120     |\n| train/                  |            |\n|    approx_kl            | 0.03728389 |\n|    clip_fraction        | 0.349      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.55      |\n|    explained_variance   | 0.937      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.543      |\n|    n_updates            | 876        |\n|    policy_gradient_loss | -0.0127    |\n|    value_loss           | 0.988      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 242         |\n|    ep_rew_mean          | 26.1        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 221         |\n|    time_elapsed         | 2068        |\n|    total_timesteps      | 905216      |\n| train/                  |             |\n|    approx_kl            | 0.045552984 |\n|    clip_fraction        | 0.394       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.5        |\n|    explained_variance   | 0.936       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.321       |\n|    n_updates            | 880         |\n|    policy_gradient_loss | -0.0136     |\n|    value_loss           | 1.04        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 241         |\n|    ep_rew_mean          | 26.5        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 222         |\n|    time_elapsed         | 2075        |\n|    total_timesteps      | 909312      |\n| train/                  |             |\n|    approx_kl            | 0.050562568 |\n|    clip_fraction        | 0.406       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.76       |\n|    explained_variance   | 0.913       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.0807      |\n|    n_updates            | 884         |\n|    policy_gradient_loss | -0.019      |\n|    value_loss           | 0.578       |\n-----------------------------------------\nEval num_timesteps=912000, episode_reward=1260.00 +/- 70.14\nEpisode length: 2919.40 +/- 175.67\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.92e+03    |\n|    mean_reward          | 1.26e+03    |\n| time/                   |             |\n|    total_timesteps      | 912000      |\n| train/                  |             |\n|    approx_kl            | 0.036838997 |\n|    clip_fraction        | 0.365       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.57       |\n|    explained_variance   | 0.946       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.246       |\n|    n_updates            | 888         |\n|    policy_gradient_loss | -0.0164     |\n|    value_loss           | 0.803       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 245      |\n|    ep_rew_mean     | 26.2     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 223      |\n|    time_elapsed    | 2091     |\n|    total_timesteps | 913408   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 26.5        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 224         |\n|    time_elapsed         | 2098        |\n|    total_timesteps      | 917504      |\n| train/                  |             |\n|    approx_kl            | 0.032194093 |\n|    clip_fraction        | 0.346       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.952       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.157       |\n|    n_updates            | 892         |\n|    policy_gradient_loss | -0.0142     |\n|    value_loss           | 1.05        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 254        |\n|    ep_rew_mean          | 28         |\n| time/                   |            |\n|    fps                  | 437        |\n|    iterations           | 225        |\n|    time_elapsed         | 2105       |\n|    total_timesteps      | 921600     |\n| train/                  |            |\n|    approx_kl            | 0.03720006 |\n|    clip_fraction        | 0.383      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.75      |\n|    explained_variance   | 0.947      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.124      |\n|    n_updates            | 896        |\n|    policy_gradient_loss | -0.0204    |\n|    value_loss           | 0.663      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 257         |\n|    ep_rew_mean          | 27.5        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 226         |\n|    time_elapsed         | 2113        |\n|    total_timesteps      | 925696      |\n| train/                  |             |\n|    approx_kl            | 0.044295073 |\n|    clip_fraction        | 0.413       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.64       |\n|    explained_variance   | 0.956       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.186       |\n|    n_updates            | 900         |\n|    policy_gradient_loss | -0.0154     |\n|    value_loss           | 0.584       |\n-----------------------------------------\nEval num_timesteps=928000, episode_reward=1122.00 +/- 126.71\nEpisode length: 2605.80 +/- 264.10\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.61e+03    |\n|    mean_reward          | 1.12e+03    |\n| time/                   |             |\n|    total_timesteps      | 928000      |\n| train/                  |             |\n|    approx_kl            | 0.033180606 |\n|    clip_fraction        | 0.389       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.122       |\n|    n_updates            | 904         |\n|    policy_gradient_loss | -0.012      |\n|    value_loss           | 0.919       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 252      |\n|    ep_rew_mean     | 26.8     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 227      |\n|    time_elapsed    | 2128     |\n|    total_timesteps | 929792   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 247         |\n|    ep_rew_mean          | 25.1        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 228         |\n|    time_elapsed         | 2135        |\n|    total_timesteps      | 933888      |\n| train/                  |             |\n|    approx_kl            | 0.039436005 |\n|    clip_fraction        | 0.386       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.915       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.181       |\n|    n_updates            | 908         |\n|    policy_gradient_loss | -0.0205     |\n|    value_loss           | 0.593       |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 243       |\n|    ep_rew_mean          | 24        |\n| time/                   |           |\n|    fps                  | 437       |\n|    iterations           | 229       |\n|    time_elapsed         | 2142      |\n|    total_timesteps      | 937984    |\n| train/                  |           |\n|    approx_kl            | 0.0410152 |\n|    clip_fraction        | 0.384     |\n|    clip_range           | 0.181     |\n|    entropy_loss         | -1.79     |\n|    explained_variance   | 0.886     |\n|    learning_rate        | 0.000228  |\n|    loss                 | 0.161     |\n|    n_updates            | 912       |\n|    policy_gradient_loss | -0.0219   |\n|    value_loss           | 0.708     |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 243         |\n|    ep_rew_mean          | 24.6        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 230         |\n|    time_elapsed         | 2149        |\n|    total_timesteps      | 942080      |\n| train/                  |             |\n|    approx_kl            | 0.036406316 |\n|    clip_fraction        | 0.365       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.914       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.216       |\n|    n_updates            | 916         |\n|    policy_gradient_loss | -0.0131     |\n|    value_loss           | 0.962       |\n-----------------------------------------\nEval num_timesteps=944000, episode_reward=1124.00 +/- 60.86\nEpisode length: 2469.80 +/- 59.78\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.47e+03    |\n|    mean_reward          | 1.12e+03    |\n| time/                   |             |\n|    total_timesteps      | 944000      |\n| train/                  |             |\n|    approx_kl            | 0.035052344 |\n|    clip_fraction        | 0.373       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.64       |\n|    explained_variance   | 0.936       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.545       |\n|    n_updates            | 920         |\n|    policy_gradient_loss | -0.0157     |\n|    value_loss           | 1           |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 230      |\n|    ep_rew_mean     | 22.8     |\n| time/              |          |\n|    fps             | 437      |\n|    iterations      | 231      |\n|    time_elapsed    | 2164     |\n|    total_timesteps | 946176   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 226         |\n|    ep_rew_mean          | 23.1        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 232         |\n|    time_elapsed         | 2171        |\n|    total_timesteps      | 950272      |\n| train/                  |             |\n|    approx_kl            | 0.038890462 |\n|    clip_fraction        | 0.375       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.62       |\n|    explained_variance   | 0.929       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.317       |\n|    n_updates            | 924         |\n|    policy_gradient_loss | -0.0196     |\n|    value_loss           | 0.827       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 227         |\n|    ep_rew_mean          | 23.8        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 233         |\n|    time_elapsed         | 2178        |\n|    total_timesteps      | 954368      |\n| train/                  |             |\n|    approx_kl            | 0.028816354 |\n|    clip_fraction        | 0.332       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.6        |\n|    explained_variance   | 0.955       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.398       |\n|    n_updates            | 928         |\n|    policy_gradient_loss | -0.0137     |\n|    value_loss           | 1.03        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 228        |\n|    ep_rew_mean          | 24.8       |\n| time/                   |            |\n|    fps                  | 438        |\n|    iterations           | 234        |\n|    time_elapsed         | 2185       |\n|    total_timesteps      | 958464     |\n| train/                  |            |\n|    approx_kl            | 0.03391198 |\n|    clip_fraction        | 0.373      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.65      |\n|    explained_variance   | 0.959      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.461      |\n|    n_updates            | 932        |\n|    policy_gradient_loss | -0.0148    |\n|    value_loss           | 0.725      |\n----------------------------------------\nEval num_timesteps=960000, episode_reward=1382.00 +/- 224.71\nEpisode length: 2999.40 +/- 655.03\n----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3e+03      |\n|    mean_reward          | 1.38e+03   |\n| time/                   |            |\n|    total_timesteps      | 960000     |\n| train/                  |            |\n|    approx_kl            | 0.04156613 |\n|    clip_fraction        | 0.386      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.65      |\n|    explained_variance   | 0.932      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.188      |\n|    n_updates            | 936        |\n|    policy_gradient_loss | -0.0153    |\n|    value_loss           | 1          |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 235      |\n|    ep_rew_mean     | 25.3     |\n| time/              |          |\n|    fps             | 437      |\n|    iterations      | 235      |\n|    time_elapsed    | 2201     |\n|    total_timesteps | 962560   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 236         |\n|    ep_rew_mean          | 25.9        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 236         |\n|    time_elapsed         | 2208        |\n|    total_timesteps      | 966656      |\n| train/                  |             |\n|    approx_kl            | 0.046415783 |\n|    clip_fraction        | 0.394       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.936       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.277       |\n|    n_updates            | 940         |\n|    policy_gradient_loss | -0.0174     |\n|    value_loss           | 0.736       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 232        |\n|    ep_rew_mean          | 25.4       |\n| time/                   |            |\n|    fps                  | 438        |\n|    iterations           | 237        |\n|    time_elapsed         | 2216       |\n|    total_timesteps      | 970752     |\n| train/                  |            |\n|    approx_kl            | 0.03866314 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.181      |\n|    entropy_loss         | -1.56      |\n|    explained_variance   | 0.934      |\n|    learning_rate        | 0.000228   |\n|    loss                 | 0.557      |\n|    n_updates            | 944        |\n|    policy_gradient_loss | -0.0163    |\n|    value_loss           | 1.27       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 229         |\n|    ep_rew_mean          | 25          |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 238         |\n|    time_elapsed         | 2223        |\n|    total_timesteps      | 974848      |\n| train/                  |             |\n|    approx_kl            | 0.035953432 |\n|    clip_fraction        | 0.373       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.947       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.341       |\n|    n_updates            | 948         |\n|    policy_gradient_loss | -0.0152     |\n|    value_loss           | 1.06        |\n-----------------------------------------\nEval num_timesteps=976000, episode_reward=1394.00 +/- 281.47\nEpisode length: 3423.40 +/- 495.16\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.42e+03    |\n|    mean_reward          | 1.39e+03    |\n| time/                   |             |\n|    total_timesteps      | 976000      |\n| train/                  |             |\n|    approx_kl            | 0.049121078 |\n|    clip_fraction        | 0.424       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.891       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.26        |\n|    n_updates            | 952         |\n|    policy_gradient_loss | -0.0135     |\n|    value_loss           | 0.939       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 235      |\n|    ep_rew_mean     | 25.5     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 239      |\n|    time_elapsed    | 2240     |\n|    total_timesteps | 978944   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 25.9        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 240         |\n|    time_elapsed         | 2247        |\n|    total_timesteps      | 983040      |\n| train/                  |             |\n|    approx_kl            | 0.047299348 |\n|    clip_fraction        | 0.407       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.918       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.292       |\n|    n_updates            | 956         |\n|    policy_gradient_loss | -0.0182     |\n|    value_loss           | 0.794       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 235         |\n|    ep_rew_mean          | 25.5        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 241         |\n|    time_elapsed         | 2255        |\n|    total_timesteps      | 987136      |\n| train/                  |             |\n|    approx_kl            | 0.030725949 |\n|    clip_fraction        | 0.374       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.66       |\n|    explained_variance   | 0.949       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.152       |\n|    n_updates            | 960         |\n|    policy_gradient_loss | -0.0162     |\n|    value_loss           | 0.76        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 232         |\n|    ep_rew_mean          | 24.9        |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 242         |\n|    time_elapsed         | 2262        |\n|    total_timesteps      | 991232      |\n| train/                  |             |\n|    approx_kl            | 0.031989437 |\n|    clip_fraction        | 0.348       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.69       |\n|    explained_variance   | 0.959       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.726       |\n|    n_updates            | 964         |\n|    policy_gradient_loss | -0.0108     |\n|    value_loss           | 1.01        |\n-----------------------------------------\nEval num_timesteps=992000, episode_reward=1394.00 +/- 352.11\nEpisode length: 2929.00 +/- 444.41\n-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.93e+03    |\n|    mean_reward          | 1.39e+03    |\n| time/                   |             |\n|    total_timesteps      | 992000      |\n| train/                  |             |\n|    approx_kl            | 0.039228596 |\n|    clip_fraction        | 0.384       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.76       |\n|    explained_variance   | 0.926       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.252       |\n|    n_updates            | 968         |\n|    policy_gradient_loss | -0.013      |\n|    value_loss           | 0.911       |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 241      |\n|    ep_rew_mean     | 25.8     |\n| time/              |          |\n|    fps             | 436      |\n|    iterations      | 243      |\n|    time_elapsed    | 2278     |\n|    total_timesteps | 995328   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 237         |\n|    ep_rew_mean          | 24.7        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 244         |\n|    time_elapsed         | 2285        |\n|    total_timesteps      | 999424      |\n| train/                  |             |\n|    approx_kl            | 0.039837316 |\n|    clip_fraction        | 0.406       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.67       |\n|    explained_variance   | 0.923       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.237       |\n|    n_updates            | 972         |\n|    policy_gradient_loss | -0.0242     |\n|    value_loss           | 1.01        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 244         |\n|    ep_rew_mean          | 26.6        |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 245         |\n|    time_elapsed         | 2292        |\n|    total_timesteps      | 1003520     |\n| train/                  |             |\n|    approx_kl            | 0.031764485 |\n|    clip_fraction        | 0.347       |\n|    clip_range           | 0.181       |\n|    entropy_loss         | -1.65       |\n|    explained_variance   | 0.952       |\n|    learning_rate        | 0.000228    |\n|    loss                 | 0.338       |\n|    n_updates            | 976         |\n|    policy_gradient_loss | -0.0157     |\n|    value_loss           | 1.06        |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1,003,520/1,000,000 \u001b[0m [ \u001b[33m0:38:06\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m398 it/s\u001b[0m ]\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">1,003,520/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:38:06</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">398 it/s</span> ]\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"PPO training complete and saved.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"eval_env = make_eval_env()\n\nmean_reward, std_reward = evaluate_policy(\n    ppo_model,\n    eval_env,\n    n_eval_episodes=10,\n    deterministic=True\n)\n\nprint(f\"PPO Evaluation → Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T20:37:12.139145Z","iopub.execute_input":"2025-12-14T20:37:12.139391Z","iopub.status.idle":"2025-12-14T20:37:33.374057Z","shell.execute_reply.started":"2025-12-14T20:37:12.139372Z","shell.execute_reply":"2025-12-14T20:37:33.373464Z"}},"outputs":[{"name":"stdout","text":"PPO Evaluation → Mean reward: 1663.00 ± 364.88\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## DQN (Off-Policy)","metadata":{}},{"cell_type":"code","source":"def objective_dqn(trial):\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True)\n    buffer_size = trial.suggest_categorical(\"buffer_size\", [100000, 200000])\n    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n    exploration_fraction = trial.suggest_float(\"exploration_fraction\", 0.1, 0.3)\n    exploration_final_eps = trial.suggest_float(\"exploration_final_eps\", 0.01, 0.05)\n\n    env = make_atari_env(ENV_NAME, n_envs=4, seed=42)\n    env = VecFrameStack(env, n_stack=N_STACK)\n    env = VecMonitor(env)\n\n    model = DQN(\n        \"CnnPolicy\",\n        env,\n        learning_rate=learning_rate,\n        buffer_size=buffer_size,\n        learning_starts=10000,\n        batch_size=batch_size,\n        gamma=0.99,\n        train_freq=4,\n        target_update_interval=1000,\n        exploration_fraction=exploration_fraction,\n        exploration_final_eps=exploration_final_eps,\n        verbose=0,\n        policy_kwargs={\"normalize_images\": False}\n    )\n\n    model.learn(total_timesteps=100000)\n\n    eval_env = make_atari_env(ENV_NAME, n_envs=1, seed=42)\n    eval_env = VecFrameStack(eval_env, n_stack=N_STACK)\n    mean_reward, _ = evaluate_policy(model, eval_env, n_eval_episodes=10)\n\n    env.close(); eval_env.close()\n    return mean_reward\n\nstudy_dqn = optuna.create_study(direction=\"maximize\", study_name=\"dqn_ms_pacman\")\nstudy_dqn.optimize(objective_dqn, n_trials=N_TRIALS, show_progress_bar=True)\nprint(\"\\nDQN Best hyperparameters:\", study_dqn.best_params)\nprint(\"DQN Best value:\", study_dqn.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T20:37:33.374906Z","iopub.execute_input":"2025-12-14T20:37:33.375296Z","iopub.status.idle":"2025-12-14T21:27:39.680405Z","shell.execute_reply.started":"2025-12-14T20:37:33.375270Z","shell.execute_reply":"2025-12-14T21:27:39.679566Z"}},"outputs":[{"name":"stderr","text":"[I 2025-12-14 20:37:33,379] A new study created in memory with name: dqn_ms_pacman\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb8af4db5bbd4e34a0b0bf4e29866e1a"}},"metadata":{}},{"name":"stdout","text":"[I 2025-12-14 20:40:49,040] Trial 0 finished with value: 419.0 and parameters: {'learning_rate': 8.895566852389869e-05, 'buffer_size': 200000, 'batch_size': 64, 'exploration_fraction': 0.2605032871514573, 'exploration_final_eps': 0.02836338465031056}. Best is trial 0 with value: 419.0.\n[I 2025-12-14 20:44:05,371] Trial 1 finished with value: 305.0 and parameters: {'learning_rate': 0.00030350686418001595, 'buffer_size': 200000, 'batch_size': 64, 'exploration_fraction': 0.22708696888544094, 'exploration_final_eps': 0.024096836801111507}. Best is trial 0 with value: 419.0.\n[I 2025-12-14 20:47:42,085] Trial 2 finished with value: 373.0 and parameters: {'learning_rate': 1.331038487783375e-05, 'buffer_size': 200000, 'batch_size': 128, 'exploration_fraction': 0.12879685909529395, 'exploration_final_eps': 0.049339433087745264}. Best is trial 0 with value: 419.0.\n[I 2025-12-14 20:50:46,553] Trial 3 finished with value: 123.0 and parameters: {'learning_rate': 0.0003848803818384977, 'buffer_size': 200000, 'batch_size': 32, 'exploration_fraction': 0.12248146881824794, 'exploration_final_eps': 0.021773607070762438}. Best is trial 0 with value: 419.0.\n[I 2025-12-14 20:53:50,673] Trial 4 finished with value: 495.0 and parameters: {'learning_rate': 1.553667943174547e-05, 'buffer_size': 100000, 'batch_size': 32, 'exploration_fraction': 0.12962309898616123, 'exploration_final_eps': 0.031820553558664304}. Best is trial 4 with value: 495.0.\n[I 2025-12-14 20:57:29,658] Trial 5 finished with value: 544.0 and parameters: {'learning_rate': 5.842293965013072e-05, 'buffer_size': 100000, 'batch_size': 128, 'exploration_fraction': 0.15023867354532766, 'exploration_final_eps': 0.014410711562144747}. Best is trial 5 with value: 544.0.\n[I 2025-12-14 21:01:11,073] Trial 6 finished with value: 484.0 and parameters: {'learning_rate': 0.0001635695431005914, 'buffer_size': 200000, 'batch_size': 128, 'exploration_fraction': 0.14550747835286465, 'exploration_final_eps': 0.03220286643898815}. Best is trial 5 with value: 544.0.\n[I 2025-12-14 21:04:13,466] Trial 7 finished with value: 142.0 and parameters: {'learning_rate': 1.1733385956648112e-05, 'buffer_size': 100000, 'batch_size': 32, 'exploration_fraction': 0.21748141442605282, 'exploration_final_eps': 0.02691541909353836}. Best is trial 5 with value: 544.0.\n[I 2025-12-14 21:07:28,565] Trial 8 finished with value: 486.0 and parameters: {'learning_rate': 0.00012607218215931435, 'buffer_size': 200000, 'batch_size': 64, 'exploration_fraction': 0.22070690015045524, 'exploration_final_eps': 0.014764937178295346}. Best is trial 5 with value: 544.0.\n[I 2025-12-14 21:10:41,489] Trial 9 finished with value: 333.0 and parameters: {'learning_rate': 7.776269000587608e-05, 'buffer_size': 200000, 'batch_size': 64, 'exploration_fraction': 0.14634576692926948, 'exploration_final_eps': 0.040060304036992365}. Best is trial 5 with value: 544.0.\n[I 2025-12-14 21:14:18,620] Trial 10 finished with value: 358.0 and parameters: {'learning_rate': 3.28461488613246e-05, 'buffer_size': 100000, 'batch_size': 128, 'exploration_fraction': 0.17376846286563016, 'exploration_final_eps': 0.014163752620342567}. Best is trial 5 with value: 544.0.\n[I 2025-12-14 21:17:22,567] Trial 11 finished with value: 700.0 and parameters: {'learning_rate': 3.359589946120624e-05, 'buffer_size': 100000, 'batch_size': 32, 'exploration_fraction': 0.10486210314755481, 'exploration_final_eps': 0.03877171952765678}. Best is trial 11 with value: 700.0.\n[I 2025-12-14 21:21:00,432] Trial 12 finished with value: 358.0 and parameters: {'learning_rate': 3.64175785764804e-05, 'buffer_size': 100000, 'batch_size': 128, 'exploration_fraction': 0.10087730113922527, 'exploration_final_eps': 0.03937794330493852}. Best is trial 11 with value: 700.0.\n[I 2025-12-14 21:24:00,787] Trial 13 finished with value: 70.0 and parameters: {'learning_rate': 3.631704014656851e-05, 'buffer_size': 100000, 'batch_size': 32, 'exploration_fraction': 0.1730013023696948, 'exploration_final_eps': 0.03984713641258283}. Best is trial 11 with value: 700.0.\n[I 2025-12-14 21:27:39,669] Trial 14 finished with value: 642.0 and parameters: {'learning_rate': 4.8962920003375494e-05, 'buffer_size': 100000, 'batch_size': 128, 'exploration_fraction': 0.2992549991732603, 'exploration_final_eps': 0.010588877648038366}. Best is trial 11 with value: 700.0.\n\nDQN Best hyperparameters: {'learning_rate': 3.359589946120624e-05, 'buffer_size': 100000, 'batch_size': 32, 'exploration_fraction': 0.10486210314755481, 'exploration_final_eps': 0.03877171952765678}\nDQN Best value: 700.0\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"print(\"Training DQN...\")\n\ndqn_best_params = study_dqn.best_params\n\n# Need separate env for DQN (can't share with PPO)\ndqn_train_env = make_atari_env(ENV_NAME, n_envs=N_ENVS, seed=42)\ndqn_train_env = VecFrameStack(dqn_train_env, n_stack=N_STACK)\ndqn_train_env = VecMonitor(dqn_train_env)\n\ndqn_model = DQN(\n    \"CnnPolicy\",\n    dqn_train_env,\n    learning_rate=dqn_best_params[\"learning_rate\"],\n    buffer_size=dqn_best_params[\"buffer_size\"],\n    learning_starts=10000,\n    batch_size=dqn_best_params[\"batch_size\"],\n    gamma=0.99,\n    train_freq=4,\n    target_update_interval=1000,\n    exploration_fraction=dqn_best_params[\"exploration_fraction\"],\n    exploration_final_eps=dqn_best_params[\"exploration_final_eps\"],\n    verbose=1,\n    tensorboard_log=\"./logs/optimized/\",\n    policy_kwargs={\"normalize_images\": False}\n)\n\ndqn_eval_callback = EvalCallback(\n    make_eval_env(),\n    best_model_save_path=\"./models/best_dqn/\",\n    log_path=\"./logs/dqn_eval/\",\n    eval_freq=2000,\n    deterministic=True\n)\n\ndqn_model.learn(\n    total_timesteps=TOTAL_TIMESTEPS,\n    callback=[dqn_eval_callback],\n    progress_bar=True,\n    tb_log_name=\"dqn_training\"\n)\n\ndqn_model.save(\"./models/dqn_ms_pacman_final\")\nprint(\"DQN training complete and saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:27:39.682109Z","iopub.execute_input":"2025-12-14T21:27:39.682322Z","iopub.status.idle":"2025-12-14T21:57:36.083089Z","shell.execute_reply.started":"2025-12-14T21:27:39.682305Z","shell.execute_reply":"2025-12-14T21:57:36.082296Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Training DQN...\nUsing cuda device\nWrapping the env in a VecTransposeImage.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 5.65GB > 1.51GB\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Logging to ./logs/optimized/dqn_training_1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x78108ea152d0> != <stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x78108ea39f90>\n  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n","output_type":"stream"},{"name":"stdout","text":"----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 10       |\n|    exploration_rate | 0.986    |\n| time/               |          |\n|    episodes         | 4        |\n|    fps              | 490      |\n|    time_elapsed     | 3        |\n|    total_timesteps  | 1512     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 12.1     |\n|    exploration_rate | 0.984    |\n| time/               |          |\n|    episodes         | 8        |\n|    fps              | 517      |\n|    time_elapsed     | 3        |\n|    total_timesteps  | 1712     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 9.83     |\n|    exploration_rate | 0.976    |\n| time/               |          |\n|    episodes         | 12       |\n|    fps              | 600      |\n|    time_elapsed     | 4        |\n|    total_timesteps  | 2600     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 8.62     |\n|    exploration_rate | 0.972    |\n| time/               |          |\n|    episodes         | 16       |\n|    fps              | 627      |\n|    time_elapsed     | 4        |\n|    total_timesteps  | 3056     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 158      |\n|    ep_rew_mean      | 8.05     |\n|    exploration_rate | 0.967    |\n| time/               |          |\n|    episodes         | 20       |\n|    fps              | 649      |\n|    time_elapsed     | 5        |\n|    total_timesteps  | 3552     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 7.46     |\n|    exploration_rate | 0.961    |\n| time/               |          |\n|    episodes         | 24       |\n|    fps              | 670      |\n|    time_elapsed     | 6        |\n|    total_timesteps  | 4224     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 154      |\n|    ep_rew_mean      | 7.39     |\n|    exploration_rate | 0.955    |\n| time/               |          |\n|    episodes         | 28       |\n|    fps              | 692      |\n|    time_elapsed     | 7        |\n|    total_timesteps  | 4912     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 8        |\n|    exploration_rate | 0.948    |\n| time/               |          |\n|    episodes         | 32       |\n|    fps              | 711      |\n|    time_elapsed     | 7        |\n|    total_timesteps  | 5648     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 154      |\n|    ep_rew_mean      | 8.14     |\n|    exploration_rate | 0.946    |\n| time/               |          |\n|    episodes         | 36       |\n|    fps              | 716      |\n|    time_elapsed     | 8        |\n|    total_timesteps  | 5928     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 150      |\n|    ep_rew_mean      | 8        |\n|    exploration_rate | 0.943    |\n| time/               |          |\n|    episodes         | 40       |\n|    fps              | 723      |\n|    time_elapsed     | 8        |\n|    total_timesteps  | 6264     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 147      |\n|    ep_rew_mean      | 7.66     |\n|    exploration_rate | 0.935    |\n| time/               |          |\n|    episodes         | 44       |\n|    fps              | 736      |\n|    time_elapsed     | 9        |\n|    total_timesteps  | 7112     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 149      |\n|    ep_rew_mean      | 7.83     |\n|    exploration_rate | 0.929    |\n| time/               |          |\n|    episodes         | 48       |\n|    fps              | 743      |\n|    time_elapsed     | 10       |\n|    total_timesteps  | 7696     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 152      |\n|    ep_rew_mean      | 7.88     |\n|    exploration_rate | 0.921    |\n| time/               |          |\n|    episodes         | 52       |\n|    fps              | 754      |\n|    time_elapsed     | 11       |\n|    total_timesteps  | 8616     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 8.09     |\n|    exploration_rate | 0.916    |\n| time/               |          |\n|    episodes         | 56       |\n|    fps              | 760      |\n|    time_elapsed     | 11       |\n|    total_timesteps  | 9112     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 152      |\n|    ep_rew_mean      | 7.72     |\n|    exploration_rate | 0.909    |\n| time/               |          |\n|    episodes         | 60       |\n|    fps              | 764      |\n|    time_elapsed     | 12       |\n|    total_timesteps  | 9896     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 152      |\n|    ep_rew_mean      | 7.59     |\n|    exploration_rate | 0.904    |\n| time/               |          |\n|    episodes         | 64       |\n|    fps              | 764      |\n|    time_elapsed     | 13       |\n|    total_timesteps  | 10432    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.139    |\n|    n_updates        | 13       |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 150      |\n|    ep_rew_mean      | 7.37     |\n|    exploration_rate | 0.899    |\n| time/               |          |\n|    episodes         | 68       |\n|    fps              | 761      |\n|    time_elapsed     | 14       |\n|    total_timesteps  | 11032    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.123    |\n|    n_updates        | 32       |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 7.79     |\n|    exploration_rate | 0.895    |\n| time/               |          |\n|    episodes         | 72       |\n|    fps              | 761      |\n|    time_elapsed     | 15       |\n|    total_timesteps  | 11432    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0758   |\n|    n_updates        | 45       |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 7.74     |\n|    exploration_rate | 0.888    |\n| time/               |          |\n|    episodes         | 76       |\n|    fps              | 760      |\n|    time_elapsed     | 16       |\n|    total_timesteps  | 12192    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.264    |\n|    n_updates        | 68       |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 152      |\n|    ep_rew_mean      | 7.65     |\n|    exploration_rate | 0.884    |\n| time/               |          |\n|    episodes         | 80       |\n|    fps              | 759      |\n|    time_elapsed     | 16       |\n|    total_timesteps  | 12704    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0591   |\n|    n_updates        | 84       |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 151      |\n|    ep_rew_mean      | 7.48     |\n|    exploration_rate | 0.881    |\n| time/               |          |\n|    episodes         | 84       |\n|    fps              | 758      |\n|    time_elapsed     | 17       |\n|    total_timesteps  | 12936    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.105    |\n|    n_updates        | 92       |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 151      |\n|    ep_rew_mean      | 7.56     |\n|    exploration_rate | 0.87     |\n| time/               |          |\n|    episodes         | 88       |\n|    fps              | 757      |\n|    time_elapsed     | 18       |\n|    total_timesteps  | 14136    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0612   |\n|    n_updates        | 129      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 7.7      |\n|    exploration_rate | 0.867    |\n| time/               |          |\n|    episodes         | 92       |\n|    fps              | 757      |\n|    time_elapsed     | 19       |\n|    total_timesteps  | 14552    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 142      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 7.86     |\n|    exploration_rate | 0.857    |\n| time/               |          |\n|    episodes         | 96       |\n|    fps              | 755      |\n|    time_elapsed     | 20       |\n|    total_timesteps  | 15632    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0694   |\n|    n_updates        | 176      |\n----------------------------------\nEval num_timesteps=16000, episode_reward=60.00 +/- 0.00\nEpisode length: 1857.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.86e+03 |\n|    mean_reward      | 60       |\n| rollout/            |          |\n|    exploration_rate | 0.853    |\n| time/               |          |\n|    total_timesteps  | 16000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0446   |\n|    n_updates        | 187      |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 152      |\n|    ep_rew_mean      | 7.71     |\n|    exploration_rate | 0.849    |\n| time/               |          |\n|    episodes         | 100      |\n|    fps              | 612      |\n|    time_elapsed     | 26       |\n|    total_timesteps  | 16424    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.056    |\n|    n_updates        | 201      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 7.76     |\n|    exploration_rate | 0.847    |\n| time/               |          |\n|    episodes         | 104      |\n|    fps              | 614      |\n|    time_elapsed     | 27       |\n|    total_timesteps  | 16696    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.287    |\n|    n_updates        | 209      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 154      |\n|    ep_rew_mean      | 7.67     |\n|    exploration_rate | 0.838    |\n| time/               |          |\n|    episodes         | 108      |\n|    fps              | 620      |\n|    time_elapsed     | 28       |\n|    total_timesteps  | 17720    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.00909  |\n|    n_updates        | 241      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 7.71     |\n|    exploration_rate | 0.832    |\n| time/               |          |\n|    episodes         | 112      |\n|    fps              | 623      |\n|    time_elapsed     | 29       |\n|    total_timesteps  | 18304    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0759   |\n|    n_updates        | 259      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 7.75     |\n|    exploration_rate | 0.826    |\n| time/               |          |\n|    episodes         | 116      |\n|    fps              | 626      |\n|    time_elapsed     | 30       |\n|    total_timesteps  | 18952    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0322   |\n|    n_updates        | 280      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 159      |\n|    ep_rew_mean      | 7.97     |\n|    exploration_rate | 0.817    |\n| time/               |          |\n|    episodes         | 120      |\n|    fps              | 632      |\n|    time_elapsed     | 31       |\n|    total_timesteps  | 19912    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0502   |\n|    n_updates        | 310      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 8.13     |\n|    exploration_rate | 0.812    |\n| time/               |          |\n|    episodes         | 124      |\n|    fps              | 634      |\n|    time_elapsed     | 32       |\n|    total_timesteps  | 20552    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0465   |\n|    n_updates        | 330      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 8.28     |\n|    exploration_rate | 0.806    |\n| time/               |          |\n|    episodes         | 128      |\n|    fps              | 636      |\n|    time_elapsed     | 33       |\n|    total_timesteps  | 21200    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.231    |\n|    n_updates        | 350      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 8.42     |\n|    exploration_rate | 0.799    |\n| time/               |          |\n|    episodes         | 132      |\n|    fps              | 639      |\n|    time_elapsed     | 34       |\n|    total_timesteps  | 21888    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0544   |\n|    n_updates        | 371      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 8.32     |\n|    exploration_rate | 0.797    |\n| time/               |          |\n|    episodes         | 136      |\n|    fps              | 640      |\n|    time_elapsed     | 34       |\n|    total_timesteps  | 22200    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.236    |\n|    n_updates        | 381      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 8.29     |\n|    exploration_rate | 0.788    |\n| time/               |          |\n|    episodes         | 140      |\n|    fps              | 643      |\n|    time_elapsed     | 35       |\n|    total_timesteps  | 23152    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.233    |\n|    n_updates        | 411      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 8.48     |\n|    exploration_rate | 0.782    |\n| time/               |          |\n|    episodes         | 144      |\n|    fps              | 645      |\n|    time_elapsed     | 36       |\n|    total_timesteps  | 23752    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.027    |\n|    n_updates        | 430      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 8.48     |\n|    exploration_rate | 0.775    |\n| time/               |          |\n|    episodes         | 148      |\n|    fps              | 647      |\n|    time_elapsed     | 37       |\n|    total_timesteps  | 24512    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0445   |\n|    n_updates        | 453      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 8.7      |\n|    exploration_rate | 0.77     |\n| time/               |          |\n|    episodes         | 152      |\n|    fps              | 649      |\n|    time_elapsed     | 38       |\n|    total_timesteps  | 25048    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0831   |\n|    n_updates        | 470      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 167      |\n|    ep_rew_mean      | 8.68     |\n|    exploration_rate | 0.761    |\n| time/               |          |\n|    episodes         | 156      |\n|    fps              | 652      |\n|    time_elapsed     | 39       |\n|    total_timesteps  | 26104    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 503      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 8.86     |\n|    exploration_rate | 0.758    |\n| time/               |          |\n|    episodes         | 160      |\n|    fps              | 653      |\n|    time_elapsed     | 40       |\n|    total_timesteps  | 26448    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0344   |\n|    n_updates        | 514      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 8.94     |\n|    exploration_rate | 0.748    |\n| time/               |          |\n|    episodes         | 164      |\n|    fps              | 655      |\n|    time_elapsed     | 41       |\n|    total_timesteps  | 27472    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0251   |\n|    n_updates        | 546      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 9.31     |\n|    exploration_rate | 0.743    |\n| time/               |          |\n|    episodes         | 168      |\n|    fps              | 656      |\n|    time_elapsed     | 42       |\n|    total_timesteps  | 28000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.037    |\n|    n_updates        | 562      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 8.98     |\n|    exploration_rate | 0.736    |\n| time/               |          |\n|    episodes         | 172      |\n|    fps              | 658      |\n|    time_elapsed     | 43       |\n|    total_timesteps  | 28808    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0362   |\n|    n_updates        | 588      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 8.98     |\n|    exploration_rate | 0.733    |\n| time/               |          |\n|    episodes         | 176      |\n|    fps              | 659      |\n|    time_elapsed     | 44       |\n|    total_timesteps  | 29144    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0447   |\n|    n_updates        | 598      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 8.98     |\n|    exploration_rate | 0.726    |\n| time/               |          |\n|    episodes         | 180      |\n|    fps              | 660      |\n|    time_elapsed     | 45       |\n|    total_timesteps  | 29920    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.229    |\n|    n_updates        | 622      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 9.21     |\n|    exploration_rate | 0.721    |\n| time/               |          |\n|    episodes         | 184      |\n|    fps              | 661      |\n|    time_elapsed     | 45       |\n|    total_timesteps  | 30424    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0561   |\n|    n_updates        | 638      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 8.96     |\n|    exploration_rate | 0.717    |\n| time/               |          |\n|    episodes         | 188      |\n|    fps              | 662      |\n|    time_elapsed     | 46       |\n|    total_timesteps  | 30888    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0505   |\n|    n_updates        | 653      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 8.91     |\n|    exploration_rate | 0.711    |\n| time/               |          |\n|    episodes         | 192      |\n|    fps              | 663      |\n|    time_elapsed     | 47       |\n|    total_timesteps  | 31568    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0177   |\n|    n_updates        | 674      |\n----------------------------------\nEval num_timesteps=32000, episode_reward=248.00 +/- 132.27\nEpisode length: 2271.40 +/- 223.39\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.27e+03 |\n|    mean_reward      | 248      |\n| rollout/            |          |\n|    exploration_rate | 0.707    |\n| time/               |          |\n|    total_timesteps  | 32000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0411   |\n|    n_updates        | 687      |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 169      |\n|    ep_rew_mean      | 8.75     |\n|    exploration_rate | 0.705    |\n| time/               |          |\n|    episodes         | 196      |\n|    fps              | 591      |\n|    time_elapsed     | 54       |\n|    total_timesteps  | 32224    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0841   |\n|    n_updates        | 694      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 8.85     |\n|    exploration_rate | 0.7      |\n| time/               |          |\n|    episodes         | 200      |\n|    fps              | 593      |\n|    time_elapsed     | 55       |\n|    total_timesteps  | 32712    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0284   |\n|    n_updates        | 710      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 8.76     |\n|    exploration_rate | 0.694    |\n| time/               |          |\n|    episodes         | 204      |\n|    fps              | 595      |\n|    time_elapsed     | 56       |\n|    total_timesteps  | 33432    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0581   |\n|    n_updates        | 732      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 8.66     |\n|    exploration_rate | 0.689    |\n| time/               |          |\n|    episodes         | 208      |\n|    fps              | 597      |\n|    time_elapsed     | 56       |\n|    total_timesteps  | 33960    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0677   |\n|    n_updates        | 749      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 8.79     |\n|    exploration_rate | 0.684    |\n| time/               |          |\n|    episodes         | 212      |\n|    fps              | 598      |\n|    time_elapsed     | 57       |\n|    total_timesteps  | 34512    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0408   |\n|    n_updates        | 766      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 8.77     |\n|    exploration_rate | 0.676    |\n| time/               |          |\n|    episodes         | 216      |\n|    fps              | 601      |\n|    time_elapsed     | 58       |\n|    total_timesteps  | 35320    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0878   |\n|    n_updates        | 791      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 162      |\n|    ep_rew_mean      | 8.73     |\n|    exploration_rate | 0.672    |\n| time/               |          |\n|    episodes         | 220      |\n|    fps              | 602      |\n|    time_elapsed     | 59       |\n|    total_timesteps  | 35728    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0607   |\n|    n_updates        | 804      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 8.76     |\n|    exploration_rate | 0.667    |\n| time/               |          |\n|    episodes         | 224      |\n|    fps              | 604      |\n|    time_elapsed     | 60       |\n|    total_timesteps  | 36296    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0571   |\n|    n_updates        | 822      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 158      |\n|    ep_rew_mean      | 8.52     |\n|    exploration_rate | 0.662    |\n| time/               |          |\n|    episodes         | 228      |\n|    fps              | 605      |\n|    time_elapsed     | 60       |\n|    total_timesteps  | 36840    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.291    |\n|    n_updates        | 839      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 8.29     |\n|    exploration_rate | 0.658    |\n| time/               |          |\n|    episodes         | 232      |\n|    fps              | 606      |\n|    time_elapsed     | 61       |\n|    total_timesteps  | 37336    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0421   |\n|    n_updates        | 854      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 8.27     |\n|    exploration_rate | 0.652    |\n| time/               |          |\n|    episodes         | 236      |\n|    fps              | 608      |\n|    time_elapsed     | 62       |\n|    total_timesteps  | 37944    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0371   |\n|    n_updates        | 873      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 157      |\n|    ep_rew_mean      | 8.22     |\n|    exploration_rate | 0.644    |\n| time/               |          |\n|    episodes         | 240      |\n|    fps              | 610      |\n|    time_elapsed     | 63       |\n|    total_timesteps  | 38824    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0315   |\n|    n_updates        | 901      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 8.14     |\n|    exploration_rate | 0.64     |\n| time/               |          |\n|    episodes         | 244      |\n|    fps              | 611      |\n|    time_elapsed     | 64       |\n|    total_timesteps  | 39304    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0472   |\n|    n_updates        | 916      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 8.15     |\n|    exploration_rate | 0.635    |\n| time/               |          |\n|    episodes         | 248      |\n|    fps              | 612      |\n|    time_elapsed     | 64       |\n|    total_timesteps  | 39816    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0492   |\n|    n_updates        | 932      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 152      |\n|    ep_rew_mean      | 7.93     |\n|    exploration_rate | 0.625    |\n| time/               |          |\n|    episodes         | 252      |\n|    fps              | 615      |\n|    time_elapsed     | 66       |\n|    total_timesteps  | 40952    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.338    |\n|    n_updates        | 967      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 151      |\n|    ep_rew_mean      | 7.95     |\n|    exploration_rate | 0.621    |\n| time/               |          |\n|    episodes         | 256      |\n|    fps              | 616      |\n|    time_elapsed     | 67       |\n|    total_timesteps  | 41376    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0925   |\n|    n_updates        | 980      |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 8.27     |\n|    exploration_rate | 0.613    |\n| time/               |          |\n|    episodes         | 260      |\n|    fps              | 618      |\n|    time_elapsed     | 68       |\n|    total_timesteps  | 42272    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0212   |\n|    n_updates        | 1008     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 8.42     |\n|    exploration_rate | 0.608    |\n| time/               |          |\n|    episodes         | 264      |\n|    fps              | 619      |\n|    time_elapsed     | 69       |\n|    total_timesteps  | 42736    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0483   |\n|    n_updates        | 1023     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 154      |\n|    ep_rew_mean      | 8.09     |\n|    exploration_rate | 0.601    |\n| time/               |          |\n|    episodes         | 268      |\n|    fps              | 620      |\n|    time_elapsed     | 70       |\n|    total_timesteps  | 43512    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0348   |\n|    n_updates        | 1047     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 8.24     |\n|    exploration_rate | 0.597    |\n| time/               |          |\n|    episodes         | 272      |\n|    fps              | 621      |\n|    time_elapsed     | 70       |\n|    total_timesteps  | 43992    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0536   |\n|    n_updates        | 1062     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 154      |\n|    ep_rew_mean      | 8.41     |\n|    exploration_rate | 0.589    |\n| time/               |          |\n|    episodes         | 276      |\n|    fps              | 623      |\n|    time_elapsed     | 71       |\n|    total_timesteps  | 44864    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0821   |\n|    n_updates        | 1089     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 8.53     |\n|    exploration_rate | 0.582    |\n| time/               |          |\n|    episodes         | 280      |\n|    fps              | 624      |\n|    time_elapsed     | 73       |\n|    total_timesteps  | 45584    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.049    |\n|    n_updates        | 1112     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 8.55     |\n|    exploration_rate | 0.575    |\n| time/               |          |\n|    episodes         | 284      |\n|    fps              | 625      |\n|    time_elapsed     | 74       |\n|    total_timesteps  | 46312    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0686   |\n|    n_updates        | 1135     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 158      |\n|    ep_rew_mean      | 8.91     |\n|    exploration_rate | 0.571    |\n| time/               |          |\n|    episodes         | 288      |\n|    fps              | 626      |\n|    time_elapsed     | 74       |\n|    total_timesteps  | 46824    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.365    |\n|    n_updates        | 1151     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 159      |\n|    ep_rew_mean      | 8.81     |\n|    exploration_rate | 0.563    |\n| time/               |          |\n|    episodes         | 292      |\n|    fps              | 627      |\n|    time_elapsed     | 75       |\n|    total_timesteps  | 47680    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.721    |\n|    n_updates        | 1177     |\n----------------------------------\nEval num_timesteps=48000, episode_reward=290.00 +/- 71.83\nEpisode length: 2327.40 +/- 734.11\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.33e+03 |\n|    mean_reward      | 290      |\n| rollout/            |          |\n|    exploration_rate | 0.56     |\n| time/               |          |\n|    total_timesteps  | 48000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.351    |\n|    n_updates        | 1187     |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 160      |\n|    ep_rew_mean      | 8.79     |\n|    exploration_rate | 0.556    |\n| time/               |          |\n|    episodes         | 296      |\n|    fps              | 582      |\n|    time_elapsed     | 83       |\n|    total_timesteps  | 48464    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0335   |\n|    n_updates        | 1202     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 8.85     |\n|    exploration_rate | 0.553    |\n| time/               |          |\n|    episodes         | 300      |\n|    fps              | 583      |\n|    time_elapsed     | 83       |\n|    total_timesteps  | 48736    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0511   |\n|    n_updates        | 1210     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 8.97     |\n|    exploration_rate | 0.545    |\n| time/               |          |\n|    episodes         | 304      |\n|    fps              | 585      |\n|    time_elapsed     | 84       |\n|    total_timesteps  | 49672    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0513   |\n|    n_updates        | 1240     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 9.11     |\n|    exploration_rate | 0.54     |\n| time/               |          |\n|    episodes         | 308      |\n|    fps              | 586      |\n|    time_elapsed     | 85       |\n|    total_timesteps  | 50136    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.017    |\n|    n_updates        | 1254     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 9.05     |\n|    exploration_rate | 0.536    |\n| time/               |          |\n|    episodes         | 312      |\n|    fps              | 587      |\n|    time_elapsed     | 86       |\n|    total_timesteps  | 50656    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0615   |\n|    n_updates        | 1270     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 9.36     |\n|    exploration_rate | 0.525    |\n| time/               |          |\n|    episodes         | 316      |\n|    fps              | 589      |\n|    time_elapsed     | 87       |\n|    total_timesteps  | 51800    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0402   |\n|    n_updates        | 1306     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 9.46     |\n|    exploration_rate | 0.516    |\n| time/               |          |\n|    episodes         | 320      |\n|    fps              | 591      |\n|    time_elapsed     | 89       |\n|    total_timesteps  | 52816    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.047    |\n|    n_updates        | 1338     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 169      |\n|    ep_rew_mean      | 9.86     |\n|    exploration_rate | 0.512    |\n| time/               |          |\n|    episodes         | 324      |\n|    fps              | 592      |\n|    time_elapsed     | 89       |\n|    total_timesteps  | 53232    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0505   |\n|    n_updates        | 1351     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 10       |\n|    exploration_rate | 0.504    |\n| time/               |          |\n|    episodes         | 328      |\n|    fps              | 593      |\n|    time_elapsed     | 91       |\n|    total_timesteps  | 54056    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0216   |\n|    n_updates        | 1377     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 9.95     |\n|    exploration_rate | 0.498    |\n| time/               |          |\n|    episodes         | 332      |\n|    fps              | 594      |\n|    time_elapsed     | 92       |\n|    total_timesteps  | 54752    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.072    |\n|    n_updates        | 1398     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 10       |\n|    exploration_rate | 0.491    |\n| time/               |          |\n|    episodes         | 336      |\n|    fps              | 596      |\n|    time_elapsed     | 93       |\n|    total_timesteps  | 55488    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0419   |\n|    n_updates        | 1421     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.489    |\n| time/               |          |\n|    episodes         | 340      |\n|    fps              | 596      |\n|    time_elapsed     | 93       |\n|    total_timesteps  | 55792    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0553   |\n|    n_updates        | 1431     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.481    |\n| time/               |          |\n|    episodes         | 344      |\n|    fps              | 597      |\n|    time_elapsed     | 94       |\n|    total_timesteps  | 56656    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0765   |\n|    n_updates        | 1458     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.478    |\n| time/               |          |\n|    episodes         | 348      |\n|    fps              | 598      |\n|    time_elapsed     | 95       |\n|    total_timesteps  | 56944    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.029    |\n|    n_updates        | 1467     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 10.6     |\n|    exploration_rate | 0.471    |\n| time/               |          |\n|    episodes         | 352      |\n|    fps              | 599      |\n|    time_elapsed     | 96       |\n|    total_timesteps  | 57720    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.809    |\n|    n_updates        | 1491     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.463    |\n| time/               |          |\n|    episodes         | 356      |\n|    fps              | 601      |\n|    time_elapsed     | 97       |\n|    total_timesteps  | 58544    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0697   |\n|    n_updates        | 1517     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.458    |\n| time/               |          |\n|    episodes         | 360      |\n|    fps              | 602      |\n|    time_elapsed     | 98       |\n|    total_timesteps  | 59128    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0847   |\n|    n_updates        | 1535     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 169      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.454    |\n| time/               |          |\n|    episodes         | 364      |\n|    fps              | 602      |\n|    time_elapsed     | 98       |\n|    total_timesteps  | 59616    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0357   |\n|    n_updates        | 1550     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 10.7     |\n|    exploration_rate | 0.444    |\n| time/               |          |\n|    episodes         | 368      |\n|    fps              | 604      |\n|    time_elapsed     | 100      |\n|    total_timesteps  | 60616    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0432   |\n|    n_updates        | 1582     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 10.7     |\n|    exploration_rate | 0.44     |\n| time/               |          |\n|    episodes         | 372      |\n|    fps              | 604      |\n|    time_elapsed     | 101      |\n|    total_timesteps  | 61088    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0598   |\n|    n_updates        | 1596     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 10.9     |\n|    exploration_rate | 0.433    |\n| time/               |          |\n|    episodes         | 376      |\n|    fps              | 605      |\n|    time_elapsed     | 102      |\n|    total_timesteps  | 61888    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0343   |\n|    n_updates        | 1621     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 10.8     |\n|    exploration_rate | 0.427    |\n| time/               |          |\n|    episodes         | 380      |\n|    fps              | 606      |\n|    time_elapsed     | 103      |\n|    total_timesteps  | 62512    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0229   |\n|    n_updates        | 1641     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 10.9     |\n|    exploration_rate | 0.423    |\n| time/               |          |\n|    episodes         | 384      |\n|    fps              | 606      |\n|    time_elapsed     | 103      |\n|    total_timesteps  | 62976    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.068    |\n|    n_updates        | 1655     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 167      |\n|    ep_rew_mean      | 10.7     |\n|    exploration_rate | 0.418    |\n| time/               |          |\n|    episodes         | 388      |\n|    fps              | 607      |\n|    time_elapsed     | 104      |\n|    total_timesteps  | 63528    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.145    |\n|    n_updates        | 1673     |\n----------------------------------\nEval num_timesteps=64000, episode_reward=380.00 +/- 95.08\nEpisode length: 2530.60 +/- 218.06\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.53e+03 |\n|    mean_reward      | 380      |\n| rollout/            |          |\n|    exploration_rate | 0.413    |\n| time/               |          |\n|    total_timesteps  | 64000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0293   |\n|    n_updates        | 1687     |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 10.7     |\n|    exploration_rate | 0.413    |\n| time/               |          |\n|    episodes         | 392      |\n|    fps              | 571      |\n|    time_elapsed     | 111      |\n|    total_timesteps  | 64000    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 10.7     |\n|    exploration_rate | 0.408    |\n| time/               |          |\n|    episodes         | 396      |\n|    fps              | 572      |\n|    time_elapsed     | 112      |\n|    total_timesteps  | 64528    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0663   |\n|    n_updates        | 1704     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 10.8     |\n|    exploration_rate | 0.403    |\n| time/               |          |\n|    episodes         | 400      |\n|    fps              | 573      |\n|    time_elapsed     | 113      |\n|    total_timesteps  | 65104    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0834   |\n|    n_updates        | 1722     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 10.6     |\n|    exploration_rate | 0.396    |\n| time/               |          |\n|    episodes         | 404      |\n|    fps              | 574      |\n|    time_elapsed     | 114      |\n|    total_timesteps  | 65912    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0549   |\n|    n_updates        | 1747     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 10.6     |\n|    exploration_rate | 0.392    |\n| time/               |          |\n|    episodes         | 408      |\n|    fps              | 575      |\n|    time_elapsed     | 115      |\n|    total_timesteps  | 66296    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.45     |\n|    n_updates        | 1759     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 10.6     |\n|    exploration_rate | 0.385    |\n| time/               |          |\n|    episodes         | 412      |\n|    fps              | 576      |\n|    time_elapsed     | 116      |\n|    total_timesteps  | 67072    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0575   |\n|    n_updates        | 1783     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 162      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.38     |\n| time/               |          |\n|    episodes         | 416      |\n|    fps              | 576      |\n|    time_elapsed     | 117      |\n|    total_timesteps  | 67664    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0226   |\n|    n_updates        | 1802     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.374    |\n| time/               |          |\n|    episodes         | 420      |\n|    fps              | 578      |\n|    time_elapsed     | 118      |\n|    total_timesteps  | 68304    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.487    |\n|    n_updates        | 1822     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 10.1     |\n|    exploration_rate | 0.369    |\n| time/               |          |\n|    episodes         | 424      |\n|    fps              | 578      |\n|    time_elapsed     | 118      |\n|    total_timesteps  | 68784    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0493   |\n|    n_updates        | 1837     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 157      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.36     |\n| time/               |          |\n|    episodes         | 428      |\n|    fps              | 580      |\n|    time_elapsed     | 120      |\n|    total_timesteps  | 69776    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.474    |\n|    n_updates        | 1868     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.357    |\n| time/               |          |\n|    episodes         | 432      |\n|    fps              | 581      |\n|    time_elapsed     | 120      |\n|    total_timesteps  | 70144    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0451   |\n|    n_updates        | 1879     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 154      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.351    |\n| time/               |          |\n|    episodes         | 436      |\n|    fps              | 582      |\n|    time_elapsed     | 121      |\n|    total_timesteps  | 70816    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0539   |\n|    n_updates        | 1900     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.346    |\n| time/               |          |\n|    episodes         | 440      |\n|    fps              | 582      |\n|    time_elapsed     | 122      |\n|    total_timesteps  | 71376    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0728   |\n|    n_updates        | 1918     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.338    |\n| time/               |          |\n|    episodes         | 444      |\n|    fps              | 583      |\n|    time_elapsed     | 123      |\n|    total_timesteps  | 72240    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.571    |\n|    n_updates        | 1945     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 10.6     |\n|    exploration_rate | 0.335    |\n| time/               |          |\n|    episodes         | 448      |\n|    fps              | 584      |\n|    time_elapsed     | 124      |\n|    total_timesteps  | 72552    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.098    |\n|    n_updates        | 1955     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 156      |\n|    ep_rew_mean      | 10.5     |\n|    exploration_rate | 0.328    |\n| time/               |          |\n|    episodes         | 452      |\n|    fps              | 585      |\n|    time_elapsed     | 125      |\n|    total_timesteps  | 73272    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0277   |\n|    n_updates        | 1977     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 155      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.323    |\n| time/               |          |\n|    episodes         | 456      |\n|    fps              | 585      |\n|    time_elapsed     | 126      |\n|    total_timesteps  | 73880    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.044    |\n|    n_updates        | 1996     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 153      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.314    |\n| time/               |          |\n|    episodes         | 460      |\n|    fps              | 587      |\n|    time_elapsed     | 127      |\n|    total_timesteps  | 74864    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.059    |\n|    n_updates        | 2027     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 151      |\n|    ep_rew_mean      | 10.4     |\n|    exploration_rate | 0.309    |\n| time/               |          |\n|    episodes         | 464      |\n|    fps              | 587      |\n|    time_elapsed     | 128      |\n|    total_timesteps  | 75336    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0818   |\n|    n_updates        | 2042     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 157      |\n|    ep_rew_mean      | 10.9     |\n|    exploration_rate | 0.3      |\n| time/               |          |\n|    episodes         | 468      |\n|    fps              | 589      |\n|    time_elapsed     | 129      |\n|    total_timesteps  | 76392    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0744   |\n|    n_updates        | 2075     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 158      |\n|    ep_rew_mean      | 11.1     |\n|    exploration_rate | 0.289    |\n| time/               |          |\n|    episodes         | 472      |\n|    fps              | 590      |\n|    time_elapsed     | 131      |\n|    total_timesteps  | 77536    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0509   |\n|    n_updates        | 2110     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 160      |\n|    ep_rew_mean      | 11       |\n|    exploration_rate | 0.284    |\n| time/               |          |\n|    episodes         | 476      |\n|    fps              | 591      |\n|    time_elapsed     | 132      |\n|    total_timesteps  | 78072    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.054    |\n|    n_updates        | 2127     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 11.3     |\n|    exploration_rate | 0.28     |\n| time/               |          |\n|    episodes         | 480      |\n|    fps              | 591      |\n|    time_elapsed     | 132      |\n|    total_timesteps  | 78552    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.062    |\n|    n_updates        | 2142     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 11.1     |\n|    exploration_rate | 0.271    |\n| time/               |          |\n|    episodes         | 484      |\n|    fps              | 592      |\n|    time_elapsed     | 134      |\n|    total_timesteps  | 79504    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.562    |\n|    n_updates        | 2172     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 11.3     |\n|    exploration_rate | 0.268    |\n| time/               |          |\n|    episodes         | 488      |\n|    fps              | 593      |\n|    time_elapsed     | 134      |\n|    total_timesteps  | 79840    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.43     |\n|    n_updates        | 2182     |\n----------------------------------\nEval num_timesteps=80000, episode_reward=74.00 +/- 28.00\nEpisode length: 1925.80 +/- 6.40\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.93e+03 |\n|    mean_reward      | 74       |\n| rollout/            |          |\n|    exploration_rate | 0.267    |\n| time/               |          |\n|    total_timesteps  | 80000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0963   |\n|    n_updates        | 2187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 11.4     |\n|    exploration_rate | 0.262    |\n| time/               |          |\n|    episodes         | 492      |\n|    fps              | 573      |\n|    time_elapsed     | 140      |\n|    total_timesteps  | 80552    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0219   |\n|    n_updates        | 2205     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 166      |\n|    ep_rew_mean      | 11.6     |\n|    exploration_rate | 0.257    |\n| time/               |          |\n|    episodes         | 496      |\n|    fps              | 574      |\n|    time_elapsed     | 141      |\n|    total_timesteps  | 81080    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.029    |\n|    n_updates        | 2221     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 11.5     |\n|    exploration_rate | 0.25     |\n| time/               |          |\n|    episodes         | 500      |\n|    fps              | 575      |\n|    time_elapsed     | 142      |\n|    total_timesteps  | 81792    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.041    |\n|    n_updates        | 2243     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 11.8     |\n|    exploration_rate | 0.244    |\n| time/               |          |\n|    episodes         | 504      |\n|    fps              | 575      |\n|    time_elapsed     | 143      |\n|    total_timesteps  | 82480    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.195    |\n|    n_updates        | 2265     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 166      |\n|    ep_rew_mean      | 11.8     |\n|    exploration_rate | 0.238    |\n| time/               |          |\n|    episodes         | 508      |\n|    fps              | 576      |\n|    time_elapsed     | 144      |\n|    total_timesteps  | 83088    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0307   |\n|    n_updates        | 2284     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 166      |\n|    ep_rew_mean      | 11.9     |\n|    exploration_rate | 0.231    |\n| time/               |          |\n|    episodes         | 512      |\n|    fps              | 577      |\n|    time_elapsed     | 145      |\n|    total_timesteps  | 83944    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.523    |\n|    n_updates        | 2311     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 12.1     |\n|    exploration_rate | 0.226    |\n| time/               |          |\n|    episodes         | 516      |\n|    fps              | 578      |\n|    time_elapsed     | 146      |\n|    total_timesteps  | 84424    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0231   |\n|    n_updates        | 2326     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 166      |\n|    ep_rew_mean      | 11.8     |\n|    exploration_rate | 0.223    |\n| time/               |          |\n|    episodes         | 520      |\n|    fps              | 578      |\n|    time_elapsed     | 146      |\n|    total_timesteps  | 84768    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0678   |\n|    n_updates        | 2336     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 11.9     |\n|    exploration_rate | 0.213    |\n| time/               |          |\n|    episodes         | 524      |\n|    fps              | 579      |\n|    time_elapsed     | 148      |\n|    total_timesteps  | 85896    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0465   |\n|    n_updates        | 2372     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 11.9     |\n|    exploration_rate | 0.201    |\n| time/               |          |\n|    episodes         | 528      |\n|    fps              | 581      |\n|    time_elapsed     | 149      |\n|    total_timesteps  | 87160    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0477   |\n|    n_updates        | 2411     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 12.8     |\n|    exploration_rate | 0.197    |\n| time/               |          |\n|    episodes         | 532      |\n|    fps              | 581      |\n|    time_elapsed     | 150      |\n|    total_timesteps  | 87576    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0707   |\n|    n_updates        | 2424     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 13.1     |\n|    exploration_rate | 0.196    |\n| time/               |          |\n|    episodes         | 536      |\n|    fps              | 581      |\n|    time_elapsed     | 150      |\n|    total_timesteps  | 87760    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.087    |\n|    n_updates        | 2430     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 12.6     |\n|    exploration_rate | 0.189    |\n| time/               |          |\n|    episodes         | 540      |\n|    fps              | 582      |\n|    time_elapsed     | 151      |\n|    total_timesteps  | 88504    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0987   |\n|    n_updates        | 2453     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 12.7     |\n|    exploration_rate | 0.183    |\n| time/               |          |\n|    episodes         | 544      |\n|    fps              | 583      |\n|    time_elapsed     | 152      |\n|    total_timesteps  | 89088    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0525   |\n|    n_updates        | 2471     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 12.9     |\n|    exploration_rate | 0.174    |\n| time/               |          |\n|    episodes         | 548      |\n|    fps              | 584      |\n|    time_elapsed     | 154      |\n|    total_timesteps  | 90088    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.601    |\n|    n_updates        | 2503     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 13       |\n|    exploration_rate | 0.172    |\n| time/               |          |\n|    episodes         | 552      |\n|    fps              | 584      |\n|    time_elapsed     | 154      |\n|    total_timesteps  | 90288    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0606   |\n|    n_updates        | 2509     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 13.6     |\n|    exploration_rate | 0.165    |\n| time/               |          |\n|    episodes         | 556      |\n|    fps              | 585      |\n|    time_elapsed     | 155      |\n|    total_timesteps  | 91136    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0251   |\n|    n_updates        | 2535     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 13.6     |\n|    exploration_rate | 0.159    |\n| time/               |          |\n|    episodes         | 560      |\n|    fps              | 586      |\n|    time_elapsed     | 156      |\n|    total_timesteps  | 91752    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.103    |\n|    n_updates        | 2555     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 13.4     |\n|    exploration_rate | 0.157    |\n| time/               |          |\n|    episodes         | 564      |\n|    fps              | 586      |\n|    time_elapsed     | 156      |\n|    total_timesteps  | 91976    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0338   |\n|    n_updates        | 2562     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 166      |\n|    ep_rew_mean      | 12.9     |\n|    exploration_rate | 0.15     |\n| time/               |          |\n|    episodes         | 568      |\n|    fps              | 587      |\n|    time_elapsed     | 157      |\n|    total_timesteps  | 92704    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0519   |\n|    n_updates        | 2584     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 12.6     |\n|    exploration_rate | 0.144    |\n| time/               |          |\n|    episodes         | 572      |\n|    fps              | 588      |\n|    time_elapsed     | 158      |\n|    total_timesteps  | 93400    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0509   |\n|    n_updates        | 2606     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 12.4     |\n|    exploration_rate | 0.139    |\n| time/               |          |\n|    episodes         | 576      |\n|    fps              | 588      |\n|    time_elapsed     | 159      |\n|    total_timesteps  | 93920    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0262   |\n|    n_updates        | 2622     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 158      |\n|    ep_rew_mean      | 12.5     |\n|    exploration_rate | 0.132    |\n| time/               |          |\n|    episodes         | 580      |\n|    fps              | 589      |\n|    time_elapsed     | 160      |\n|    total_timesteps  | 94688    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.632    |\n|    n_updates        | 2646     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 159      |\n|    ep_rew_mean      | 12.7     |\n|    exploration_rate | 0.122    |\n| time/               |          |\n|    episodes         | 584      |\n|    fps              | 590      |\n|    time_elapsed     | 162      |\n|    total_timesteps  | 95744    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0785   |\n|    n_updates        | 2679     |\n----------------------------------\nEval num_timesteps=96000, episode_reward=114.00 +/- 12.00\nEpisode length: 1676.20 +/- 166.40\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.68e+03 |\n|    mean_reward      | 114      |\n| rollout/            |          |\n|    exploration_rate | 0.12     |\n| time/               |          |\n|    total_timesteps  | 96000    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.143    |\n|    n_updates        | 2687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 159      |\n|    ep_rew_mean      | 12.9     |\n|    exploration_rate | 0.119    |\n| time/               |          |\n|    episodes         | 588      |\n|    fps              | 575      |\n|    time_elapsed     | 167      |\n|    total_timesteps  | 96144    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 2692     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 163      |\n|    ep_rew_mean      | 13.2     |\n|    exploration_rate | 0.112    |\n| time/               |          |\n|    episodes         | 592      |\n|    fps              | 576      |\n|    time_elapsed     | 168      |\n|    total_timesteps  | 96832    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0466   |\n|    n_updates        | 2713     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 162      |\n|    ep_rew_mean      | 13       |\n|    exploration_rate | 0.109    |\n| time/               |          |\n|    episodes         | 596      |\n|    fps              | 576      |\n|    time_elapsed     | 168      |\n|    total_timesteps  | 97168    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0651   |\n|    n_updates        | 2724     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 162      |\n|    ep_rew_mean      | 13.1     |\n|    exploration_rate | 0.102    |\n| time/               |          |\n|    episodes         | 600      |\n|    fps              | 577      |\n|    time_elapsed     | 169      |\n|    total_timesteps  | 98016    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.638    |\n|    n_updates        | 2750     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 162      |\n|    ep_rew_mean      | 12.9     |\n|    exploration_rate | 0.0956   |\n| time/               |          |\n|    episodes         | 604      |\n|    fps              | 577      |\n|    time_elapsed     | 170      |\n|    total_timesteps  | 98664    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0794   |\n|    n_updates        | 2771     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 161      |\n|    ep_rew_mean      | 12.8     |\n|    exploration_rate | 0.0853   |\n| time/               |          |\n|    episodes         | 608      |\n|    fps              | 578      |\n|    time_elapsed     | 172      |\n|    total_timesteps  | 99784    |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0809   |\n|    n_updates        | 2806     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 165      |\n|    ep_rew_mean      | 13.4     |\n|    exploration_rate | 0.0789   |\n| time/               |          |\n|    episodes         | 612      |\n|    fps              | 579      |\n|    time_elapsed     | 173      |\n|    total_timesteps  | 100480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0406   |\n|    n_updates        | 2827     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 164      |\n|    ep_rew_mean      | 13.3     |\n|    exploration_rate | 0.0709   |\n| time/               |          |\n|    episodes         | 616      |\n|    fps              | 580      |\n|    time_elapsed     | 174      |\n|    total_timesteps  | 101360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0863   |\n|    n_updates        | 2855     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 13.9     |\n|    exploration_rate | 0.0664   |\n| time/               |          |\n|    episodes         | 620      |\n|    fps              | 580      |\n|    time_elapsed     | 175      |\n|    total_timesteps  | 101848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.629    |\n|    n_updates        | 2870     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 13.9     |\n|    exploration_rate | 0.0583   |\n| time/               |          |\n|    episodes         | 624      |\n|    fps              | 581      |\n|    time_elapsed     | 176      |\n|    total_timesteps  | 102736   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0351   |\n|    n_updates        | 2898     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 14       |\n|    exploration_rate | 0.0523   |\n| time/               |          |\n|    episodes         | 628      |\n|    fps              | 582      |\n|    time_elapsed     | 177      |\n|    total_timesteps  | 103384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.076    |\n|    n_updates        | 2918     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 167      |\n|    ep_rew_mean      | 13.7     |\n|    exploration_rate | 0.0455   |\n| time/               |          |\n|    episodes         | 632      |\n|    fps              | 582      |\n|    time_elapsed     | 178      |\n|    total_timesteps  | 104128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 2941     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 166      |\n|    ep_rew_mean      | 13.3     |\n|    exploration_rate | 0.0412   |\n| time/               |          |\n|    episodes         | 636      |\n|    fps              | 583      |\n|    time_elapsed     | 179      |\n|    total_timesteps  | 104600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0338   |\n|    n_updates        | 2956     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 13.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 640      |\n|    fps              | 583      |\n|    time_elapsed     | 180      |\n|    total_timesteps  | 105440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0601   |\n|    n_updates        | 2982     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 13.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 644      |\n|    fps              | 584      |\n|    time_elapsed     | 181      |\n|    total_timesteps  | 106264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0468   |\n|    n_updates        | 3008     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 13.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 648      |\n|    fps              | 585      |\n|    time_elapsed     | 182      |\n|    total_timesteps  | 106928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 3029     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 14.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 652      |\n|    fps              | 586      |\n|    time_elapsed     | 185      |\n|    total_timesteps  | 108592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.669    |\n|    n_updates        | 3081     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 656      |\n|    fps              | 587      |\n|    time_elapsed     | 186      |\n|    total_timesteps  | 109560   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.043    |\n|    n_updates        | 3111     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 14.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 660      |\n|    fps              | 587      |\n|    time_elapsed     | 187      |\n|    total_timesteps  | 110368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0691   |\n|    n_updates        | 3136     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 664      |\n|    fps              | 588      |\n|    time_elapsed     | 188      |\n|    total_timesteps  | 111160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0442   |\n|    n_updates        | 3161     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 668      |\n|    fps              | 588      |\n|    time_elapsed     | 189      |\n|    total_timesteps  | 111640   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.139    |\n|    n_updates        | 3176     |\n----------------------------------\nEval num_timesteps=112000, episode_reward=140.00 +/- 0.00\nEpisode length: 2204.20 +/- 38.73\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.2e+03  |\n|    mean_reward      | 140      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 112000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 3187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 672      |\n|    fps              | 572      |\n|    time_elapsed     | 197      |\n|    total_timesteps  | 112792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0796   |\n|    n_updates        | 3212     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 676      |\n|    fps              | 573      |\n|    time_elapsed     | 198      |\n|    total_timesteps  | 113760   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 3242     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 680      |\n|    fps              | 573      |\n|    time_elapsed     | 199      |\n|    total_timesteps  | 114376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.031    |\n|    n_updates        | 3262     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 684      |\n|    fps              | 574      |\n|    time_elapsed     | 200      |\n|    total_timesteps  | 114968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0582   |\n|    n_updates        | 3280     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 688      |\n|    fps              | 575      |\n|    time_elapsed     | 201      |\n|    total_timesteps  | 115904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0745   |\n|    n_updates        | 3309     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 692      |\n|    fps              | 575      |\n|    time_elapsed     | 202      |\n|    total_timesteps  | 116512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0365   |\n|    n_updates        | 3328     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 696      |\n|    fps              | 576      |\n|    time_elapsed     | 203      |\n|    total_timesteps  | 117072   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 3346     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 700      |\n|    fps              | 576      |\n|    time_elapsed     | 204      |\n|    total_timesteps  | 118016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0399   |\n|    n_updates        | 3375     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 704      |\n|    fps              | 577      |\n|    time_elapsed     | 205      |\n|    total_timesteps  | 118648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.686    |\n|    n_updates        | 3395     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 708      |\n|    fps              | 578      |\n|    time_elapsed     | 206      |\n|    total_timesteps  | 119608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0793   |\n|    n_updates        | 3425     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 712      |\n|    fps              | 578      |\n|    time_elapsed     | 207      |\n|    total_timesteps  | 120144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0801   |\n|    n_updates        | 3442     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 716      |\n|    fps              | 579      |\n|    time_elapsed     | 209      |\n|    total_timesteps  | 121168   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0483   |\n|    n_updates        | 3474     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 720      |\n|    fps              | 580      |\n|    time_elapsed     | 210      |\n|    total_timesteps  | 122280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.103    |\n|    n_updates        | 3509     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 724      |\n|    fps              | 580      |\n|    time_elapsed     | 211      |\n|    total_timesteps  | 122936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.1      |\n|    n_updates        | 3529     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 728      |\n|    fps              | 581      |\n|    time_elapsed     | 212      |\n|    total_timesteps  | 123488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0393   |\n|    n_updates        | 3546     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 732      |\n|    fps              | 581      |\n|    time_elapsed     | 212      |\n|    total_timesteps  | 123832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.115    |\n|    n_updates        | 3557     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 736      |\n|    fps              | 582      |\n|    time_elapsed     | 213      |\n|    total_timesteps  | 124432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.689    |\n|    n_updates        | 3576     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 740      |\n|    fps              | 582      |\n|    time_elapsed     | 214      |\n|    total_timesteps  | 125104   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.072    |\n|    n_updates        | 3597     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 744      |\n|    fps              | 583      |\n|    time_elapsed     | 216      |\n|    total_timesteps  | 126080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0494   |\n|    n_updates        | 3627     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 748      |\n|    fps              | 583      |\n|    time_elapsed     | 217      |\n|    total_timesteps  | 126952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0345   |\n|    n_updates        | 3655     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 752      |\n|    fps              | 584      |\n|    time_elapsed     | 218      |\n|    total_timesteps  | 127608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0612   |\n|    n_updates        | 3675     |\n----------------------------------\nEval num_timesteps=128000, episode_reward=110.00 +/- 0.00\nEpisode length: 1865.00 +/- 56.34\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.86e+03 |\n|    mean_reward      | 110      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 128000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 3687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 756      |\n|    fps              | 572      |\n|    time_elapsed     | 225      |\n|    total_timesteps  | 128848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.773    |\n|    n_updates        | 3714     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 760      |\n|    fps              | 572      |\n|    time_elapsed     | 225      |\n|    total_timesteps  | 129272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0814   |\n|    n_updates        | 3727     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 764      |\n|    fps              | 573      |\n|    time_elapsed     | 226      |\n|    total_timesteps  | 129944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.721    |\n|    n_updates        | 3748     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 768      |\n|    fps              | 573      |\n|    time_elapsed     | 227      |\n|    total_timesteps  | 130504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0835   |\n|    n_updates        | 3766     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 772      |\n|    fps              | 574      |\n|    time_elapsed     | 228      |\n|    total_timesteps  | 131032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0663   |\n|    n_updates        | 3782     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 14.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 776      |\n|    fps              | 574      |\n|    time_elapsed     | 229      |\n|    total_timesteps  | 131872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.732    |\n|    n_updates        | 3808     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 780      |\n|    fps              | 575      |\n|    time_elapsed     | 230      |\n|    total_timesteps  | 132312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0569   |\n|    n_updates        | 3822     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 14.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 784      |\n|    fps              | 575      |\n|    time_elapsed     | 230      |\n|    total_timesteps  | 132968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 3843     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 14.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 788      |\n|    fps              | 576      |\n|    time_elapsed     | 231      |\n|    total_timesteps  | 133568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0782   |\n|    n_updates        | 3861     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 14.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 792      |\n|    fps              | 576      |\n|    time_elapsed     | 232      |\n|    total_timesteps  | 134264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0884   |\n|    n_updates        | 3883     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 13.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 796      |\n|    fps              | 577      |\n|    time_elapsed     | 233      |\n|    total_timesteps  | 134904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.169    |\n|    n_updates        | 3903     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 13.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 800      |\n|    fps              | 577      |\n|    time_elapsed     | 235      |\n|    total_timesteps  | 135816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.771    |\n|    n_updates        | 3932     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 804      |\n|    fps              | 578      |\n|    time_elapsed     | 236      |\n|    total_timesteps  | 136792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.755    |\n|    n_updates        | 3962     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 14.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 808      |\n|    fps              | 578      |\n|    time_elapsed     | 237      |\n|    total_timesteps  | 137360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.019    |\n|    n_updates        | 3980     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 13.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 812      |\n|    fps              | 579      |\n|    time_elapsed     | 239      |\n|    total_timesteps  | 138512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.46     |\n|    n_updates        | 4016     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 13.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 816      |\n|    fps              | 580      |\n|    time_elapsed     | 240      |\n|    total_timesteps  | 139432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.713    |\n|    n_updates        | 4045     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 14.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 820      |\n|    fps              | 580      |\n|    time_elapsed     | 241      |\n|    total_timesteps  | 140208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.752    |\n|    n_updates        | 4069     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 13.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 824      |\n|    fps              | 581      |\n|    time_elapsed     | 243      |\n|    total_timesteps  | 141304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.769    |\n|    n_updates        | 4103     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 14.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 828      |\n|    fps              | 581      |\n|    time_elapsed     | 243      |\n|    total_timesteps  | 141536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0962   |\n|    n_updates        | 4110     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 14.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 832      |\n|    fps              | 582      |\n|    time_elapsed     | 244      |\n|    total_timesteps  | 142592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0821   |\n|    n_updates        | 4143     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 14.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 836      |\n|    fps              | 582      |\n|    time_elapsed     | 245      |\n|    total_timesteps  | 142920   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0523   |\n|    n_updates        | 4154     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 840      |\n|    fps              | 582      |\n|    time_elapsed     | 246      |\n|    total_timesteps  | 143816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0557   |\n|    n_updates        | 4182     |\n----------------------------------\nEval num_timesteps=144000, episode_reward=96.00 +/- 33.23\nEpisode length: 2098.60 +/- 44.80\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.1e+03  |\n|    mean_reward      | 96       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 144000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0569   |\n|    n_updates        | 4187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 844      |\n|    fps              | 570      |\n|    time_elapsed     | 252      |\n|    total_timesteps  | 144008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0808   |\n|    n_updates        | 4188     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 848      |\n|    fps              | 570      |\n|    time_elapsed     | 254      |\n|    total_timesteps  | 144952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.00746  |\n|    n_updates        | 4217     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 14.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 852      |\n|    fps              | 570      |\n|    time_elapsed     | 254      |\n|    total_timesteps  | 145360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.788    |\n|    n_updates        | 4230     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 14.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 856      |\n|    fps              | 571      |\n|    time_elapsed     | 256      |\n|    total_timesteps  | 146408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0814   |\n|    n_updates        | 4263     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 14.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 860      |\n|    fps              | 571      |\n|    time_elapsed     | 256      |\n|    total_timesteps  | 146720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0584   |\n|    n_updates        | 4272     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 14.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 864      |\n|    fps              | 572      |\n|    time_elapsed     | 258      |\n|    total_timesteps  | 147712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0599   |\n|    n_updates        | 4303     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 868      |\n|    fps              | 572      |\n|    time_elapsed     | 258      |\n|    total_timesteps  | 148216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 4319     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 872      |\n|    fps              | 573      |\n|    time_elapsed     | 259      |\n|    total_timesteps  | 149024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0892   |\n|    n_updates        | 4344     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 876      |\n|    fps              | 573      |\n|    time_elapsed     | 260      |\n|    total_timesteps  | 149440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0578   |\n|    n_updates        | 4357     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 880      |\n|    fps              | 574      |\n|    time_elapsed     | 261      |\n|    total_timesteps  | 150408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.724    |\n|    n_updates        | 4388     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 884      |\n|    fps              | 574      |\n|    time_elapsed     | 262      |\n|    total_timesteps  | 150808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.751    |\n|    n_updates        | 4400     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 888      |\n|    fps              | 575      |\n|    time_elapsed     | 265      |\n|    total_timesteps  | 152608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.797    |\n|    n_updates        | 4456     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 892      |\n|    fps              | 575      |\n|    time_elapsed     | 266      |\n|    total_timesteps  | 153488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.117    |\n|    n_updates        | 4484     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 896      |\n|    fps              | 576      |\n|    time_elapsed     | 267      |\n|    total_timesteps  | 154392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.07     |\n|    n_updates        | 4512     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 900      |\n|    fps              | 576      |\n|    time_elapsed     | 269      |\n|    total_timesteps  | 155160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0477   |\n|    n_updates        | 4536     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 904      |\n|    fps              | 577      |\n|    time_elapsed     | 270      |\n|    total_timesteps  | 156064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0539   |\n|    n_updates        | 4564     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 908      |\n|    fps              | 577      |\n|    time_elapsed     | 270      |\n|    total_timesteps  | 156360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0701   |\n|    n_updates        | 4574     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 912      |\n|    fps              | 577      |\n|    time_elapsed     | 271      |\n|    total_timesteps  | 157064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0593   |\n|    n_updates        | 4596     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 916      |\n|    fps              | 578      |\n|    time_elapsed     | 273      |\n|    total_timesteps  | 157952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 4623     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 920      |\n|    fps              | 578      |\n|    time_elapsed     | 274      |\n|    total_timesteps  | 158576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0699   |\n|    n_updates        | 4643     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 924      |\n|    fps              | 579      |\n|    time_elapsed     | 275      |\n|    total_timesteps  | 159392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0634   |\n|    n_updates        | 4668     |\n----------------------------------\nEval num_timesteps=160000, episode_reward=70.00 +/- 0.00\nEpisode length: 2079.40 +/- 3.20\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.08e+03 |\n|    mean_reward      | 70       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 160000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.14     |\n|    n_updates        | 4687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 928      |\n|    fps              | 568      |\n|    time_elapsed     | 281      |\n|    total_timesteps  | 160176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 4693     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 932      |\n|    fps              | 568      |\n|    time_elapsed     | 283      |\n|    total_timesteps  | 161272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0419   |\n|    n_updates        | 4727     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 936      |\n|    fps              | 569      |\n|    time_elapsed     | 285      |\n|    total_timesteps  | 162384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0214   |\n|    n_updates        | 4762     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 940      |\n|    fps              | 569      |\n|    time_elapsed     | 285      |\n|    total_timesteps  | 162672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0581   |\n|    n_updates        | 4771     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 944      |\n|    fps              | 570      |\n|    time_elapsed     | 286      |\n|    total_timesteps  | 163392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0493   |\n|    n_updates        | 4793     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 948      |\n|    fps              | 570      |\n|    time_elapsed     | 287      |\n|    total_timesteps  | 164072   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0739   |\n|    n_updates        | 4815     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 952      |\n|    fps              | 570      |\n|    time_elapsed     | 288      |\n|    total_timesteps  | 164808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0675   |\n|    n_updates        | 4838     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 956      |\n|    fps              | 571      |\n|    time_elapsed     | 288      |\n|    total_timesteps  | 165040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0652   |\n|    n_updates        | 4845     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 960      |\n|    fps              | 571      |\n|    time_elapsed     | 289      |\n|    total_timesteps  | 165672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.112    |\n|    n_updates        | 4865     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 964      |\n|    fps              | 571      |\n|    time_elapsed     | 290      |\n|    total_timesteps  | 166192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.83     |\n|    n_updates        | 4881     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 968      |\n|    fps              | 572      |\n|    time_elapsed     | 291      |\n|    total_timesteps  | 166992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.933    |\n|    n_updates        | 4906     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 972      |\n|    fps              | 572      |\n|    time_elapsed     | 292      |\n|    total_timesteps  | 167592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0863   |\n|    n_updates        | 4925     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 976      |\n|    fps              | 573      |\n|    time_elapsed     | 294      |\n|    total_timesteps  | 169000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0795   |\n|    n_updates        | 4969     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 980      |\n|    fps              | 573      |\n|    time_elapsed     | 295      |\n|    total_timesteps  | 169344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.087    |\n|    n_updates        | 4979     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 984      |\n|    fps              | 574      |\n|    time_elapsed     | 296      |\n|    total_timesteps  | 170216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0715   |\n|    n_updates        | 5007     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 988      |\n|    fps              | 574      |\n|    time_elapsed     | 297      |\n|    total_timesteps  | 170704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.105    |\n|    n_updates        | 5022     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 992      |\n|    fps              | 575      |\n|    time_elapsed     | 298      |\n|    total_timesteps  | 171656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.905    |\n|    n_updates        | 5052     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 996      |\n|    fps              | 575      |\n|    time_elapsed     | 298      |\n|    total_timesteps  | 171904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0536   |\n|    n_updates        | 5059     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1000     |\n|    fps              | 575      |\n|    time_elapsed     | 300      |\n|    total_timesteps  | 172928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0403   |\n|    n_updates        | 5091     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1004     |\n|    fps              | 576      |\n|    time_elapsed     | 301      |\n|    total_timesteps  | 173424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0861   |\n|    n_updates        | 5107     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1008     |\n|    fps              | 576      |\n|    time_elapsed     | 301      |\n|    total_timesteps  | 173960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0767   |\n|    n_updates        | 5124     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1012     |\n|    fps              | 577      |\n|    time_elapsed     | 303      |\n|    total_timesteps  | 175152   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0922   |\n|    n_updates        | 5161     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1016     |\n|    fps              | 577      |\n|    time_elapsed     | 304      |\n|    total_timesteps  | 175872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.037    |\n|    n_updates        | 5183     |\n----------------------------------\nEval num_timesteps=176000, episode_reward=562.00 +/- 150.25\nEpisode length: 3196.20 +/- 146.78\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 3.2e+03  |\n|    mean_reward      | 562      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 176000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.201    |\n|    n_updates        | 5187     |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1020     |\n|    fps              | 561      |\n|    time_elapsed     | 313      |\n|    total_timesteps  | 176240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0595   |\n|    n_updates        | 5195     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1024     |\n|    fps              | 562      |\n|    time_elapsed     | 314      |\n|    total_timesteps  | 177016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.073    |\n|    n_updates        | 5219     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1028     |\n|    fps              | 562      |\n|    time_elapsed     | 315      |\n|    total_timesteps  | 177632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0903   |\n|    n_updates        | 5238     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1032     |\n|    fps              | 563      |\n|    time_elapsed     | 316      |\n|    total_timesteps  | 178384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0445   |\n|    n_updates        | 5262     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1036     |\n|    fps              | 563      |\n|    time_elapsed     | 318      |\n|    total_timesteps  | 179584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0685   |\n|    n_updates        | 5299     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 171      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1040     |\n|    fps              | 564      |\n|    time_elapsed     | 319      |\n|    total_timesteps  | 180200   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0656   |\n|    n_updates        | 5319     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1044     |\n|    fps              | 564      |\n|    time_elapsed     | 320      |\n|    total_timesteps  | 181048   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.903    |\n|    n_updates        | 5345     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1048     |\n|    fps              | 564      |\n|    time_elapsed     | 321      |\n|    total_timesteps  | 181824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.887    |\n|    n_updates        | 5369     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1052     |\n|    fps              | 565      |\n|    time_elapsed     | 323      |\n|    total_timesteps  | 182680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0516   |\n|    n_updates        | 5396     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1056     |\n|    fps              | 565      |\n|    time_elapsed     | 324      |\n|    total_timesteps  | 183640   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0471   |\n|    n_updates        | 5426     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1060     |\n|    fps              | 566      |\n|    time_elapsed     | 325      |\n|    total_timesteps  | 184208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.925    |\n|    n_updates        | 5444     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1064     |\n|    fps              | 566      |\n|    time_elapsed     | 326      |\n|    total_timesteps  | 185000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0912   |\n|    n_updates        | 5469     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1068     |\n|    fps              | 567      |\n|    time_elapsed     | 327      |\n|    total_timesteps  | 185624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1        |\n|    n_updates        | 5488     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1072     |\n|    fps              | 567      |\n|    time_elapsed     | 328      |\n|    total_timesteps  | 186464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.203    |\n|    n_updates        | 5514     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1076     |\n|    fps              | 567      |\n|    time_elapsed     | 329      |\n|    total_timesteps  | 186952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0369   |\n|    n_updates        | 5530     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1080     |\n|    fps              | 568      |\n|    time_elapsed     | 330      |\n|    total_timesteps  | 187712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.134    |\n|    n_updates        | 5553     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1084     |\n|    fps              | 568      |\n|    time_elapsed     | 331      |\n|    total_timesteps  | 188184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0775   |\n|    n_updates        | 5568     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1088     |\n|    fps              | 568      |\n|    time_elapsed     | 331      |\n|    total_timesteps  | 188792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0496   |\n|    n_updates        | 5587     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1092     |\n|    fps              | 568      |\n|    time_elapsed     | 333      |\n|    total_timesteps  | 189488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.894    |\n|    n_updates        | 5609     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1096     |\n|    fps              | 569      |\n|    time_elapsed     | 333      |\n|    total_timesteps  | 189856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.053    |\n|    n_updates        | 5620     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1100     |\n|    fps              | 569      |\n|    time_elapsed     | 334      |\n|    total_timesteps  | 190584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0724   |\n|    n_updates        | 5643     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1104     |\n|    fps              | 569      |\n|    time_elapsed     | 335      |\n|    total_timesteps  | 191368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0988   |\n|    n_updates        | 5668     |\n----------------------------------\nEval num_timesteps=192000, episode_reward=90.00 +/- 0.00\nEpisode length: 2009.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.01e+03 |\n|    mean_reward      | 90       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 192000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0509   |\n|    n_updates        | 5687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1108     |\n|    fps              | 561      |\n|    time_elapsed     | 342      |\n|    total_timesteps  | 192000   |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1112     |\n|    fps              | 561      |\n|    time_elapsed     | 343      |\n|    total_timesteps  | 193128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0687   |\n|    n_updates        | 5723     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1116     |\n|    fps              | 562      |\n|    time_elapsed     | 344      |\n|    total_timesteps  | 193824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0924   |\n|    n_updates        | 5744     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1120     |\n|    fps              | 562      |\n|    time_elapsed     | 345      |\n|    total_timesteps  | 194472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0486   |\n|    n_updates        | 5765     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1124     |\n|    fps              | 562      |\n|    time_elapsed     | 346      |\n|    total_timesteps  | 195248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0318   |\n|    n_updates        | 5789     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1128     |\n|    fps              | 563      |\n|    time_elapsed     | 348      |\n|    total_timesteps  | 196192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.02     |\n|    n_updates        | 5818     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1132     |\n|    fps              | 563      |\n|    time_elapsed     | 348      |\n|    total_timesteps  | 196664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0941   |\n|    n_updates        | 5833     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1136     |\n|    fps              | 564      |\n|    time_elapsed     | 350      |\n|    total_timesteps  | 198080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0416   |\n|    n_updates        | 5877     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1140     |\n|    fps              | 564      |\n|    time_elapsed     | 351      |\n|    total_timesteps  | 198544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0327   |\n|    n_updates        | 5892     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1144     |\n|    fps              | 565      |\n|    time_elapsed     | 353      |\n|    total_timesteps  | 199504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 5922     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1148     |\n|    fps              | 565      |\n|    time_elapsed     | 353      |\n|    total_timesteps  | 200000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0366   |\n|    n_updates        | 5937     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1152     |\n|    fps              | 565      |\n|    time_elapsed     | 355      |\n|    total_timesteps  | 201016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0664   |\n|    n_updates        | 5969     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1156     |\n|    fps              | 566      |\n|    time_elapsed     | 356      |\n|    total_timesteps  | 201720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0988   |\n|    n_updates        | 5991     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1160     |\n|    fps              | 566      |\n|    time_elapsed     | 357      |\n|    total_timesteps  | 202784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0653   |\n|    n_updates        | 6024     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1164     |\n|    fps              | 567      |\n|    time_elapsed     | 358      |\n|    total_timesteps  | 203544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0594   |\n|    n_updates        | 6048     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1168     |\n|    fps              | 567      |\n|    time_elapsed     | 359      |\n|    total_timesteps  | 204088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0847   |\n|    n_updates        | 6065     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1172     |\n|    fps              | 567      |\n|    time_elapsed     | 361      |\n|    total_timesteps  | 205240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0675   |\n|    n_updates        | 6101     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1176     |\n|    fps              | 568      |\n|    time_elapsed     | 362      |\n|    total_timesteps  | 206120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0998   |\n|    n_updates        | 6129     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1180     |\n|    fps              | 568      |\n|    time_elapsed     | 364      |\n|    total_timesteps  | 207136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.044    |\n|    n_updates        | 6160     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1184     |\n|    fps              | 568      |\n|    time_elapsed     | 364      |\n|    total_timesteps  | 207472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.93     |\n|    n_updates        | 6171     |\n----------------------------------\nEval num_timesteps=208000, episode_reward=70.00 +/- 0.00\nEpisode length: 2121.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.12e+03 |\n|    mean_reward      | 70       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 208000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 6187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1188     |\n|    fps              | 560      |\n|    time_elapsed     | 371      |\n|    total_timesteps  | 208040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0983   |\n|    n_updates        | 6189     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1192     |\n|    fps              | 561      |\n|    time_elapsed     | 371      |\n|    total_timesteps  | 208552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0822   |\n|    n_updates        | 6205     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1196     |\n|    fps              | 561      |\n|    time_elapsed     | 372      |\n|    total_timesteps  | 209120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.1      |\n|    n_updates        | 6222     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1200     |\n|    fps              | 561      |\n|    time_elapsed     | 373      |\n|    total_timesteps  | 209952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0969   |\n|    n_updates        | 6248     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1204     |\n|    fps              | 562      |\n|    time_elapsed     | 375      |\n|    total_timesteps  | 210960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 6280     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1208     |\n|    fps              | 562      |\n|    time_elapsed     | 375      |\n|    total_timesteps  | 211288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0654   |\n|    n_updates        | 6290     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1212     |\n|    fps              | 562      |\n|    time_elapsed     | 377      |\n|    total_timesteps  | 212288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0564   |\n|    n_updates        | 6321     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1216     |\n|    fps              | 563      |\n|    time_elapsed     | 378      |\n|    total_timesteps  | 213040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0836   |\n|    n_updates        | 6345     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1220     |\n|    fps              | 563      |\n|    time_elapsed     | 379      |\n|    total_timesteps  | 213952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 6373     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1224     |\n|    fps              | 564      |\n|    time_elapsed     | 380      |\n|    total_timesteps  | 214640   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0622   |\n|    n_updates        | 6395     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1228     |\n|    fps              | 564      |\n|    time_elapsed     | 382      |\n|    total_timesteps  | 215992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.01     |\n|    n_updates        | 6437     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1232     |\n|    fps              | 564      |\n|    time_elapsed     | 382      |\n|    total_timesteps  | 216184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0653   |\n|    n_updates        | 6443     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1236     |\n|    fps              | 565      |\n|    time_elapsed     | 384      |\n|    total_timesteps  | 217232   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0436   |\n|    n_updates        | 6476     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1240     |\n|    fps              | 565      |\n|    time_elapsed     | 385      |\n|    total_timesteps  | 217800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.082    |\n|    n_updates        | 6494     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1244     |\n|    fps              | 565      |\n|    time_elapsed     | 386      |\n|    total_timesteps  | 218672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.985    |\n|    n_updates        | 6521     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1248     |\n|    fps              | 566      |\n|    time_elapsed     | 386      |\n|    total_timesteps  | 218784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 6524     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1252     |\n|    fps              | 566      |\n|    time_elapsed     | 387      |\n|    total_timesteps  | 219688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.08     |\n|    n_updates        | 6553     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1256     |\n|    fps              | 566      |\n|    time_elapsed     | 388      |\n|    total_timesteps  | 220304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 6572     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1260     |\n|    fps              | 567      |\n|    time_elapsed     | 390      |\n|    total_timesteps  | 221248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0909   |\n|    n_updates        | 6601     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1264     |\n|    fps              | 567      |\n|    time_elapsed     | 391      |\n|    total_timesteps  | 221944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0946   |\n|    n_updates        | 6623     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1268     |\n|    fps              | 567      |\n|    time_elapsed     | 392      |\n|    total_timesteps  | 222688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0891   |\n|    n_updates        | 6646     |\n----------------------------------\nEval num_timesteps=224000, episode_reward=734.00 +/- 284.37\nEpisode length: 2788.20 +/- 712.68\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.79e+03 |\n|    mean_reward      | 734      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 224000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0657   |\n|    n_updates        | 6687     |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1272     |\n|    fps              | 557      |\n|    time_elapsed     | 401      |\n|    total_timesteps  | 224000   |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1276     |\n|    fps              | 558      |\n|    time_elapsed     | 403      |\n|    total_timesteps  | 225008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.205    |\n|    n_updates        | 6719     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1280     |\n|    fps              | 558      |\n|    time_elapsed     | 404      |\n|    total_timesteps  | 226224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0875   |\n|    n_updates        | 6757     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1284     |\n|    fps              | 558      |\n|    time_elapsed     | 405      |\n|    total_timesteps  | 226704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0716   |\n|    n_updates        | 6772     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1288     |\n|    fps              | 559      |\n|    time_elapsed     | 407      |\n|    total_timesteps  | 227712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0811   |\n|    n_updates        | 6803     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1292     |\n|    fps              | 559      |\n|    time_elapsed     | 408      |\n|    total_timesteps  | 228544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0771   |\n|    n_updates        | 6829     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1296     |\n|    fps              | 560      |\n|    time_elapsed     | 409      |\n|    total_timesteps  | 229480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 6859     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1300     |\n|    fps              | 560      |\n|    time_elapsed     | 410      |\n|    total_timesteps  | 230040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.05     |\n|    n_updates        | 6876     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1304     |\n|    fps              | 560      |\n|    time_elapsed     | 411      |\n|    total_timesteps  | 231016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 6907     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1308     |\n|    fps              | 561      |\n|    time_elapsed     | 412      |\n|    total_timesteps  | 231744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 6929     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1312     |\n|    fps              | 561      |\n|    time_elapsed     | 414      |\n|    total_timesteps  | 232872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.199    |\n|    n_updates        | 6965     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1316     |\n|    fps              | 561      |\n|    time_elapsed     | 415      |\n|    total_timesteps  | 233312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0586   |\n|    n_updates        | 6978     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1320     |\n|    fps              | 562      |\n|    time_elapsed     | 416      |\n|    total_timesteps  | 233968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0826   |\n|    n_updates        | 6999     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1324     |\n|    fps              | 562      |\n|    time_elapsed     | 417      |\n|    total_timesteps  | 234672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0831   |\n|    n_updates        | 7021     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1328     |\n|    fps              | 562      |\n|    time_elapsed     | 418      |\n|    total_timesteps  | 235384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.08     |\n|    n_updates        | 7043     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1332     |\n|    fps              | 563      |\n|    time_elapsed     | 419      |\n|    total_timesteps  | 236096   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.146    |\n|    n_updates        | 7065     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1336     |\n|    fps              | 563      |\n|    time_elapsed     | 420      |\n|    total_timesteps  | 237264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.139    |\n|    n_updates        | 7102     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1340     |\n|    fps              | 563      |\n|    time_elapsed     | 421      |\n|    total_timesteps  | 237792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0847   |\n|    n_updates        | 7118     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1344     |\n|    fps              | 564      |\n|    time_elapsed     | 422      |\n|    total_timesteps  | 238400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0315   |\n|    n_updates        | 7137     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1348     |\n|    fps              | 564      |\n|    time_elapsed     | 424      |\n|    total_timesteps  | 239800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.134    |\n|    n_updates        | 7181     |\n----------------------------------\nEval num_timesteps=240000, episode_reward=228.00 +/- 4.00\nEpisode length: 3943.40 +/- 499.20\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 3.94e+03 |\n|    mean_reward      | 228      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 240000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0693   |\n|    n_updates        | 7187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1352     |\n|    fps              | 551      |\n|    time_elapsed     | 436      |\n|    total_timesteps  | 240440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.18     |\n|    n_updates        | 7201     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1356     |\n|    fps              | 551      |\n|    time_elapsed     | 436      |\n|    total_timesteps  | 240944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0779   |\n|    n_updates        | 7217     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1360     |\n|    fps              | 551      |\n|    time_elapsed     | 437      |\n|    total_timesteps  | 241504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0483   |\n|    n_updates        | 7234     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1364     |\n|    fps              | 552      |\n|    time_elapsed     | 439      |\n|    total_timesteps  | 242840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.187    |\n|    n_updates        | 7276     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 211      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1368     |\n|    fps              | 552      |\n|    time_elapsed     | 440      |\n|    total_timesteps  | 243568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0988   |\n|    n_updates        | 7299     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 210      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1372     |\n|    fps              | 552      |\n|    time_elapsed     | 441      |\n|    total_timesteps  | 244288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0639   |\n|    n_updates        | 7321     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1376     |\n|    fps              | 553      |\n|    time_elapsed     | 443      |\n|    total_timesteps  | 245248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0837   |\n|    n_updates        | 7351     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1380     |\n|    fps              | 553      |\n|    time_elapsed     | 443      |\n|    total_timesteps  | 245696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 7365     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1384     |\n|    fps              | 553      |\n|    time_elapsed     | 444      |\n|    total_timesteps  | 246224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0652   |\n|    n_updates        | 7382     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1388     |\n|    fps              | 554      |\n|    time_elapsed     | 445      |\n|    total_timesteps  | 246816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.15     |\n|    n_updates        | 7400     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1392     |\n|    fps              | 554      |\n|    time_elapsed     | 446      |\n|    total_timesteps  | 247696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.061    |\n|    n_updates        | 7428     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1396     |\n|    fps              | 554      |\n|    time_elapsed     | 447      |\n|    total_timesteps  | 248448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0989   |\n|    n_updates        | 7451     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1400     |\n|    fps              | 555      |\n|    time_elapsed     | 448      |\n|    total_timesteps  | 249136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0589   |\n|    n_updates        | 7473     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1404     |\n|    fps              | 555      |\n|    time_elapsed     | 449      |\n|    total_timesteps  | 249896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.1      |\n|    n_updates        | 7497     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1408     |\n|    fps              | 555      |\n|    time_elapsed     | 450      |\n|    total_timesteps  | 250512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.09     |\n|    n_updates        | 7516     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1412     |\n|    fps              | 556      |\n|    time_elapsed     | 451      |\n|    total_timesteps  | 251360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0389   |\n|    n_updates        | 7542     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1416     |\n|    fps              | 556      |\n|    time_elapsed     | 452      |\n|    total_timesteps  | 251680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1        |\n|    n_updates        | 7552     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1420     |\n|    fps              | 556      |\n|    time_elapsed     | 454      |\n|    total_timesteps  | 252928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.125    |\n|    n_updates        | 7591     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1424     |\n|    fps              | 556      |\n|    time_elapsed     | 454      |\n|    total_timesteps  | 253144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.243    |\n|    n_updates        | 7598     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1428     |\n|    fps              | 557      |\n|    time_elapsed     | 455      |\n|    total_timesteps  | 253680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0801   |\n|    n_updates        | 7615     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1432     |\n|    fps              | 557      |\n|    time_elapsed     | 456      |\n|    total_timesteps  | 254600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 7644     |\n----------------------------------\nEval num_timesteps=256000, episode_reward=420.00 +/- 74.30\nEpisode length: 2285.80 +/- 141.36\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.29e+03 |\n|    mean_reward      | 420      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 256000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0986   |\n|    n_updates        | 7687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1436     |\n|    fps              | 550      |\n|    time_elapsed     | 464      |\n|    total_timesteps  | 256088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0886   |\n|    n_updates        | 7690     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1440     |\n|    fps              | 551      |\n|    time_elapsed     | 465      |\n|    total_timesteps  | 256504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.07     |\n|    n_updates        | 7703     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1444     |\n|    fps              | 551      |\n|    time_elapsed     | 467      |\n|    total_timesteps  | 257704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 7741     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1448     |\n|    fps              | 551      |\n|    time_elapsed     | 467      |\n|    total_timesteps  | 258144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.01     |\n|    n_updates        | 7754     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1452     |\n|    fps              | 552      |\n|    time_elapsed     | 468      |\n|    total_timesteps  | 258808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 7775     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1456     |\n|    fps              | 552      |\n|    time_elapsed     | 469      |\n|    total_timesteps  | 259624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.17     |\n|    n_updates        | 7801     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1460     |\n|    fps              | 552      |\n|    time_elapsed     | 471      |\n|    total_timesteps  | 260648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.05     |\n|    n_updates        | 7833     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1464     |\n|    fps              | 553      |\n|    time_elapsed     | 472      |\n|    total_timesteps  | 261160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0637   |\n|    n_updates        | 7849     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1468     |\n|    fps              | 553      |\n|    time_elapsed     | 473      |\n|    total_timesteps  | 262240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0898   |\n|    n_updates        | 7882     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1472     |\n|    fps              | 553      |\n|    time_elapsed     | 474      |\n|    total_timesteps  | 262752   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0392   |\n|    n_updates        | 7898     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1476     |\n|    fps              | 554      |\n|    time_elapsed     | 475      |\n|    total_timesteps  | 263544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 7923     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1480     |\n|    fps              | 554      |\n|    time_elapsed     | 476      |\n|    total_timesteps  | 264216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.103    |\n|    n_updates        | 7944     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1484     |\n|    fps              | 554      |\n|    time_elapsed     | 477      |\n|    total_timesteps  | 265120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0765   |\n|    n_updates        | 7972     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1488     |\n|    fps              | 555      |\n|    time_elapsed     | 478      |\n|    total_timesteps  | 265728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.074    |\n|    n_updates        | 7991     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1492     |\n|    fps              | 555      |\n|    time_elapsed     | 479      |\n|    total_timesteps  | 266288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.103    |\n|    n_updates        | 8009     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1496     |\n|    fps              | 555      |\n|    time_elapsed     | 480      |\n|    total_timesteps  | 267176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0653   |\n|    n_updates        | 8037     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1500     |\n|    fps              | 556      |\n|    time_elapsed     | 481      |\n|    total_timesteps  | 267912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0922   |\n|    n_updates        | 8060     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1504     |\n|    fps              | 556      |\n|    time_elapsed     | 482      |\n|    total_timesteps  | 268160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 8067     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1508     |\n|    fps              | 556      |\n|    time_elapsed     | 483      |\n|    total_timesteps  | 269400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.12     |\n|    n_updates        | 8106     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1512     |\n|    fps              | 557      |\n|    time_elapsed     | 485      |\n|    total_timesteps  | 270464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0606   |\n|    n_updates        | 8139     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1516     |\n|    fps              | 557      |\n|    time_elapsed     | 486      |\n|    total_timesteps  | 271344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0526   |\n|    n_updates        | 8167     |\n----------------------------------\nEval num_timesteps=272000, episode_reward=572.00 +/- 220.76\nEpisode length: 2948.20 +/- 278.68\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.95e+03 |\n|    mean_reward      | 572      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 272000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 8187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1520     |\n|    fps              | 549      |\n|    time_elapsed     | 495      |\n|    total_timesteps  | 272312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0349   |\n|    n_updates        | 8197     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1524     |\n|    fps              | 549      |\n|    time_elapsed     | 496      |\n|    total_timesteps  | 272784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0556   |\n|    n_updates        | 8212     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1528     |\n|    fps              | 549      |\n|    time_elapsed     | 497      |\n|    total_timesteps  | 273392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0806   |\n|    n_updates        | 8231     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1532     |\n|    fps              | 550      |\n|    time_elapsed     | 498      |\n|    total_timesteps  | 274272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.156    |\n|    n_updates        | 8258     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1536     |\n|    fps              | 550      |\n|    time_elapsed     | 499      |\n|    total_timesteps  | 275136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0599   |\n|    n_updates        | 8285     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1540     |\n|    fps              | 550      |\n|    time_elapsed     | 501      |\n|    total_timesteps  | 276008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.175    |\n|    n_updates        | 8313     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1544     |\n|    fps              | 551      |\n|    time_elapsed     | 502      |\n|    total_timesteps  | 277304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0818   |\n|    n_updates        | 8353     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1548     |\n|    fps              | 551      |\n|    time_elapsed     | 503      |\n|    total_timesteps  | 277536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0612   |\n|    n_updates        | 8360     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1552     |\n|    fps              | 551      |\n|    time_elapsed     | 504      |\n|    total_timesteps  | 278400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 8387     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1556     |\n|    fps              | 552      |\n|    time_elapsed     | 505      |\n|    total_timesteps  | 279024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0728   |\n|    n_updates        | 8407     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1560     |\n|    fps              | 552      |\n|    time_elapsed     | 506      |\n|    total_timesteps  | 280056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.158    |\n|    n_updates        | 8439     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1564     |\n|    fps              | 552      |\n|    time_elapsed     | 507      |\n|    total_timesteps  | 280624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 8457     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1568     |\n|    fps              | 553      |\n|    time_elapsed     | 508      |\n|    total_timesteps  | 281488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.159    |\n|    n_updates        | 8484     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1572     |\n|    fps              | 553      |\n|    time_elapsed     | 509      |\n|    total_timesteps  | 281904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0991   |\n|    n_updates        | 8497     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1576     |\n|    fps              | 553      |\n|    time_elapsed     | 510      |\n|    total_timesteps  | 282816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.18     |\n|    n_updates        | 8525     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1580     |\n|    fps              | 553      |\n|    time_elapsed     | 511      |\n|    total_timesteps  | 283304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.212    |\n|    n_updates        | 8541     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1584     |\n|    fps              | 554      |\n|    time_elapsed     | 511      |\n|    total_timesteps  | 283672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.14     |\n|    n_updates        | 8552     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1588     |\n|    fps              | 554      |\n|    time_elapsed     | 514      |\n|    total_timesteps  | 285656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0601   |\n|    n_updates        | 8614     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1592     |\n|    fps              | 555      |\n|    time_elapsed     | 515      |\n|    total_timesteps  | 286312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 8635     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1596     |\n|    fps              | 555      |\n|    time_elapsed     | 517      |\n|    total_timesteps  | 287408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 8669     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1600     |\n|    fps              | 555      |\n|    time_elapsed     | 517      |\n|    total_timesteps  | 287904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0772   |\n|    n_updates        | 8684     |\n----------------------------------\nEval num_timesteps=288000, episode_reward=482.00 +/- 46.65\nEpisode length: 2161.00 +/- 220.54\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.16e+03 |\n|    mean_reward      | 482      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 288000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0572   |\n|    n_updates        | 8687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1604     |\n|    fps              | 550      |\n|    time_elapsed     | 524      |\n|    total_timesteps  | 288664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0674   |\n|    n_updates        | 8708     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1608     |\n|    fps              | 550      |\n|    time_elapsed     | 526      |\n|    total_timesteps  | 290112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0704   |\n|    n_updates        | 8753     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1612     |\n|    fps              | 550      |\n|    time_elapsed     | 527      |\n|    total_timesteps  | 290512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.09     |\n|    n_updates        | 8766     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1616     |\n|    fps              | 551      |\n|    time_elapsed     | 528      |\n|    total_timesteps  | 291424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.136    |\n|    n_updates        | 8794     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1620     |\n|    fps              | 551      |\n|    time_elapsed     | 529      |\n|    total_timesteps  | 291928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0594   |\n|    n_updates        | 8810     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1624     |\n|    fps              | 551      |\n|    time_elapsed     | 530      |\n|    total_timesteps  | 292728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0826   |\n|    n_updates        | 8835     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1628     |\n|    fps              | 552      |\n|    time_elapsed     | 531      |\n|    total_timesteps  | 293712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0598   |\n|    n_updates        | 8866     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1632     |\n|    fps              | 552      |\n|    time_elapsed     | 532      |\n|    total_timesteps  | 294088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0458   |\n|    n_updates        | 8878     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1636     |\n|    fps              | 552      |\n|    time_elapsed     | 534      |\n|    total_timesteps  | 295336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.182    |\n|    n_updates        | 8917     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1640     |\n|    fps              | 552      |\n|    time_elapsed     | 534      |\n|    total_timesteps  | 295520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.27     |\n|    n_updates        | 8922     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1644     |\n|    fps              | 553      |\n|    time_elapsed     | 536      |\n|    total_timesteps  | 296960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.25     |\n|    n_updates        | 8967     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1648     |\n|    fps              | 553      |\n|    time_elapsed     | 537      |\n|    total_timesteps  | 297488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.144    |\n|    n_updates        | 8984     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1652     |\n|    fps              | 553      |\n|    time_elapsed     | 538      |\n|    total_timesteps  | 298336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.157    |\n|    n_updates        | 9010     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1656     |\n|    fps              | 554      |\n|    time_elapsed     | 539      |\n|    total_timesteps  | 298688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.143    |\n|    n_updates        | 9021     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1660     |\n|    fps              | 554      |\n|    time_elapsed     | 540      |\n|    total_timesteps  | 299800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0619   |\n|    n_updates        | 9056     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1664     |\n|    fps              | 554      |\n|    time_elapsed     | 541      |\n|    total_timesteps  | 300416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.139    |\n|    n_updates        | 9075     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1668     |\n|    fps              | 554      |\n|    time_elapsed     | 543      |\n|    total_timesteps  | 301360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.115    |\n|    n_updates        | 9105     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1672     |\n|    fps              | 555      |\n|    time_elapsed     | 544      |\n|    total_timesteps  | 302080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0707   |\n|    n_updates        | 9127     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1676     |\n|    fps              | 555      |\n|    time_elapsed     | 544      |\n|    total_timesteps  | 302784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 9149     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1680     |\n|    fps              | 555      |\n|    time_elapsed     | 545      |\n|    total_timesteps  | 303040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0523   |\n|    n_updates        | 9157     |\n----------------------------------\nEval num_timesteps=304000, episode_reward=70.00 +/- 0.00\nEpisode length: 2121.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.12e+03 |\n|    mean_reward      | 70       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 304000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0447   |\n|    n_updates        | 9187     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1684     |\n|    fps              | 550      |\n|    time_elapsed     | 552      |\n|    total_timesteps  | 304072   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.095    |\n|    n_updates        | 9190     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1688     |\n|    fps              | 550      |\n|    time_elapsed     | 553      |\n|    total_timesteps  | 304864   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.145    |\n|    n_updates        | 9214     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1692     |\n|    fps              | 551      |\n|    time_elapsed     | 554      |\n|    total_timesteps  | 305816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0981   |\n|    n_updates        | 9244     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1696     |\n|    fps              | 551      |\n|    time_elapsed     | 555      |\n|    total_timesteps  | 306592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.165    |\n|    n_updates        | 9268     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1700     |\n|    fps              | 551      |\n|    time_elapsed     | 557      |\n|    total_timesteps  | 307392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.077    |\n|    n_updates        | 9293     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1704     |\n|    fps              | 552      |\n|    time_elapsed     | 558      |\n|    total_timesteps  | 308144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0636   |\n|    n_updates        | 9317     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1708     |\n|    fps              | 552      |\n|    time_elapsed     | 559      |\n|    total_timesteps  | 308808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.164    |\n|    n_updates        | 9338     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1712     |\n|    fps              | 552      |\n|    time_elapsed     | 560      |\n|    total_timesteps  | 309512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0991   |\n|    n_updates        | 9360     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1716     |\n|    fps              | 552      |\n|    time_elapsed     | 560      |\n|    total_timesteps  | 310064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.02     |\n|    n_updates        | 9377     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1720     |\n|    fps              | 552      |\n|    time_elapsed     | 561      |\n|    total_timesteps  | 310520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 9391     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1724     |\n|    fps              | 553      |\n|    time_elapsed     | 563      |\n|    total_timesteps  | 312032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0931   |\n|    n_updates        | 9438     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1728     |\n|    fps              | 553      |\n|    time_elapsed     | 564      |\n|    total_timesteps  | 312456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0761   |\n|    n_updates        | 9452     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1732     |\n|    fps              | 553      |\n|    time_elapsed     | 565      |\n|    total_timesteps  | 313056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.14     |\n|    n_updates        | 9470     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1736     |\n|    fps              | 554      |\n|    time_elapsed     | 566      |\n|    total_timesteps  | 313704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0958   |\n|    n_updates        | 9491     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1740     |\n|    fps              | 554      |\n|    time_elapsed     | 567      |\n|    total_timesteps  | 314992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0598   |\n|    n_updates        | 9531     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1744     |\n|    fps              | 554      |\n|    time_elapsed     | 568      |\n|    total_timesteps  | 315600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.15     |\n|    n_updates        | 9550     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1748     |\n|    fps              | 555      |\n|    time_elapsed     | 570      |\n|    total_timesteps  | 316456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.24     |\n|    n_updates        | 9577     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1752     |\n|    fps              | 555      |\n|    time_elapsed     | 570      |\n|    total_timesteps  | 316832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.134    |\n|    n_updates        | 9588     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1756     |\n|    fps              | 555      |\n|    time_elapsed     | 571      |\n|    total_timesteps  | 317616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0414   |\n|    n_updates        | 9613     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1760     |\n|    fps              | 555      |\n|    time_elapsed     | 573      |\n|    total_timesteps  | 318544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.194    |\n|    n_updates        | 9642     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1764     |\n|    fps              | 556      |\n|    time_elapsed     | 574      |\n|    total_timesteps  | 319264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.12     |\n|    n_updates        | 9664     |\n----------------------------------\nEval num_timesteps=320000, episode_reward=370.00 +/- 285.24\nEpisode length: 2218.60 +/- 346.92\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.22e+03 |\n|    mean_reward      | 370      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 320000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0801   |\n|    n_updates        | 9687     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1768     |\n|    fps              | 550      |\n|    time_elapsed     | 580      |\n|    total_timesteps  | 320024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0488   |\n|    n_updates        | 9688     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1772     |\n|    fps              | 551      |\n|    time_elapsed     | 581      |\n|    total_timesteps  | 320528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0584   |\n|    n_updates        | 9704     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1776     |\n|    fps              | 551      |\n|    time_elapsed     | 582      |\n|    total_timesteps  | 321304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.09     |\n|    n_updates        | 9728     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1780     |\n|    fps              | 551      |\n|    time_elapsed     | 583      |\n|    total_timesteps  | 321944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0659   |\n|    n_updates        | 9748     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1784     |\n|    fps              | 551      |\n|    time_elapsed     | 584      |\n|    total_timesteps  | 322736   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.342    |\n|    n_updates        | 9773     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1788     |\n|    fps              | 552      |\n|    time_elapsed     | 586      |\n|    total_timesteps  | 323512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.16     |\n|    n_updates        | 9797     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1792     |\n|    fps              | 552      |\n|    time_elapsed     | 587      |\n|    total_timesteps  | 324568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.088    |\n|    n_updates        | 9830     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1796     |\n|    fps              | 552      |\n|    time_elapsed     | 588      |\n|    total_timesteps  | 325296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 9853     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1800     |\n|    fps              | 552      |\n|    time_elapsed     | 590      |\n|    total_timesteps  | 326096   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.241    |\n|    n_updates        | 9878     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1804     |\n|    fps              | 553      |\n|    time_elapsed     | 592      |\n|    total_timesteps  | 327536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.117    |\n|    n_updates        | 9923     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1808     |\n|    fps              | 553      |\n|    time_elapsed     | 592      |\n|    total_timesteps  | 327848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.235    |\n|    n_updates        | 9933     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1812     |\n|    fps              | 553      |\n|    time_elapsed     | 593      |\n|    total_timesteps  | 328584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0785   |\n|    n_updates        | 9956     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1816     |\n|    fps              | 553      |\n|    time_elapsed     | 594      |\n|    total_timesteps  | 329040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.042    |\n|    n_updates        | 9970     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1820     |\n|    fps              | 553      |\n|    time_elapsed     | 596      |\n|    total_timesteps  | 329976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0879   |\n|    n_updates        | 9999     |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1824     |\n|    fps              | 553      |\n|    time_elapsed     | 596      |\n|    total_timesteps  | 330376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.12     |\n|    n_updates        | 10012    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1828     |\n|    fps              | 553      |\n|    time_elapsed     | 598      |\n|    total_timesteps  | 331280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 10040    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1832     |\n|    fps              | 553      |\n|    time_elapsed     | 598      |\n|    total_timesteps  | 331616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.127    |\n|    n_updates        | 10050    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1836     |\n|    fps              | 553      |\n|    time_elapsed     | 599      |\n|    total_timesteps  | 332280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 10071    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1840     |\n|    fps              | 554      |\n|    time_elapsed     | 600      |\n|    total_timesteps  | 332848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.149    |\n|    n_updates        | 10089    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1844     |\n|    fps              | 554      |\n|    time_elapsed     | 602      |\n|    total_timesteps  | 333744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0598   |\n|    n_updates        | 10117    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1848     |\n|    fps              | 554      |\n|    time_elapsed     | 603      |\n|    total_timesteps  | 334616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.152    |\n|    n_updates        | 10144    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1852     |\n|    fps              | 554      |\n|    time_elapsed     | 604      |\n|    total_timesteps  | 334984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.116    |\n|    n_updates        | 10156    |\n----------------------------------\nEval num_timesteps=336000, episode_reward=230.00 +/- 0.00\nEpisode length: 2321.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.32e+03 |\n|    mean_reward      | 230      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 336000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0716   |\n|    n_updates        | 10187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1856     |\n|    fps              | 548      |\n|    time_elapsed     | 612      |\n|    total_timesteps  | 336000   |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1860     |\n|    fps              | 548      |\n|    time_elapsed     | 613      |\n|    total_timesteps  | 336528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.225    |\n|    n_updates        | 10204    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1864     |\n|    fps              | 548      |\n|    time_elapsed     | 614      |\n|    total_timesteps  | 337248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0683   |\n|    n_updates        | 10226    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1868     |\n|    fps              | 549      |\n|    time_elapsed     | 615      |\n|    total_timesteps  | 337800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.143    |\n|    n_updates        | 10244    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1872     |\n|    fps              | 549      |\n|    time_elapsed     | 616      |\n|    total_timesteps  | 338408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.158    |\n|    n_updates        | 10263    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1876     |\n|    fps              | 549      |\n|    time_elapsed     | 617      |\n|    total_timesteps  | 339200   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.222    |\n|    n_updates        | 10287    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 14.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1880     |\n|    fps              | 549      |\n|    time_elapsed     | 618      |\n|    total_timesteps  | 340184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.158    |\n|    n_updates        | 10318    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1884     |\n|    fps              | 550      |\n|    time_elapsed     | 621      |\n|    total_timesteps  | 341896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.13     |\n|    n_updates        | 10372    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1888     |\n|    fps              | 550      |\n|    time_elapsed     | 622      |\n|    total_timesteps  | 342448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.137    |\n|    n_updates        | 10389    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1892     |\n|    fps              | 550      |\n|    time_elapsed     | 623      |\n|    total_timesteps  | 343528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.27     |\n|    n_updates        | 10423    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1896     |\n|    fps              | 551      |\n|    time_elapsed     | 625      |\n|    total_timesteps  | 344496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0362   |\n|    n_updates        | 10453    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1900     |\n|    fps              | 551      |\n|    time_elapsed     | 626      |\n|    total_timesteps  | 345240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 10476    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1904     |\n|    fps              | 551      |\n|    time_elapsed     | 627      |\n|    total_timesteps  | 346496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.168    |\n|    n_updates        | 10515    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1908     |\n|    fps              | 552      |\n|    time_elapsed     | 629      |\n|    total_timesteps  | 347440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0733   |\n|    n_updates        | 10545    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1912     |\n|    fps              | 552      |\n|    time_elapsed     | 630      |\n|    total_timesteps  | 348000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 10562    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1916     |\n|    fps              | 552      |\n|    time_elapsed     | 631      |\n|    total_timesteps  | 349008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.144    |\n|    n_updates        | 10594    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1920     |\n|    fps              | 552      |\n|    time_elapsed     | 632      |\n|    total_timesteps  | 349648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0977   |\n|    n_updates        | 10614    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1924     |\n|    fps              | 553      |\n|    time_elapsed     | 633      |\n|    total_timesteps  | 350424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.225    |\n|    n_updates        | 10638    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1928     |\n|    fps              | 553      |\n|    time_elapsed     | 634      |\n|    total_timesteps  | 350912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0734   |\n|    n_updates        | 10653    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1932     |\n|    fps              | 553      |\n|    time_elapsed     | 635      |\n|    total_timesteps  | 351944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0685   |\n|    n_updates        | 10686    |\n----------------------------------\nEval num_timesteps=352000, episode_reward=132.00 +/- 9.80\nEpisode length: 1879.40 +/- 11.76\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.88e+03 |\n|    mean_reward      | 132      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 352000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 10687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1936     |\n|    fps              | 549      |\n|    time_elapsed     | 641      |\n|    total_timesteps  | 352416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0671   |\n|    n_updates        | 10700    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1940     |\n|    fps              | 549      |\n|    time_elapsed     | 642      |\n|    total_timesteps  | 353088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.176    |\n|    n_updates        | 10721    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1944     |\n|    fps              | 549      |\n|    time_elapsed     | 643      |\n|    total_timesteps  | 353680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 10740    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1948     |\n|    fps              | 550      |\n|    time_elapsed     | 644      |\n|    total_timesteps  | 354704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0356   |\n|    n_updates        | 10772    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1952     |\n|    fps              | 550      |\n|    time_elapsed     | 645      |\n|    total_timesteps  | 355192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.116    |\n|    n_updates        | 10787    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1956     |\n|    fps              | 550      |\n|    time_elapsed     | 646      |\n|    total_timesteps  | 356080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.195    |\n|    n_updates        | 10815    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1960     |\n|    fps              | 550      |\n|    time_elapsed     | 647      |\n|    total_timesteps  | 356568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0843   |\n|    n_updates        | 10830    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1964     |\n|    fps              | 551      |\n|    time_elapsed     | 648      |\n|    total_timesteps  | 357632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.18     |\n|    n_updates        | 10863    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1968     |\n|    fps              | 551      |\n|    time_elapsed     | 649      |\n|    total_timesteps  | 358040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.162    |\n|    n_updates        | 10876    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1972     |\n|    fps              | 551      |\n|    time_elapsed     | 650      |\n|    total_timesteps  | 358688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 10896    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1976     |\n|    fps              | 551      |\n|    time_elapsed     | 651      |\n|    total_timesteps  | 359536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.17     |\n|    n_updates        | 10923    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1980     |\n|    fps              | 552      |\n|    time_elapsed     | 653      |\n|    total_timesteps  | 360504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0698   |\n|    n_updates        | 10953    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1984     |\n|    fps              | 552      |\n|    time_elapsed     | 654      |\n|    total_timesteps  | 361208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.09     |\n|    n_updates        | 10975    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1988     |\n|    fps              | 552      |\n|    time_elapsed     | 655      |\n|    total_timesteps  | 362128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0513   |\n|    n_updates        | 11004    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1992     |\n|    fps              | 552      |\n|    time_elapsed     | 656      |\n|    total_timesteps  | 362712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0743   |\n|    n_updates        | 11022    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 1996     |\n|    fps              | 552      |\n|    time_elapsed     | 657      |\n|    total_timesteps  | 363320   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.34     |\n|    n_updates        | 11041    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2000     |\n|    fps              | 553      |\n|    time_elapsed     | 658      |\n|    total_timesteps  | 364040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.105    |\n|    n_updates        | 11064    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2004     |\n|    fps              | 553      |\n|    time_elapsed     | 659      |\n|    total_timesteps  | 364720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.37     |\n|    n_updates        | 11085    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2008     |\n|    fps              | 553      |\n|    time_elapsed     | 659      |\n|    total_timesteps  | 365312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.095    |\n|    n_updates        | 11103    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2012     |\n|    fps              | 553      |\n|    time_elapsed     | 660      |\n|    total_timesteps  | 366104   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.359    |\n|    n_updates        | 11128    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2016     |\n|    fps              | 554      |\n|    time_elapsed     | 661      |\n|    total_timesteps  | 366504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0374   |\n|    n_updates        | 11141    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2020     |\n|    fps              | 554      |\n|    time_elapsed     | 663      |\n|    total_timesteps  | 367616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.16     |\n|    n_updates        | 11175    |\n----------------------------------\nEval num_timesteps=368000, episode_reward=104.00 +/- 68.00\nEpisode length: 2263.40 +/- 284.80\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.26e+03 |\n|    mean_reward      | 104      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 368000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 11187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2024     |\n|    fps              | 549      |\n|    time_elapsed     | 669      |\n|    total_timesteps  | 368160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.103    |\n|    n_updates        | 11192    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2028     |\n|    fps              | 550      |\n|    time_elapsed     | 671      |\n|    total_timesteps  | 369064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.164    |\n|    n_updates        | 11221    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2032     |\n|    fps              | 550      |\n|    time_elapsed     | 672      |\n|    total_timesteps  | 369776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.157    |\n|    n_updates        | 11243    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2036     |\n|    fps              | 550      |\n|    time_elapsed     | 672      |\n|    total_timesteps  | 370288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0746   |\n|    n_updates        | 11259    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2040     |\n|    fps              | 550      |\n|    time_elapsed     | 674      |\n|    total_timesteps  | 371264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.046    |\n|    n_updates        | 11289    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2044     |\n|    fps              | 550      |\n|    time_elapsed     | 674      |\n|    total_timesteps  | 371624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 11301    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 14.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2048     |\n|    fps              | 550      |\n|    time_elapsed     | 675      |\n|    total_timesteps  | 371856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.159    |\n|    n_updates        | 11308    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 14.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2052     |\n|    fps              | 551      |\n|    time_elapsed     | 676      |\n|    total_timesteps  | 372872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.13     |\n|    n_updates        | 11340    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 14.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2056     |\n|    fps              | 551      |\n|    time_elapsed     | 677      |\n|    total_timesteps  | 373496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.156    |\n|    n_updates        | 11359    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 14.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2060     |\n|    fps              | 551      |\n|    time_elapsed     | 678      |\n|    total_timesteps  | 374240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0858   |\n|    n_updates        | 11382    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 14.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2064     |\n|    fps              | 551      |\n|    time_elapsed     | 679      |\n|    total_timesteps  | 375128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.25     |\n|    n_updates        | 11410    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 14.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2068     |\n|    fps              | 552      |\n|    time_elapsed     | 680      |\n|    total_timesteps  | 375800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.22     |\n|    n_updates        | 11431    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 14.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2072     |\n|    fps              | 552      |\n|    time_elapsed     | 681      |\n|    total_timesteps  | 376728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.136    |\n|    n_updates        | 11460    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 14.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2076     |\n|    fps              | 552      |\n|    time_elapsed     | 682      |\n|    total_timesteps  | 377232   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.15     |\n|    n_updates        | 11476    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2080     |\n|    fps              | 552      |\n|    time_elapsed     | 683      |\n|    total_timesteps  | 377968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 11499    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 14.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2084     |\n|    fps              | 552      |\n|    time_elapsed     | 684      |\n|    total_timesteps  | 378424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.37     |\n|    n_updates        | 11513    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 14.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2088     |\n|    fps              | 553      |\n|    time_elapsed     | 686      |\n|    total_timesteps  | 379824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0415   |\n|    n_updates        | 11557    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2092     |\n|    fps              | 553      |\n|    time_elapsed     | 687      |\n|    total_timesteps  | 380408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.304    |\n|    n_updates        | 11575    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2096     |\n|    fps              | 553      |\n|    time_elapsed     | 688      |\n|    total_timesteps  | 380976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0702   |\n|    n_updates        | 11593    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2100     |\n|    fps              | 553      |\n|    time_elapsed     | 689      |\n|    total_timesteps  | 381912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.23     |\n|    n_updates        | 11622    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2104     |\n|    fps              | 554      |\n|    time_elapsed     | 690      |\n|    total_timesteps  | 382720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0993   |\n|    n_updates        | 11647    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2108     |\n|    fps              | 554      |\n|    time_elapsed     | 691      |\n|    total_timesteps  | 383440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0442   |\n|    n_updates        | 11670    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2112     |\n|    fps              | 554      |\n|    time_elapsed     | 692      |\n|    total_timesteps  | 383880   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0524   |\n|    n_updates        | 11684    |\n----------------------------------\nEval num_timesteps=384000, episode_reward=152.00 +/- 29.26\nEpisode length: 2300.20 +/- 309.90\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.3e+03  |\n|    mean_reward      | 152      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 384000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.145    |\n|    n_updates        | 11687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2116     |\n|    fps              | 549      |\n|    time_elapsed     | 699      |\n|    total_timesteps  | 384648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.19     |\n|    n_updates        | 11708    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2120     |\n|    fps              | 550      |\n|    time_elapsed     | 700      |\n|    total_timesteps  | 385520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 11735    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2124     |\n|    fps              | 550      |\n|    time_elapsed     | 701      |\n|    total_timesteps  | 386112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0833   |\n|    n_updates        | 11753    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2128     |\n|    fps              | 550      |\n|    time_elapsed     | 702      |\n|    total_timesteps  | 386600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0955   |\n|    n_updates        | 11769    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2132     |\n|    fps              | 550      |\n|    time_elapsed     | 703      |\n|    total_timesteps  | 387504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.116    |\n|    n_updates        | 11797    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2136     |\n|    fps              | 550      |\n|    time_elapsed     | 704      |\n|    total_timesteps  | 388072   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.3      |\n|    n_updates        | 11815    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2140     |\n|    fps              | 551      |\n|    time_elapsed     | 705      |\n|    total_timesteps  | 388936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0926   |\n|    n_updates        | 11842    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2144     |\n|    fps              | 551      |\n|    time_elapsed     | 706      |\n|    total_timesteps  | 389488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.16     |\n|    n_updates        | 11859    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2148     |\n|    fps              | 551      |\n|    time_elapsed     | 707      |\n|    total_timesteps  | 390032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0714   |\n|    n_updates        | 11876    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2152     |\n|    fps              | 551      |\n|    time_elapsed     | 708      |\n|    total_timesteps  | 391088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 11909    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2156     |\n|    fps              | 552      |\n|    time_elapsed     | 709      |\n|    total_timesteps  | 391536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0662   |\n|    n_updates        | 11923    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2160     |\n|    fps              | 552      |\n|    time_elapsed     | 710      |\n|    total_timesteps  | 392368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0638   |\n|    n_updates        | 11949    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2164     |\n|    fps              | 552      |\n|    time_elapsed     | 712      |\n|    total_timesteps  | 393712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 11991    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2168     |\n|    fps              | 552      |\n|    time_elapsed     | 713      |\n|    total_timesteps  | 394336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.252    |\n|    n_updates        | 12010    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2172     |\n|    fps              | 552      |\n|    time_elapsed     | 714      |\n|    total_timesteps  | 394872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0968   |\n|    n_updates        | 12027    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2176     |\n|    fps              | 553      |\n|    time_elapsed     | 715      |\n|    total_timesteps  | 395672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.33     |\n|    n_updates        | 12052    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2180     |\n|    fps              | 553      |\n|    time_elapsed     | 716      |\n|    total_timesteps  | 396304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.155    |\n|    n_updates        | 12072    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2184     |\n|    fps              | 553      |\n|    time_elapsed     | 717      |\n|    total_timesteps  | 397136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0506   |\n|    n_updates        | 12098    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2188     |\n|    fps              | 553      |\n|    time_elapsed     | 718      |\n|    total_timesteps  | 397952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.116    |\n|    n_updates        | 12123    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2192     |\n|    fps              | 553      |\n|    time_elapsed     | 718      |\n|    total_timesteps  | 398152   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.144    |\n|    n_updates        | 12130    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2196     |\n|    fps              | 554      |\n|    time_elapsed     | 719      |\n|    total_timesteps  | 398920   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0477   |\n|    n_updates        | 12154    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2200     |\n|    fps              | 554      |\n|    time_elapsed     | 720      |\n|    total_timesteps  | 399344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 12167    |\n----------------------------------\nEval num_timesteps=400000, episode_reward=120.00 +/- 0.00\nEpisode length: 2157.80 +/- 82.30\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.16e+03 |\n|    mean_reward      | 120      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 400000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0457   |\n|    n_updates        | 12187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2204     |\n|    fps              | 550      |\n|    time_elapsed     | 727      |\n|    total_timesteps  | 400232   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 12195    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2208     |\n|    fps              | 550      |\n|    time_elapsed     | 728      |\n|    total_timesteps  | 400880   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.28     |\n|    n_updates        | 12215    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2212     |\n|    fps              | 550      |\n|    time_elapsed     | 729      |\n|    total_timesteps  | 401776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.48     |\n|    n_updates        | 12243    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2216     |\n|    fps              | 550      |\n|    time_elapsed     | 730      |\n|    total_timesteps  | 402448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.085    |\n|    n_updates        | 12264    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2220     |\n|    fps              | 551      |\n|    time_elapsed     | 731      |\n|    total_timesteps  | 403296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0807   |\n|    n_updates        | 12290    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2224     |\n|    fps              | 551      |\n|    time_elapsed     | 732      |\n|    total_timesteps  | 404176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0779   |\n|    n_updates        | 12318    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2228     |\n|    fps              | 551      |\n|    time_elapsed     | 734      |\n|    total_timesteps  | 405160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.17     |\n|    n_updates        | 12349    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2232     |\n|    fps              | 551      |\n|    time_elapsed     | 734      |\n|    total_timesteps  | 405576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.299    |\n|    n_updates        | 12362    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2236     |\n|    fps              | 551      |\n|    time_elapsed     | 735      |\n|    total_timesteps  | 405976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0717   |\n|    n_updates        | 12374    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2240     |\n|    fps              | 552      |\n|    time_elapsed     | 736      |\n|    total_timesteps  | 407032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.124    |\n|    n_updates        | 12407    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2244     |\n|    fps              | 552      |\n|    time_elapsed     | 737      |\n|    total_timesteps  | 407344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0841   |\n|    n_updates        | 12417    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2248     |\n|    fps              | 552      |\n|    time_elapsed     | 738      |\n|    total_timesteps  | 408400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0758   |\n|    n_updates        | 12450    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2252     |\n|    fps              | 552      |\n|    time_elapsed     | 739      |\n|    total_timesteps  | 408752   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.272    |\n|    n_updates        | 12461    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2256     |\n|    fps              | 553      |\n|    time_elapsed     | 741      |\n|    total_timesteps  | 410464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0603   |\n|    n_updates        | 12514    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2260     |\n|    fps              | 553      |\n|    time_elapsed     | 742      |\n|    total_timesteps  | 410784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0725   |\n|    n_updates        | 12524    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2264     |\n|    fps              | 553      |\n|    time_elapsed     | 743      |\n|    total_timesteps  | 411968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 12561    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2268     |\n|    fps              | 553      |\n|    time_elapsed     | 744      |\n|    total_timesteps  | 412648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 12583    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2272     |\n|    fps              | 554      |\n|    time_elapsed     | 745      |\n|    total_timesteps  | 413032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0571   |\n|    n_updates        | 12595    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2276     |\n|    fps              | 554      |\n|    time_elapsed     | 746      |\n|    total_timesteps  | 414096   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 12628    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2280     |\n|    fps              | 554      |\n|    time_elapsed     | 747      |\n|    total_timesteps  | 414408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0434   |\n|    n_updates        | 12638    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2284     |\n|    fps              | 554      |\n|    time_elapsed     | 748      |\n|    total_timesteps  | 415136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 12660    |\n----------------------------------\nEval num_timesteps=416000, episode_reward=460.00 +/- 24.49\nEpisode length: 2373.80 +/- 82.30\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.37e+03 |\n|    mean_reward      | 460      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 416000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0798   |\n|    n_updates        | 12687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2288     |\n|    fps              | 550      |\n|    time_elapsed     | 756      |\n|    total_timesteps  | 416504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0945   |\n|    n_updates        | 12703    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2292     |\n|    fps              | 550      |\n|    time_elapsed     | 757      |\n|    total_timesteps  | 416984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.39     |\n|    n_updates        | 12718    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2296     |\n|    fps              | 550      |\n|    time_elapsed     | 758      |\n|    total_timesteps  | 417680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.13     |\n|    n_updates        | 12740    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2300     |\n|    fps              | 551      |\n|    time_elapsed     | 759      |\n|    total_timesteps  | 418328   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.283    |\n|    n_updates        | 12760    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2304     |\n|    fps              | 551      |\n|    time_elapsed     | 760      |\n|    total_timesteps  | 419096   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.48     |\n|    n_updates        | 12784    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2308     |\n|    fps              | 551      |\n|    time_elapsed     | 761      |\n|    total_timesteps  | 419952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0458   |\n|    n_updates        | 12811    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2312     |\n|    fps              | 551      |\n|    time_elapsed     | 762      |\n|    total_timesteps  | 420552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.116    |\n|    n_updates        | 12830    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2316     |\n|    fps              | 552      |\n|    time_elapsed     | 763      |\n|    total_timesteps  | 421600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0594   |\n|    n_updates        | 12862    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2320     |\n|    fps              | 552      |\n|    time_elapsed     | 764      |\n|    total_timesteps  | 422336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0804   |\n|    n_updates        | 12885    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2324     |\n|    fps              | 552      |\n|    time_elapsed     | 765      |\n|    total_timesteps  | 423000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 12906    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2328     |\n|    fps              | 552      |\n|    time_elapsed     | 766      |\n|    total_timesteps  | 423776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.342    |\n|    n_updates        | 12930    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2332     |\n|    fps              | 552      |\n|    time_elapsed     | 767      |\n|    total_timesteps  | 424528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0638   |\n|    n_updates        | 12954    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2336     |\n|    fps              | 553      |\n|    time_elapsed     | 769      |\n|    total_timesteps  | 425688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 12990    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2340     |\n|    fps              | 553      |\n|    time_elapsed     | 770      |\n|    total_timesteps  | 426176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.252    |\n|    n_updates        | 13005    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2344     |\n|    fps              | 553      |\n|    time_elapsed     | 771      |\n|    total_timesteps  | 427208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.18     |\n|    n_updates        | 13038    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2348     |\n|    fps              | 553      |\n|    time_elapsed     | 772      |\n|    total_timesteps  | 427952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 13061    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2352     |\n|    fps              | 554      |\n|    time_elapsed     | 773      |\n|    total_timesteps  | 428736   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0953   |\n|    n_updates        | 13085    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2356     |\n|    fps              | 554      |\n|    time_elapsed     | 775      |\n|    total_timesteps  | 429816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.23     |\n|    n_updates        | 13119    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2360     |\n|    fps              | 554      |\n|    time_elapsed     | 776      |\n|    total_timesteps  | 430752   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.124    |\n|    n_updates        | 13148    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2364     |\n|    fps              | 554      |\n|    time_elapsed     | 777      |\n|    total_timesteps  | 431192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.209    |\n|    n_updates        | 13162    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2368     |\n|    fps              | 554      |\n|    time_elapsed     | 778      |\n|    total_timesteps  | 431832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.46     |\n|    n_updates        | 13182    |\n----------------------------------\nEval num_timesteps=432000, episode_reward=418.00 +/- 9.80\nEpisode length: 2538.60 +/- 403.68\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.54e+03 |\n|    mean_reward      | 418      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 432000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.31     |\n|    n_updates        | 13187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2372     |\n|    fps              | 550      |\n|    time_elapsed     | 785      |\n|    total_timesteps  | 432528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.41     |\n|    n_updates        | 13204    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2376     |\n|    fps              | 550      |\n|    time_elapsed     | 786      |\n|    total_timesteps  | 433216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0682   |\n|    n_updates        | 13225    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2380     |\n|    fps              | 550      |\n|    time_elapsed     | 787      |\n|    total_timesteps  | 433688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 13240    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2384     |\n|    fps              | 550      |\n|    time_elapsed     | 788      |\n|    total_timesteps  | 434392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.12     |\n|    n_updates        | 13262    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2388     |\n|    fps              | 551      |\n|    time_elapsed     | 790      |\n|    total_timesteps  | 435552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0577   |\n|    n_updates        | 13298    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2392     |\n|    fps              | 551      |\n|    time_elapsed     | 791      |\n|    total_timesteps  | 436224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.56     |\n|    n_updates        | 13319    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2396     |\n|    fps              | 551      |\n|    time_elapsed     | 792      |\n|    total_timesteps  | 437472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.124    |\n|    n_updates        | 13358    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2400     |\n|    fps              | 551      |\n|    time_elapsed     | 793      |\n|    total_timesteps  | 438200   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.21     |\n|    n_updates        | 13381    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2404     |\n|    fps              | 552      |\n|    time_elapsed     | 794      |\n|    total_timesteps  | 438816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.146    |\n|    n_updates        | 13400    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2408     |\n|    fps              | 552      |\n|    time_elapsed     | 795      |\n|    total_timesteps  | 439288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.35     |\n|    n_updates        | 13415    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2412     |\n|    fps              | 552      |\n|    time_elapsed     | 796      |\n|    total_timesteps  | 439936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0624   |\n|    n_updates        | 13435    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2416     |\n|    fps              | 552      |\n|    time_elapsed     | 797      |\n|    total_timesteps  | 440576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.227    |\n|    n_updates        | 13455    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2420     |\n|    fps              | 552      |\n|    time_elapsed     | 798      |\n|    total_timesteps  | 441576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.167    |\n|    n_updates        | 13487    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2424     |\n|    fps              | 552      |\n|    time_elapsed     | 799      |\n|    total_timesteps  | 441880   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.34     |\n|    n_updates        | 13496    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2428     |\n|    fps              | 553      |\n|    time_elapsed     | 800      |\n|    total_timesteps  | 442816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0802   |\n|    n_updates        | 13525    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2432     |\n|    fps              | 553      |\n|    time_elapsed     | 802      |\n|    total_timesteps  | 443960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.186    |\n|    n_updates        | 13561    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2436     |\n|    fps              | 553      |\n|    time_elapsed     | 803      |\n|    total_timesteps  | 444960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.12     |\n|    n_updates        | 13592    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2440     |\n|    fps              | 553      |\n|    time_elapsed     | 804      |\n|    total_timesteps  | 445312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.246    |\n|    n_updates        | 13603    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2444     |\n|    fps              | 554      |\n|    time_elapsed     | 805      |\n|    total_timesteps  | 446384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 13637    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2448     |\n|    fps              | 554      |\n|    time_elapsed     | 806      |\n|    total_timesteps  | 447064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.22     |\n|    n_updates        | 13658    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2452     |\n|    fps              | 554      |\n|    time_elapsed     | 807      |\n|    total_timesteps  | 447472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0841   |\n|    n_updates        | 13671    |\n----------------------------------\nEval num_timesteps=448000, episode_reward=60.00 +/- 0.00\nEpisode length: 1857.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.86e+03 |\n|    mean_reward      | 60       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 448000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0918   |\n|    n_updates        | 13687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2456     |\n|    fps              | 551      |\n|    time_elapsed     | 814      |\n|    total_timesteps  | 448944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0905   |\n|    n_updates        | 13717    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2460     |\n|    fps              | 551      |\n|    time_elapsed     | 815      |\n|    total_timesteps  | 449848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 13745    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2464     |\n|    fps              | 551      |\n|    time_elapsed     | 816      |\n|    total_timesteps  | 450480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.24     |\n|    n_updates        | 13765    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2468     |\n|    fps              | 552      |\n|    time_elapsed     | 817      |\n|    total_timesteps  | 451360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0678   |\n|    n_updates        | 13792    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2472     |\n|    fps              | 552      |\n|    time_elapsed     | 817      |\n|    total_timesteps  | 451576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.36     |\n|    n_updates        | 13799    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2476     |\n|    fps              | 552      |\n|    time_elapsed     | 819      |\n|    total_timesteps  | 452488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0922   |\n|    n_updates        | 13828    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2480     |\n|    fps              | 552      |\n|    time_elapsed     | 820      |\n|    total_timesteps  | 453376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.13     |\n|    n_updates        | 13855    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2484     |\n|    fps              | 552      |\n|    time_elapsed     | 821      |\n|    total_timesteps  | 454144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0916   |\n|    n_updates        | 13879    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2488     |\n|    fps              | 552      |\n|    time_elapsed     | 823      |\n|    total_timesteps  | 455144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0675   |\n|    n_updates        | 13911    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2492     |\n|    fps              | 553      |\n|    time_elapsed     | 824      |\n|    total_timesteps  | 456264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.145    |\n|    n_updates        | 13946    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2496     |\n|    fps              | 553      |\n|    time_elapsed     | 825      |\n|    total_timesteps  | 456544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.225    |\n|    n_updates        | 13954    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2500     |\n|    fps              | 553      |\n|    time_elapsed     | 826      |\n|    total_timesteps  | 457856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0758   |\n|    n_updates        | 13995    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2504     |\n|    fps              | 553      |\n|    time_elapsed     | 827      |\n|    total_timesteps  | 458464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0728   |\n|    n_updates        | 14014    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2508     |\n|    fps              | 553      |\n|    time_elapsed     | 828      |\n|    total_timesteps  | 458968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.124    |\n|    n_updates        | 14030    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2512     |\n|    fps              | 554      |\n|    time_elapsed     | 829      |\n|    total_timesteps  | 459592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 14050    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2516     |\n|    fps              | 554      |\n|    time_elapsed     | 830      |\n|    total_timesteps  | 460264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.14     |\n|    n_updates        | 14071    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2520     |\n|    fps              | 554      |\n|    time_elapsed     | 831      |\n|    total_timesteps  | 461120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.37     |\n|    n_updates        | 14097    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2524     |\n|    fps              | 554      |\n|    time_elapsed     | 832      |\n|    total_timesteps  | 461552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0954   |\n|    n_updates        | 14111    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2528     |\n|    fps              | 554      |\n|    time_elapsed     | 833      |\n|    total_timesteps  | 462376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.195    |\n|    n_updates        | 14137    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2532     |\n|    fps              | 555      |\n|    time_elapsed     | 834      |\n|    total_timesteps  | 463096   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0776   |\n|    n_updates        | 14159    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2536     |\n|    fps              | 555      |\n|    time_elapsed     | 834      |\n|    total_timesteps  | 463328   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0277   |\n|    n_updates        | 14166    |\n----------------------------------\nEval num_timesteps=464000, episode_reward=314.00 +/- 58.17\nEpisode length: 2655.40 +/- 253.86\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.66e+03 |\n|    mean_reward      | 314      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 464000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0704   |\n|    n_updates        | 14187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2540     |\n|    fps              | 550      |\n|    time_elapsed     | 842      |\n|    total_timesteps  | 464160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.124    |\n|    n_updates        | 14192    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2544     |\n|    fps              | 550      |\n|    time_elapsed     | 843      |\n|    total_timesteps  | 464936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.192    |\n|    n_updates        | 14217    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2548     |\n|    fps              | 551      |\n|    time_elapsed     | 844      |\n|    total_timesteps  | 465480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.19     |\n|    n_updates        | 14234    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2552     |\n|    fps              | 551      |\n|    time_elapsed     | 845      |\n|    total_timesteps  | 466168   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0655   |\n|    n_updates        | 14255    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2556     |\n|    fps              | 551      |\n|    time_elapsed     | 846      |\n|    total_timesteps  | 466808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.41     |\n|    n_updates        | 14275    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2560     |\n|    fps              | 551      |\n|    time_elapsed     | 847      |\n|    total_timesteps  | 467480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0288   |\n|    n_updates        | 14296    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2564     |\n|    fps              | 551      |\n|    time_elapsed     | 849      |\n|    total_timesteps  | 468496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.34     |\n|    n_updates        | 14328    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2568     |\n|    fps              | 552      |\n|    time_elapsed     | 850      |\n|    total_timesteps  | 469680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 14365    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2572     |\n|    fps              | 552      |\n|    time_elapsed     | 851      |\n|    total_timesteps  | 470296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.112    |\n|    n_updates        | 14384    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2576     |\n|    fps              | 552      |\n|    time_elapsed     | 852      |\n|    total_timesteps  | 470664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0866   |\n|    n_updates        | 14396    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2580     |\n|    fps              | 552      |\n|    time_elapsed     | 854      |\n|    total_timesteps  | 471984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0809   |\n|    n_updates        | 14437    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2584     |\n|    fps              | 552      |\n|    time_elapsed     | 855      |\n|    total_timesteps  | 472840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.219    |\n|    n_updates        | 14464    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2588     |\n|    fps              | 553      |\n|    time_elapsed     | 856      |\n|    total_timesteps  | 473448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.25     |\n|    n_updates        | 14483    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2592     |\n|    fps              | 553      |\n|    time_elapsed     | 857      |\n|    total_timesteps  | 474376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.19     |\n|    n_updates        | 14512    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2596     |\n|    fps              | 553      |\n|    time_elapsed     | 858      |\n|    total_timesteps  | 475088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.162    |\n|    n_updates        | 14534    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2600     |\n|    fps              | 553      |\n|    time_elapsed     | 859      |\n|    total_timesteps  | 475480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0932   |\n|    n_updates        | 14546    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2604     |\n|    fps              | 553      |\n|    time_elapsed     | 860      |\n|    total_timesteps  | 476184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0896   |\n|    n_updates        | 14568    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2608     |\n|    fps              | 553      |\n|    time_elapsed     | 861      |\n|    total_timesteps  | 476960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0561   |\n|    n_updates        | 14592    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2612     |\n|    fps              | 554      |\n|    time_elapsed     | 862      |\n|    total_timesteps  | 477832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0568   |\n|    n_updates        | 14620    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2616     |\n|    fps              | 554      |\n|    time_elapsed     | 863      |\n|    total_timesteps  | 478344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.054    |\n|    n_updates        | 14636    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2620     |\n|    fps              | 554      |\n|    time_elapsed     | 864      |\n|    total_timesteps  | 479312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.27     |\n|    n_updates        | 14666    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2624     |\n|    fps              | 554      |\n|    time_elapsed     | 865      |\n|    total_timesteps  | 479856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 14683    |\n----------------------------------\nEval num_timesteps=480000, episode_reward=216.00 +/- 4.90\nEpisode length: 1509.80 +/- 3.92\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.51e+03 |\n|    mean_reward      | 216      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 480000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.343    |\n|    n_updates        | 14687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2628     |\n|    fps              | 552      |\n|    time_elapsed     | 870      |\n|    total_timesteps  | 480600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.244    |\n|    n_updates        | 14706    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2632     |\n|    fps              | 552      |\n|    time_elapsed     | 872      |\n|    total_timesteps  | 482096   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 14753    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2636     |\n|    fps              | 552      |\n|    time_elapsed     | 872      |\n|    total_timesteps  | 482600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0995   |\n|    n_updates        | 14769    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2640     |\n|    fps              | 553      |\n|    time_elapsed     | 874      |\n|    total_timesteps  | 483984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.233    |\n|    n_updates        | 14812    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2644     |\n|    fps              | 553      |\n|    time_elapsed     | 876      |\n|    total_timesteps  | 485008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.124    |\n|    n_updates        | 14844    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2648     |\n|    fps              | 553      |\n|    time_elapsed     | 876      |\n|    total_timesteps  | 485320   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.125    |\n|    n_updates        | 14854    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2652     |\n|    fps              | 553      |\n|    time_elapsed     | 878      |\n|    total_timesteps  | 486656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.196    |\n|    n_updates        | 14895    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2656     |\n|    fps              | 553      |\n|    time_elapsed     | 879      |\n|    total_timesteps  | 487128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.07     |\n|    n_updates        | 14910    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2660     |\n|    fps              | 554      |\n|    time_elapsed     | 880      |\n|    total_timesteps  | 487768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.184    |\n|    n_updates        | 14930    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2664     |\n|    fps              | 554      |\n|    time_elapsed     | 880      |\n|    total_timesteps  | 488184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.086    |\n|    n_updates        | 14943    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2668     |\n|    fps              | 554      |\n|    time_elapsed     | 882      |\n|    total_timesteps  | 489032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.131    |\n|    n_updates        | 14970    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2672     |\n|    fps              | 554      |\n|    time_elapsed     | 883      |\n|    total_timesteps  | 489952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 14998    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2676     |\n|    fps              | 554      |\n|    time_elapsed     | 884      |\n|    total_timesteps  | 490424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0642   |\n|    n_updates        | 15013    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2680     |\n|    fps              | 554      |\n|    time_elapsed     | 885      |\n|    total_timesteps  | 491552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.36     |\n|    n_updates        | 15048    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2684     |\n|    fps              | 555      |\n|    time_elapsed     | 887      |\n|    total_timesteps  | 492496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.142    |\n|    n_updates        | 15078    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2688     |\n|    fps              | 555      |\n|    time_elapsed     | 888      |\n|    total_timesteps  | 493384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.123    |\n|    n_updates        | 15106    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2692     |\n|    fps              | 555      |\n|    time_elapsed     | 889      |\n|    total_timesteps  | 494224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.079    |\n|    n_updates        | 15132    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2696     |\n|    fps              | 555      |\n|    time_elapsed     | 890      |\n|    total_timesteps  | 494640   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0644   |\n|    n_updates        | 15145    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2700     |\n|    fps              | 555      |\n|    time_elapsed     | 891      |\n|    total_timesteps  | 495688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 15178    |\n----------------------------------\nEval num_timesteps=496000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.93e+03 |\n|    mean_reward      | 60       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 496000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.32     |\n|    n_updates        | 15187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2704     |\n|    fps              | 552      |\n|    time_elapsed     | 897      |\n|    total_timesteps  | 496024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 15188    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2708     |\n|    fps              | 553      |\n|    time_elapsed     | 898      |\n|    total_timesteps  | 496960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 15217    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2712     |\n|    fps              | 553      |\n|    time_elapsed     | 899      |\n|    total_timesteps  | 497448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0914   |\n|    n_updates        | 15233    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2716     |\n|    fps              | 553      |\n|    time_elapsed     | 900      |\n|    total_timesteps  | 498472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.342    |\n|    n_updates        | 15265    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2720     |\n|    fps              | 553      |\n|    time_elapsed     | 901      |\n|    total_timesteps  | 499048   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0548   |\n|    n_updates        | 15283    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2724     |\n|    fps              | 553      |\n|    time_elapsed     | 903      |\n|    total_timesteps  | 500320   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.24     |\n|    n_updates        | 15322    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2728     |\n|    fps              | 554      |\n|    time_elapsed     | 904      |\n|    total_timesteps  | 501184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0985   |\n|    n_updates        | 15349    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2732     |\n|    fps              | 554      |\n|    time_elapsed     | 905      |\n|    total_timesteps  | 501800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.171    |\n|    n_updates        | 15369    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2736     |\n|    fps              | 554      |\n|    time_elapsed     | 907      |\n|    total_timesteps  | 503032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0505   |\n|    n_updates        | 15407    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2740     |\n|    fps              | 554      |\n|    time_elapsed     | 908      |\n|    total_timesteps  | 504304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.142    |\n|    n_updates        | 15447    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2744     |\n|    fps              | 554      |\n|    time_elapsed     | 909      |\n|    total_timesteps  | 504480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0896   |\n|    n_updates        | 15452    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2748     |\n|    fps              | 555      |\n|    time_elapsed     | 910      |\n|    total_timesteps  | 505360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 15480    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2752     |\n|    fps              | 555      |\n|    time_elapsed     | 911      |\n|    total_timesteps  | 505960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.36     |\n|    n_updates        | 15499    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2756     |\n|    fps              | 555      |\n|    time_elapsed     | 911      |\n|    total_timesteps  | 506448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.7      |\n|    n_updates        | 15514    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2760     |\n|    fps              | 555      |\n|    time_elapsed     | 914      |\n|    total_timesteps  | 507992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0886   |\n|    n_updates        | 15562    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2764     |\n|    fps              | 555      |\n|    time_elapsed     | 914      |\n|    total_timesteps  | 508576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 15580    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2768     |\n|    fps              | 556      |\n|    time_elapsed     | 916      |\n|    total_timesteps  | 509568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 15611    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2772     |\n|    fps              | 556      |\n|    time_elapsed     | 917      |\n|    total_timesteps  | 510584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.129    |\n|    n_updates        | 15643    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2776     |\n|    fps              | 556      |\n|    time_elapsed     | 918      |\n|    total_timesteps  | 511328   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.38     |\n|    n_updates        | 15666    |\n----------------------------------\nEval num_timesteps=512000, episode_reward=448.00 +/- 33.11\nEpisode length: 2388.20 +/- 55.79\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.39e+03 |\n|    mean_reward      | 448      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 512000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.042    |\n|    n_updates        | 15687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2780     |\n|    fps              | 552      |\n|    time_elapsed     | 926      |\n|    total_timesteps  | 512040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 15689    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2784     |\n|    fps              | 553      |\n|    time_elapsed     | 927      |\n|    total_timesteps  | 512960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0767   |\n|    n_updates        | 15717    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2788     |\n|    fps              | 553      |\n|    time_elapsed     | 928      |\n|    total_timesteps  | 513704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.071    |\n|    n_updates        | 15741    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2792     |\n|    fps              | 553      |\n|    time_elapsed     | 929      |\n|    total_timesteps  | 514472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.23     |\n|    n_updates        | 15765    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2796     |\n|    fps              | 553      |\n|    time_elapsed     | 930      |\n|    total_timesteps  | 515160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0936   |\n|    n_updates        | 15786    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2800     |\n|    fps              | 553      |\n|    time_elapsed     | 931      |\n|    total_timesteps  | 515816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0671   |\n|    n_updates        | 15807    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2804     |\n|    fps              | 554      |\n|    time_elapsed     | 933      |\n|    total_timesteps  | 516992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0396   |\n|    n_updates        | 15843    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2808     |\n|    fps              | 554      |\n|    time_elapsed     | 934      |\n|    total_timesteps  | 517680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0718   |\n|    n_updates        | 15865    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2812     |\n|    fps              | 554      |\n|    time_elapsed     | 934      |\n|    total_timesteps  | 518216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 15882    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2816     |\n|    fps              | 554      |\n|    time_elapsed     | 936      |\n|    total_timesteps  | 519208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0642   |\n|    n_updates        | 15913    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2820     |\n|    fps              | 554      |\n|    time_elapsed     | 936      |\n|    total_timesteps  | 519648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.14     |\n|    n_updates        | 15926    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2824     |\n|    fps              | 554      |\n|    time_elapsed     | 937      |\n|    total_timesteps  | 520232   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.085    |\n|    n_updates        | 15945    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2828     |\n|    fps              | 554      |\n|    time_elapsed     | 939      |\n|    total_timesteps  | 521360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0777   |\n|    n_updates        | 15980    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2832     |\n|    fps              | 555      |\n|    time_elapsed     | 940      |\n|    total_timesteps  | 521872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.175    |\n|    n_updates        | 15996    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2836     |\n|    fps              | 555      |\n|    time_elapsed     | 941      |\n|    total_timesteps  | 523048   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 16033    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2840     |\n|    fps              | 555      |\n|    time_elapsed     | 942      |\n|    total_timesteps  | 523528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0642   |\n|    n_updates        | 16048    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2844     |\n|    fps              | 555      |\n|    time_elapsed     | 943      |\n|    total_timesteps  | 524080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0753   |\n|    n_updates        | 16065    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2848     |\n|    fps              | 555      |\n|    time_elapsed     | 945      |\n|    total_timesteps  | 525376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.246    |\n|    n_updates        | 16105    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2852     |\n|    fps              | 555      |\n|    time_elapsed     | 945      |\n|    total_timesteps  | 525848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.277    |\n|    n_updates        | 16120    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2856     |\n|    fps              | 556      |\n|    time_elapsed     | 947      |\n|    total_timesteps  | 526856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.105    |\n|    n_updates        | 16152    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2860     |\n|    fps              | 556      |\n|    time_elapsed     | 948      |\n|    total_timesteps  | 527648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 16176    |\n----------------------------------\nEval num_timesteps=528000, episode_reward=526.00 +/- 19.60\nEpisode length: 2620.20 +/- 35.27\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.62e+03 |\n|    mean_reward      | 526      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 528000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.099    |\n|    n_updates        | 16187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2864     |\n|    fps              | 552      |\n|    time_elapsed     | 957      |\n|    total_timesteps  | 528896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.136    |\n|    n_updates        | 16215    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2868     |\n|    fps              | 552      |\n|    time_elapsed     | 957      |\n|    total_timesteps  | 529400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 16231    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2872     |\n|    fps              | 552      |\n|    time_elapsed     | 959      |\n|    total_timesteps  | 530352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0458   |\n|    n_updates        | 16261    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2876     |\n|    fps              | 553      |\n|    time_elapsed     | 960      |\n|    total_timesteps  | 531528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 16298    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2880     |\n|    fps              | 553      |\n|    time_elapsed     | 961      |\n|    total_timesteps  | 531960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0833   |\n|    n_updates        | 16311    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2884     |\n|    fps              | 553      |\n|    time_elapsed     | 962      |\n|    total_timesteps  | 532800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0946   |\n|    n_updates        | 16337    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 19.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2888     |\n|    fps              | 553      |\n|    time_elapsed     | 963      |\n|    total_timesteps  | 533624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.238    |\n|    n_updates        | 16363    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2892     |\n|    fps              | 553      |\n|    time_elapsed     | 965      |\n|    total_timesteps  | 534704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0471   |\n|    n_updates        | 16397    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 19.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2896     |\n|    fps              | 553      |\n|    time_elapsed     | 965      |\n|    total_timesteps  | 535040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.139    |\n|    n_updates        | 16407    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2900     |\n|    fps              | 554      |\n|    time_elapsed     | 967      |\n|    total_timesteps  | 536296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.222    |\n|    n_updates        | 16447    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2904     |\n|    fps              | 554      |\n|    time_elapsed     | 969      |\n|    total_timesteps  | 537424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0512   |\n|    n_updates        | 16482    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 19.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2908     |\n|    fps              | 554      |\n|    time_elapsed     | 970      |\n|    total_timesteps  | 538160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0882   |\n|    n_updates        | 16505    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 19.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2912     |\n|    fps              | 554      |\n|    time_elapsed     | 971      |\n|    total_timesteps  | 538720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 16522    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2916     |\n|    fps              | 555      |\n|    time_elapsed     | 972      |\n|    total_timesteps  | 539696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.25     |\n|    n_updates        | 16553    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2920     |\n|    fps              | 555      |\n|    time_elapsed     | 972      |\n|    total_timesteps  | 539968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0739   |\n|    n_updates        | 16561    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2924     |\n|    fps              | 555      |\n|    time_elapsed     | 974      |\n|    total_timesteps  | 540912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0446   |\n|    n_updates        | 16591    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2928     |\n|    fps              | 555      |\n|    time_elapsed     | 975      |\n|    total_timesteps  | 541888   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0929   |\n|    n_updates        | 16621    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2932     |\n|    fps              | 555      |\n|    time_elapsed     | 976      |\n|    total_timesteps  | 542536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0356   |\n|    n_updates        | 16642    |\n----------------------------------\nEval num_timesteps=544000, episode_reward=1088.00 +/- 424.00\nEpisode length: 2594.60 +/- 364.80\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.59e+03 |\n|    mean_reward      | 1.09e+03 |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 544000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0603   |\n|    n_updates        | 16687    |\n----------------------------------\nNew best mean reward!\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 19.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2936     |\n|    fps              | 552      |\n|    time_elapsed     | 985      |\n|    total_timesteps  | 544136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 16692    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 212      |\n|    ep_rew_mean      | 20.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2940     |\n|    fps              | 552      |\n|    time_elapsed     | 987      |\n|    total_timesteps  | 545352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.216    |\n|    n_updates        | 16730    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 214      |\n|    ep_rew_mean      | 20.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2944     |\n|    fps              | 552      |\n|    time_elapsed     | 987      |\n|    total_timesteps  | 545688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.193    |\n|    n_updates        | 16740    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 216      |\n|    ep_rew_mean      | 20.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2948     |\n|    fps              | 552      |\n|    time_elapsed     | 989      |\n|    total_timesteps  | 546832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0179   |\n|    n_updates        | 16776    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 215      |\n|    ep_rew_mean      | 20.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2952     |\n|    fps              | 552      |\n|    time_elapsed     | 990      |\n|    total_timesteps  | 547368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0949   |\n|    n_updates        | 16793    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 217      |\n|    ep_rew_mean      | 20.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2956     |\n|    fps              | 553      |\n|    time_elapsed     | 991      |\n|    total_timesteps  | 548176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0968   |\n|    n_updates        | 16818    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 212      |\n|    ep_rew_mean      | 20       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2960     |\n|    fps              | 553      |\n|    time_elapsed     | 991      |\n|    total_timesteps  | 548688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 16834    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 210      |\n|    ep_rew_mean      | 19.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2964     |\n|    fps              | 553      |\n|    time_elapsed     | 993      |\n|    total_timesteps  | 549488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.228    |\n|    n_updates        | 16859    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2968     |\n|    fps              | 553      |\n|    time_elapsed     | 993      |\n|    total_timesteps  | 549992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0981   |\n|    n_updates        | 16875    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2972     |\n|    fps              | 553      |\n|    time_elapsed     | 995      |\n|    total_timesteps  | 550960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0493   |\n|    n_updates        | 16905    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2976     |\n|    fps              | 553      |\n|    time_elapsed     | 996      |\n|    total_timesteps  | 551984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 16937    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2980     |\n|    fps              | 553      |\n|    time_elapsed     | 997      |\n|    total_timesteps  | 552464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0954   |\n|    n_updates        | 16952    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2984     |\n|    fps              | 554      |\n|    time_elapsed     | 998      |\n|    total_timesteps  | 553608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.093    |\n|    n_updates        | 16988    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2988     |\n|    fps              | 554      |\n|    time_elapsed     | 1000     |\n|    total_timesteps  | 554368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0988   |\n|    n_updates        | 17011    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2992     |\n|    fps              | 554      |\n|    time_elapsed     | 1000     |\n|    total_timesteps  | 554608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 17019    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 2996     |\n|    fps              | 554      |\n|    time_elapsed     | 1002     |\n|    total_timesteps  | 555808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.149    |\n|    n_updates        | 17056    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3000     |\n|    fps              | 554      |\n|    time_elapsed     | 1002     |\n|    total_timesteps  | 556384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.141    |\n|    n_updates        | 17074    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3004     |\n|    fps              | 554      |\n|    time_elapsed     | 1003     |\n|    total_timesteps  | 556848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.07     |\n|    n_updates        | 17089    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3008     |\n|    fps              | 554      |\n|    time_elapsed     | 1005     |\n|    total_timesteps  | 557888   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 17121    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3012     |\n|    fps              | 555      |\n|    time_elapsed     | 1005     |\n|    total_timesteps  | 558112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0392   |\n|    n_updates        | 17128    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3016     |\n|    fps              | 555      |\n|    time_elapsed     | 1007     |\n|    total_timesteps  | 559216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0791   |\n|    n_updates        | 17163    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3020     |\n|    fps              | 555      |\n|    time_elapsed     | 1007     |\n|    total_timesteps  | 559456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0907   |\n|    n_updates        | 17170    |\n----------------------------------\nEval num_timesteps=560000, episode_reward=210.00 +/- 0.00\nEpisode length: 2113.00 +/- 16.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.11e+03 |\n|    mean_reward      | 210      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 560000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.16     |\n|    n_updates        | 17187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3024     |\n|    fps              | 552      |\n|    time_elapsed     | 1014     |\n|    total_timesteps  | 560128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.15     |\n|    n_updates        | 17191    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3028     |\n|    fps              | 552      |\n|    time_elapsed     | 1014     |\n|    total_timesteps  | 560744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.1      |\n|    n_updates        | 17211    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3032     |\n|    fps              | 552      |\n|    time_elapsed     | 1016     |\n|    total_timesteps  | 562072   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0877   |\n|    n_updates        | 17252    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3036     |\n|    fps              | 552      |\n|    time_elapsed     | 1017     |\n|    total_timesteps  | 562336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0645   |\n|    n_updates        | 17260    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3040     |\n|    fps              | 552      |\n|    time_elapsed     | 1018     |\n|    total_timesteps  | 562968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.061    |\n|    n_updates        | 17280    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3044     |\n|    fps              | 553      |\n|    time_elapsed     | 1019     |\n|    total_timesteps  | 563856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.15     |\n|    n_updates        | 17308    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3048     |\n|    fps              | 553      |\n|    time_elapsed     | 1020     |\n|    total_timesteps  | 564600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 17331    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3052     |\n|    fps              | 553      |\n|    time_elapsed     | 1021     |\n|    total_timesteps  | 565472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.12     |\n|    n_updates        | 17358    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3056     |\n|    fps              | 553      |\n|    time_elapsed     | 1022     |\n|    total_timesteps  | 566304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.162    |\n|    n_updates        | 17384    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3060     |\n|    fps              | 553      |\n|    time_elapsed     | 1024     |\n|    total_timesteps  | 567488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.32     |\n|    n_updates        | 17421    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3064     |\n|    fps              | 554      |\n|    time_elapsed     | 1026     |\n|    total_timesteps  | 568504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0752   |\n|    n_updates        | 17453    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3068     |\n|    fps              | 554      |\n|    time_elapsed     | 1026     |\n|    total_timesteps  | 568752   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.05     |\n|    n_updates        | 17461    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3072     |\n|    fps              | 554      |\n|    time_elapsed     | 1027     |\n|    total_timesteps  | 569768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0838   |\n|    n_updates        | 17493    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3076     |\n|    fps              | 554      |\n|    time_elapsed     | 1028     |\n|    total_timesteps  | 569920   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.134    |\n|    n_updates        | 17497    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3080     |\n|    fps              | 554      |\n|    time_elapsed     | 1029     |\n|    total_timesteps  | 570608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.13     |\n|    n_updates        | 17519    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3084     |\n|    fps              | 554      |\n|    time_elapsed     | 1029     |\n|    total_timesteps  | 571168   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0853   |\n|    n_updates        | 17536    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3088     |\n|    fps              | 554      |\n|    time_elapsed     | 1030     |\n|    total_timesteps  | 571656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.292    |\n|    n_updates        | 17552    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3092     |\n|    fps              | 554      |\n|    time_elapsed     | 1032     |\n|    total_timesteps  | 572720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.142    |\n|    n_updates        | 17585    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3096     |\n|    fps              | 555      |\n|    time_elapsed     | 1032     |\n|    total_timesteps  | 573352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.287    |\n|    n_updates        | 17605    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3100     |\n|    fps              | 555      |\n|    time_elapsed     | 1033     |\n|    total_timesteps  | 573952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.175    |\n|    n_updates        | 17623    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3104     |\n|    fps              | 555      |\n|    time_elapsed     | 1034     |\n|    total_timesteps  | 574656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 17645    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3108     |\n|    fps              | 555      |\n|    time_elapsed     | 1036     |\n|    total_timesteps  | 575832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.12     |\n|    n_updates        | 17682    |\n----------------------------------\nEval num_timesteps=576000, episode_reward=604.00 +/- 60.53\nEpisode length: 3121.00 +/- 565.64\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 3.12e+03 |\n|    mean_reward      | 604      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 576000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 17687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3112     |\n|    fps              | 551      |\n|    time_elapsed     | 1045     |\n|    total_timesteps  | 576248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0779   |\n|    n_updates        | 17695    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3116     |\n|    fps              | 551      |\n|    time_elapsed     | 1045     |\n|    total_timesteps  | 576600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0687   |\n|    n_updates        | 17706    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3120     |\n|    fps              | 551      |\n|    time_elapsed     | 1046     |\n|    total_timesteps  | 577416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.145    |\n|    n_updates        | 17732    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3124     |\n|    fps              | 551      |\n|    time_elapsed     | 1047     |\n|    total_timesteps  | 577904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0969   |\n|    n_updates        | 17747    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3128     |\n|    fps              | 551      |\n|    time_elapsed     | 1049     |\n|    total_timesteps  | 578856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.083    |\n|    n_updates        | 17777    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3132     |\n|    fps              | 551      |\n|    time_elapsed     | 1049     |\n|    total_timesteps  | 579432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 17795    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3136     |\n|    fps              | 552      |\n|    time_elapsed     | 1050     |\n|    total_timesteps  | 580064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.112    |\n|    n_updates        | 17814    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3140     |\n|    fps              | 552      |\n|    time_elapsed     | 1051     |\n|    total_timesteps  | 580696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0997   |\n|    n_updates        | 17834    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3144     |\n|    fps              | 552      |\n|    time_elapsed     | 1052     |\n|    total_timesteps  | 581368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 17855    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3148     |\n|    fps              | 552      |\n|    time_elapsed     | 1054     |\n|    total_timesteps  | 582352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.152    |\n|    n_updates        | 17886    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3152     |\n|    fps              | 552      |\n|    time_elapsed     | 1055     |\n|    total_timesteps  | 583592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 17925    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3156     |\n|    fps              | 552      |\n|    time_elapsed     | 1056     |\n|    total_timesteps  | 583896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0524   |\n|    n_updates        | 17934    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3160     |\n|    fps              | 552      |\n|    time_elapsed     | 1057     |\n|    total_timesteps  | 584560   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0548   |\n|    n_updates        | 17955    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3164     |\n|    fps              | 553      |\n|    time_elapsed     | 1058     |\n|    total_timesteps  | 585280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0812   |\n|    n_updates        | 17977    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 169      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3168     |\n|    fps              | 553      |\n|    time_elapsed     | 1058     |\n|    total_timesteps  | 585784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.19     |\n|    n_updates        | 17993    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3172     |\n|    fps              | 553      |\n|    time_elapsed     | 1060     |\n|    total_timesteps  | 586648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.969    |\n|    n_updates        | 18020    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3176     |\n|    fps              | 553      |\n|    time_elapsed     | 1061     |\n|    total_timesteps  | 587208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0905   |\n|    n_updates        | 18038    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3180     |\n|    fps              | 553      |\n|    time_elapsed     | 1062     |\n|    total_timesteps  | 588016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0489   |\n|    n_updates        | 18063    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3184     |\n|    fps              | 553      |\n|    time_elapsed     | 1062     |\n|    total_timesteps  | 588384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0968   |\n|    n_updates        | 18074    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3188     |\n|    fps              | 553      |\n|    time_elapsed     | 1063     |\n|    total_timesteps  | 589216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.127    |\n|    n_updates        | 18100    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3192     |\n|    fps              | 554      |\n|    time_elapsed     | 1065     |\n|    total_timesteps  | 590344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0543   |\n|    n_updates        | 18136    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3196     |\n|    fps              | 554      |\n|    time_elapsed     | 1066     |\n|    total_timesteps  | 590776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.112    |\n|    n_updates        | 18149    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3200     |\n|    fps              | 554      |\n|    time_elapsed     | 1067     |\n|    total_timesteps  | 591776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 18180    |\n----------------------------------\nEval num_timesteps=592000, episode_reward=822.00 +/- 221.12\nEpisode length: 2596.20 +/- 733.55\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.6e+03  |\n|    mean_reward      | 822      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 592000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.88     |\n|    n_updates        | 18187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3204     |\n|    fps              | 550      |\n|    time_elapsed     | 1075     |\n|    total_timesteps  | 592424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0548   |\n|    n_updates        | 18201    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3208     |\n|    fps              | 551      |\n|    time_elapsed     | 1077     |\n|    total_timesteps  | 593824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.182    |\n|    n_updates        | 18244    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3212     |\n|    fps              | 551      |\n|    time_elapsed     | 1077     |\n|    total_timesteps  | 594160   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0465   |\n|    n_updates        | 18255    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3216     |\n|    fps              | 551      |\n|    time_elapsed     | 1079     |\n|    total_timesteps  | 595032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0781   |\n|    n_updates        | 18282    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3220     |\n|    fps              | 551      |\n|    time_elapsed     | 1080     |\n|    total_timesteps  | 596136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.164    |\n|    n_updates        | 18317    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3224     |\n|    fps              | 551      |\n|    time_elapsed     | 1081     |\n|    total_timesteps  | 596880   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0584   |\n|    n_updates        | 18340    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3228     |\n|    fps              | 551      |\n|    time_elapsed     | 1082     |\n|    total_timesteps  | 597480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.151    |\n|    n_updates        | 18359    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3232     |\n|    fps              | 551      |\n|    time_elapsed     | 1084     |\n|    total_timesteps  | 598368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0877   |\n|    n_updates        | 18386    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3236     |\n|    fps              | 552      |\n|    time_elapsed     | 1084     |\n|    total_timesteps  | 599008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 18406    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3240     |\n|    fps              | 552      |\n|    time_elapsed     | 1086     |\n|    total_timesteps  | 600000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0524   |\n|    n_updates        | 18437    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3244     |\n|    fps              | 552      |\n|    time_elapsed     | 1087     |\n|    total_timesteps  | 601056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.268    |\n|    n_updates        | 18470    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3248     |\n|    fps              | 552      |\n|    time_elapsed     | 1088     |\n|    total_timesteps  | 601704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.147    |\n|    n_updates        | 18491    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3252     |\n|    fps              | 552      |\n|    time_elapsed     | 1089     |\n|    total_timesteps  | 602200   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0805   |\n|    n_updates        | 18506    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3256     |\n|    fps              | 552      |\n|    time_elapsed     | 1091     |\n|    total_timesteps  | 603296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0575   |\n|    n_updates        | 18540    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3260     |\n|    fps              | 553      |\n|    time_elapsed     | 1092     |\n|    total_timesteps  | 604448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.187    |\n|    n_updates        | 18576    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3264     |\n|    fps              | 553      |\n|    time_elapsed     | 1093     |\n|    total_timesteps  | 604824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0817   |\n|    n_updates        | 18588    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3268     |\n|    fps              | 553      |\n|    time_elapsed     | 1094     |\n|    total_timesteps  | 605592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.15     |\n|    n_updates        | 18612    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3272     |\n|    fps              | 553      |\n|    time_elapsed     | 1095     |\n|    total_timesteps  | 606144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0831   |\n|    n_updates        | 18629    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3276     |\n|    fps              | 553      |\n|    time_elapsed     | 1096     |\n|    total_timesteps  | 607048   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0367   |\n|    n_updates        | 18658    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3280     |\n|    fps              | 553      |\n|    time_elapsed     | 1097     |\n|    total_timesteps  | 607896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0734   |\n|    n_updates        | 18684    |\n----------------------------------\nEval num_timesteps=608000, episode_reward=1038.00 +/- 234.38\nEpisode length: 2809.00 +/- 359.84\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.81e+03 |\n|    mean_reward      | 1.04e+03 |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 608000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0664   |\n|    n_updates        | 18687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3284     |\n|    fps              | 550      |\n|    time_elapsed     | 1105     |\n|    total_timesteps  | 608288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 18696    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3288     |\n|    fps              | 550      |\n|    time_elapsed     | 1106     |\n|    total_timesteps  | 609016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0582   |\n|    n_updates        | 18719    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3292     |\n|    fps              | 550      |\n|    time_elapsed     | 1107     |\n|    total_timesteps  | 609848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.094    |\n|    n_updates        | 18745    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3296     |\n|    fps              | 550      |\n|    time_elapsed     | 1108     |\n|    total_timesteps  | 610024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 18751    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3300     |\n|    fps              | 550      |\n|    time_elapsed     | 1109     |\n|    total_timesteps  | 611304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.123    |\n|    n_updates        | 18791    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3304     |\n|    fps              | 550      |\n|    time_elapsed     | 1110     |\n|    total_timesteps  | 612080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.03     |\n|    n_updates        | 18815    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3308     |\n|    fps              | 551      |\n|    time_elapsed     | 1111     |\n|    total_timesteps  | 612552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 18830    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3312     |\n|    fps              | 551      |\n|    time_elapsed     | 1111     |\n|    total_timesteps  | 612832   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 18838    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3316     |\n|    fps              | 551      |\n|    time_elapsed     | 1113     |\n|    total_timesteps  | 613864   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.153    |\n|    n_updates        | 18871    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3320     |\n|    fps              | 551      |\n|    time_elapsed     | 1114     |\n|    total_timesteps  | 614928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 18904    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3324     |\n|    fps              | 551      |\n|    time_elapsed     | 1115     |\n|    total_timesteps  | 615408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.12     |\n|    n_updates        | 18919    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3328     |\n|    fps              | 551      |\n|    time_elapsed     | 1116     |\n|    total_timesteps  | 615792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0718   |\n|    n_updates        | 18931    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3332     |\n|    fps              | 551      |\n|    time_elapsed     | 1117     |\n|    total_timesteps  | 616888   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 18965    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3336     |\n|    fps              | 552      |\n|    time_elapsed     | 1118     |\n|    total_timesteps  | 617672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.241    |\n|    n_updates        | 18990    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3340     |\n|    fps              | 552      |\n|    time_elapsed     | 1119     |\n|    total_timesteps  | 618256   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0659   |\n|    n_updates        | 19008    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3344     |\n|    fps              | 552      |\n|    time_elapsed     | 1120     |\n|    total_timesteps  | 619128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.17     |\n|    n_updates        | 19035    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3348     |\n|    fps              | 552      |\n|    time_elapsed     | 1121     |\n|    total_timesteps  | 619656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.17     |\n|    n_updates        | 19052    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3352     |\n|    fps              | 552      |\n|    time_elapsed     | 1123     |\n|    total_timesteps  | 620776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.3      |\n|    n_updates        | 19087    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3356     |\n|    fps              | 552      |\n|    time_elapsed     | 1123     |\n|    total_timesteps  | 621120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0642   |\n|    n_updates        | 19097    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3360     |\n|    fps              | 552      |\n|    time_elapsed     | 1125     |\n|    total_timesteps  | 622240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0483   |\n|    n_updates        | 19132    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3364     |\n|    fps              | 553      |\n|    time_elapsed     | 1127     |\n|    total_timesteps  | 623336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0626   |\n|    n_updates        | 19167    |\n----------------------------------\nEval num_timesteps=624000, episode_reward=588.00 +/- 84.00\nEpisode length: 2322.60 +/- 51.20\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.32e+03 |\n|    mean_reward      | 588      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 624000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.98     |\n|    n_updates        | 19187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3368     |\n|    fps              | 550      |\n|    time_elapsed     | 1134     |\n|    total_timesteps  | 624040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.05     |\n|    n_updates        | 19189    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3372     |\n|    fps              | 550      |\n|    time_elapsed     | 1134     |\n|    total_timesteps  | 624496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.02     |\n|    n_updates        | 19203    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3376     |\n|    fps              | 550      |\n|    time_elapsed     | 1136     |\n|    total_timesteps  | 625768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0591   |\n|    n_updates        | 19243    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3380     |\n|    fps              | 550      |\n|    time_elapsed     | 1137     |\n|    total_timesteps  | 626168   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0601   |\n|    n_updates        | 19255    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3384     |\n|    fps              | 550      |\n|    time_elapsed     | 1139     |\n|    total_timesteps  | 627688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.133    |\n|    n_updates        | 19303    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3388     |\n|    fps              | 551      |\n|    time_elapsed     | 1141     |\n|    total_timesteps  | 628992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 19343    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3392     |\n|    fps              | 551      |\n|    time_elapsed     | 1141     |\n|    total_timesteps  | 629416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.161    |\n|    n_updates        | 19357    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3396     |\n|    fps              | 551      |\n|    time_elapsed     | 1142     |\n|    total_timesteps  | 630184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0779   |\n|    n_updates        | 19381    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3400     |\n|    fps              | 551      |\n|    time_elapsed     | 1143     |\n|    total_timesteps  | 630760   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 19399    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3404     |\n|    fps              | 551      |\n|    time_elapsed     | 1144     |\n|    total_timesteps  | 631472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0762   |\n|    n_updates        | 19421    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3408     |\n|    fps              | 551      |\n|    time_elapsed     | 1145     |\n|    total_timesteps  | 631744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0825   |\n|    n_updates        | 19429    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3412     |\n|    fps              | 551      |\n|    time_elapsed     | 1146     |\n|    total_timesteps  | 632728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.095    |\n|    n_updates        | 19460    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3416     |\n|    fps              | 551      |\n|    time_elapsed     | 1146     |\n|    total_timesteps  | 632976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0507   |\n|    n_updates        | 19468    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3420     |\n|    fps              | 552      |\n|    time_elapsed     | 1147     |\n|    total_timesteps  | 633632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.15     |\n|    n_updates        | 19488    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3424     |\n|    fps              | 552      |\n|    time_elapsed     | 1149     |\n|    total_timesteps  | 634432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 19513    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3428     |\n|    fps              | 552      |\n|    time_elapsed     | 1149     |\n|    total_timesteps  | 634920   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0849   |\n|    n_updates        | 19529    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3432     |\n|    fps              | 552      |\n|    time_elapsed     | 1150     |\n|    total_timesteps  | 635664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0448   |\n|    n_updates        | 19552    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3436     |\n|    fps              | 552      |\n|    time_elapsed     | 1151     |\n|    total_timesteps  | 636296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 19572    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3440     |\n|    fps              | 552      |\n|    time_elapsed     | 1153     |\n|    total_timesteps  | 637296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.178    |\n|    n_updates        | 19603    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3444     |\n|    fps              | 552      |\n|    time_elapsed     | 1154     |\n|    total_timesteps  | 638392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 19637    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3448     |\n|    fps              | 552      |\n|    time_elapsed     | 1155     |\n|    total_timesteps  | 638776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 19649    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3452     |\n|    fps              | 553      |\n|    time_elapsed     | 1156     |\n|    total_timesteps  | 639320   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0527   |\n|    n_updates        | 19666    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3456     |\n|    fps              | 553      |\n|    time_elapsed     | 1157     |\n|    total_timesteps  | 639976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.085    |\n|    n_updates        | 19687    |\n----------------------------------\nEval num_timesteps=640000, episode_reward=148.00 +/- 21.35\nEpisode length: 2004.20 +/- 183.03\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2e+03    |\n|    mean_reward      | 148      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 640000   |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3460     |\n|    fps              | 550      |\n|    time_elapsed     | 1162     |\n|    total_timesteps  | 640360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0359   |\n|    n_updates        | 19699    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3464     |\n|    fps              | 550      |\n|    time_elapsed     | 1163     |\n|    total_timesteps  | 641056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.146    |\n|    n_updates        | 19720    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3468     |\n|    fps              | 550      |\n|    time_elapsed     | 1164     |\n|    total_timesteps  | 641560   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 19736    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3472     |\n|    fps              | 551      |\n|    time_elapsed     | 1165     |\n|    total_timesteps  | 642288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0546   |\n|    n_updates        | 19759    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3476     |\n|    fps              | 551      |\n|    time_elapsed     | 1166     |\n|    total_timesteps  | 642984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0702   |\n|    n_updates        | 19781    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3480     |\n|    fps              | 551      |\n|    time_elapsed     | 1168     |\n|    total_timesteps  | 644496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.143    |\n|    n_updates        | 19828    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3484     |\n|    fps              | 551      |\n|    time_elapsed     | 1169     |\n|    total_timesteps  | 644848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0762   |\n|    n_updates        | 19839    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3488     |\n|    fps              | 551      |\n|    time_elapsed     | 1170     |\n|    total_timesteps  | 645784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0449   |\n|    n_updates        | 19868    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3492     |\n|    fps              | 551      |\n|    time_elapsed     | 1171     |\n|    total_timesteps  | 646200   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0715   |\n|    n_updates        | 19881    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3496     |\n|    fps              | 551      |\n|    time_elapsed     | 1172     |\n|    total_timesteps  | 647144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.13     |\n|    n_updates        | 19911    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3500     |\n|    fps              | 552      |\n|    time_elapsed     | 1173     |\n|    total_timesteps  | 647600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 19925    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 168      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3504     |\n|    fps              | 552      |\n|    time_elapsed     | 1174     |\n|    total_timesteps  | 648688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.161    |\n|    n_updates        | 19959    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3508     |\n|    fps              | 552      |\n|    time_elapsed     | 1175     |\n|    total_timesteps  | 649344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0322   |\n|    n_updates        | 19979    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3512     |\n|    fps              | 552      |\n|    time_elapsed     | 1176     |\n|    total_timesteps  | 650136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0959   |\n|    n_updates        | 20004    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3516     |\n|    fps              | 552      |\n|    time_elapsed     | 1177     |\n|    total_timesteps  | 650872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 20027    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3520     |\n|    fps              | 552      |\n|    time_elapsed     | 1178     |\n|    total_timesteps  | 651496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0522   |\n|    n_updates        | 20047    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3524     |\n|    fps              | 552      |\n|    time_elapsed     | 1179     |\n|    total_timesteps  | 652208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0947   |\n|    n_updates        | 20069    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3528     |\n|    fps              | 553      |\n|    time_elapsed     | 1182     |\n|    total_timesteps  | 653792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0253   |\n|    n_updates        | 20118    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3532     |\n|    fps              | 553      |\n|    time_elapsed     | 1184     |\n|    total_timesteps  | 655232   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0725   |\n|    n_updates        | 20163    |\n----------------------------------\nEval num_timesteps=656000, episode_reward=76.00 +/- 4.90\nEpisode length: 2097.00 +/- 19.60\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.1e+03  |\n|    mean_reward      | 76       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 656000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0354   |\n|    n_updates        | 20187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3536     |\n|    fps              | 551      |\n|    time_elapsed     | 1190     |\n|    total_timesteps  | 656040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0497   |\n|    n_updates        | 20189    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3540     |\n|    fps              | 551      |\n|    time_elapsed     | 1191     |\n|    total_timesteps  | 656544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 20204    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3544     |\n|    fps              | 551      |\n|    time_elapsed     | 1193     |\n|    total_timesteps  | 657720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.178    |\n|    n_updates        | 20241    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3548     |\n|    fps              | 551      |\n|    time_elapsed     | 1194     |\n|    total_timesteps  | 658408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0929   |\n|    n_updates        | 20263    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3552     |\n|    fps              | 551      |\n|    time_elapsed     | 1195     |\n|    total_timesteps  | 659544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.131    |\n|    n_updates        | 20298    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3556     |\n|    fps              | 551      |\n|    time_elapsed     | 1197     |\n|    total_timesteps  | 660800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0565   |\n|    n_updates        | 20337    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3560     |\n|    fps              | 551      |\n|    time_elapsed     | 1198     |\n|    total_timesteps  | 661344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 20354    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3564     |\n|    fps              | 552      |\n|    time_elapsed     | 1199     |\n|    total_timesteps  | 662296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.133    |\n|    n_updates        | 20384    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 214      |\n|    ep_rew_mean      | 19.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3568     |\n|    fps              | 552      |\n|    time_elapsed     | 1201     |\n|    total_timesteps  | 663536   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0479   |\n|    n_updates        | 20423    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 217      |\n|    ep_rew_mean      | 19.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3572     |\n|    fps              | 552      |\n|    time_elapsed     | 1201     |\n|    total_timesteps  | 663680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0655   |\n|    n_updates        | 20427    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 218      |\n|    ep_rew_mean      | 19.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3576     |\n|    fps              | 552      |\n|    time_elapsed     | 1203     |\n|    total_timesteps  | 664640   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.967    |\n|    n_updates        | 20457    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 214      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3580     |\n|    fps              | 552      |\n|    time_elapsed     | 1204     |\n|    total_timesteps  | 665352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0905   |\n|    n_updates        | 20480    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 211      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3584     |\n|    fps              | 552      |\n|    time_elapsed     | 1205     |\n|    total_timesteps  | 666272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.236    |\n|    n_updates        | 20508    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 210      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3588     |\n|    fps              | 552      |\n|    time_elapsed     | 1206     |\n|    total_timesteps  | 667224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.138    |\n|    n_updates        | 20538    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 212      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3592     |\n|    fps              | 552      |\n|    time_elapsed     | 1207     |\n|    total_timesteps  | 667544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 20548    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 215      |\n|    ep_rew_mean      | 19.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3596     |\n|    fps              | 553      |\n|    time_elapsed     | 1208     |\n|    total_timesteps  | 668752   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.105    |\n|    n_updates        | 20586    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 214      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3600     |\n|    fps              | 553      |\n|    time_elapsed     | 1209     |\n|    total_timesteps  | 669336   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0479   |\n|    n_updates        | 20604    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 216      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3604     |\n|    fps              | 553      |\n|    time_elapsed     | 1210     |\n|    total_timesteps  | 670112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0519   |\n|    n_updates        | 20628    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 216      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3608     |\n|    fps              | 553      |\n|    time_elapsed     | 1212     |\n|    total_timesteps  | 671144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0912   |\n|    n_updates        | 20661    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 215      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3612     |\n|    fps              | 553      |\n|    time_elapsed     | 1212     |\n|    total_timesteps  | 671576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0619   |\n|    n_updates        | 20674    |\n----------------------------------\nEval num_timesteps=672000, episode_reward=132.00 +/- 9.80\nEpisode length: 1623.40 +/- 37.32\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.62e+03 |\n|    mean_reward      | 132      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 672000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 20687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 217      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3616     |\n|    fps              | 551      |\n|    time_elapsed     | 1218     |\n|    total_timesteps  | 672456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0641   |\n|    n_updates        | 20702    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 215      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3620     |\n|    fps              | 552      |\n|    time_elapsed     | 1219     |\n|    total_timesteps  | 673120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 20722    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 218      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3624     |\n|    fps              | 552      |\n|    time_elapsed     | 1221     |\n|    total_timesteps  | 674360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.18     |\n|    n_updates        | 20761    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 217      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3628     |\n|    fps              | 552      |\n|    time_elapsed     | 1222     |\n|    total_timesteps  | 675136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0617   |\n|    n_updates        | 20785    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 213      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3632     |\n|    fps              | 552      |\n|    time_elapsed     | 1222     |\n|    total_timesteps  | 675552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.129    |\n|    n_updates        | 20798    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3636     |\n|    fps              | 552      |\n|    time_elapsed     | 1224     |\n|    total_timesteps  | 676584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.29     |\n|    n_updates        | 20831    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3640     |\n|    fps              | 552      |\n|    time_elapsed     | 1225     |\n|    total_timesteps  | 677624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.063    |\n|    n_updates        | 20863    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 210      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3644     |\n|    fps              | 552      |\n|    time_elapsed     | 1226     |\n|    total_timesteps  | 677768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 20868    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3648     |\n|    fps              | 552      |\n|    time_elapsed     | 1227     |\n|    total_timesteps  | 678792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0632   |\n|    n_updates        | 20900    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3652     |\n|    fps              | 553      |\n|    time_elapsed     | 1228     |\n|    total_timesteps  | 679576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.21     |\n|    n_updates        | 20924    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3656     |\n|    fps              | 553      |\n|    time_elapsed     | 1229     |\n|    total_timesteps  | 680152   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.068    |\n|    n_updates        | 20942    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3660     |\n|    fps              | 553      |\n|    time_elapsed     | 1230     |\n|    total_timesteps  | 681032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 20970    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3664     |\n|    fps              | 553      |\n|    time_elapsed     | 1232     |\n|    total_timesteps  | 682256   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0777   |\n|    n_updates        | 21008    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3668     |\n|    fps              | 553      |\n|    time_elapsed     | 1233     |\n|    total_timesteps  | 683304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0467   |\n|    n_updates        | 21041    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3672     |\n|    fps              | 553      |\n|    time_elapsed     | 1234     |\n|    total_timesteps  | 683688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 21053    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3676     |\n|    fps              | 553      |\n|    time_elapsed     | 1235     |\n|    total_timesteps  | 684416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.203    |\n|    n_updates        | 21075    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3680     |\n|    fps              | 554      |\n|    time_elapsed     | 1236     |\n|    total_timesteps  | 685368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0594   |\n|    n_updates        | 21105    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3684     |\n|    fps              | 554      |\n|    time_elapsed     | 1238     |\n|    total_timesteps  | 686440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.22     |\n|    n_updates        | 21139    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3688     |\n|    fps              | 554      |\n|    time_elapsed     | 1239     |\n|    total_timesteps  | 687408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0832   |\n|    n_updates        | 21169    |\n----------------------------------\nEval num_timesteps=688000, episode_reward=210.00 +/- 0.00\nEpisode length: 1497.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.5e+03  |\n|    mean_reward      | 210      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 688000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0601   |\n|    n_updates        | 21187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3692     |\n|    fps              | 552      |\n|    time_elapsed     | 1245     |\n|    total_timesteps  | 688416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0803   |\n|    n_updates        | 21200    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3696     |\n|    fps              | 552      |\n|    time_elapsed     | 1245     |\n|    total_timesteps  | 689024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.264    |\n|    n_updates        | 21219    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3700     |\n|    fps              | 553      |\n|    time_elapsed     | 1246     |\n|    total_timesteps  | 689472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0691   |\n|    n_updates        | 21233    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3704     |\n|    fps              | 553      |\n|    time_elapsed     | 1248     |\n|    total_timesteps  | 690528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 21266    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3708     |\n|    fps              | 553      |\n|    time_elapsed     | 1249     |\n|    total_timesteps  | 691224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.037    |\n|    n_updates        | 21288    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3712     |\n|    fps              | 553      |\n|    time_elapsed     | 1249     |\n|    total_timesteps  | 691584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.123    |\n|    n_updates        | 21299    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3716     |\n|    fps              | 553      |\n|    time_elapsed     | 1250     |\n|    total_timesteps  | 692416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0348   |\n|    n_updates        | 21325    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3720     |\n|    fps              | 553      |\n|    time_elapsed     | 1252     |\n|    total_timesteps  | 693248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0619   |\n|    n_updates        | 21351    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3724     |\n|    fps              | 553      |\n|    time_elapsed     | 1253     |\n|    total_timesteps  | 694520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0817   |\n|    n_updates        | 21391    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3728     |\n|    fps              | 553      |\n|    time_elapsed     | 1254     |\n|    total_timesteps  | 694904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 21403    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3732     |\n|    fps              | 554      |\n|    time_elapsed     | 1255     |\n|    total_timesteps  | 695880   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0927   |\n|    n_updates        | 21434    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 19.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3736     |\n|    fps              | 554      |\n|    time_elapsed     | 1257     |\n|    total_timesteps  | 697016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 21469    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3740     |\n|    fps              | 554      |\n|    time_elapsed     | 1258     |\n|    total_timesteps  | 697808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.161    |\n|    n_updates        | 21494    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3744     |\n|    fps              | 554      |\n|    time_elapsed     | 1259     |\n|    total_timesteps  | 698352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.04     |\n|    n_updates        | 21511    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3748     |\n|    fps              | 554      |\n|    time_elapsed     | 1260     |\n|    total_timesteps  | 699248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0697   |\n|    n_updates        | 21539    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3752     |\n|    fps              | 554      |\n|    time_elapsed     | 1261     |\n|    total_timesteps  | 699784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0562   |\n|    n_updates        | 21556    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3756     |\n|    fps              | 554      |\n|    time_elapsed     | 1262     |\n|    total_timesteps  | 700552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 21580    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3760     |\n|    fps              | 555      |\n|    time_elapsed     | 1262     |\n|    total_timesteps  | 700968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.14     |\n|    n_updates        | 21593    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3764     |\n|    fps              | 555      |\n|    time_elapsed     | 1263     |\n|    total_timesteps  | 701632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.23     |\n|    n_updates        | 21613    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3768     |\n|    fps              | 555      |\n|    time_elapsed     | 1265     |\n|    total_timesteps  | 702624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0652   |\n|    n_updates        | 21644    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3772     |\n|    fps              | 555      |\n|    time_elapsed     | 1265     |\n|    total_timesteps  | 703112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.169    |\n|    n_updates        | 21660    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3776     |\n|    fps              | 555      |\n|    time_elapsed     | 1267     |\n|    total_timesteps  | 703944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.15     |\n|    n_updates        | 21686    |\n----------------------------------\nEval num_timesteps=704000, episode_reward=816.00 +/- 780.17\nEpisode length: 2178.60 +/- 542.62\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.18e+03 |\n|    mean_reward      | 816      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 704000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 21687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3780     |\n|    fps              | 553      |\n|    time_elapsed     | 1273     |\n|    total_timesteps  | 704328   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0365   |\n|    n_updates        | 21698    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3784     |\n|    fps              | 553      |\n|    time_elapsed     | 1274     |\n|    total_timesteps  | 705360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.153    |\n|    n_updates        | 21730    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3788     |\n|    fps              | 553      |\n|    time_elapsed     | 1275     |\n|    total_timesteps  | 705776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 21743    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3792     |\n|    fps              | 553      |\n|    time_elapsed     | 1276     |\n|    total_timesteps  | 706464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0372   |\n|    n_updates        | 21764    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3796     |\n|    fps              | 553      |\n|    time_elapsed     | 1277     |\n|    total_timesteps  | 707360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0362   |\n|    n_updates        | 21792    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3800     |\n|    fps              | 553      |\n|    time_elapsed     | 1278     |\n|    total_timesteps  | 707928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0515   |\n|    n_updates        | 21810    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3804     |\n|    fps              | 553      |\n|    time_elapsed     | 1279     |\n|    total_timesteps  | 708888   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0856   |\n|    n_updates        | 21840    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3808     |\n|    fps              | 553      |\n|    time_elapsed     | 1280     |\n|    total_timesteps  | 709312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.235    |\n|    n_updates        | 21853    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3812     |\n|    fps              | 554      |\n|    time_elapsed     | 1282     |\n|    total_timesteps  | 710616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0925   |\n|    n_updates        | 21894    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3816     |\n|    fps              | 554      |\n|    time_elapsed     | 1283     |\n|    total_timesteps  | 711488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.139    |\n|    n_updates        | 21921    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3820     |\n|    fps              | 554      |\n|    time_elapsed     | 1284     |\n|    total_timesteps  | 712312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 21947    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 14.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3824     |\n|    fps              | 554      |\n|    time_elapsed     | 1285     |\n|    total_timesteps  | 712632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.381    |\n|    n_updates        | 21957    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3828     |\n|    fps              | 554      |\n|    time_elapsed     | 1285     |\n|    total_timesteps  | 713184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.157    |\n|    n_updates        | 21974    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3832     |\n|    fps              | 554      |\n|    time_elapsed     | 1286     |\n|    total_timesteps  | 713896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.341    |\n|    n_updates        | 21997    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3836     |\n|    fps              | 554      |\n|    time_elapsed     | 1287     |\n|    total_timesteps  | 714528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0787   |\n|    n_updates        | 22016    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 15.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3840     |\n|    fps              | 555      |\n|    time_elapsed     | 1289     |\n|    total_timesteps  | 715624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0544   |\n|    n_updates        | 22051    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 15       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3844     |\n|    fps              | 555      |\n|    time_elapsed     | 1290     |\n|    total_timesteps  | 716344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.117    |\n|    n_updates        | 22073    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3848     |\n|    fps              | 555      |\n|    time_elapsed     | 1291     |\n|    total_timesteps  | 716904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.17     |\n|    n_updates        | 22091    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3852     |\n|    fps              | 555      |\n|    time_elapsed     | 1292     |\n|    total_timesteps  | 717824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0448   |\n|    n_updates        | 22119    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3856     |\n|    fps              | 555      |\n|    time_elapsed     | 1293     |\n|    total_timesteps  | 718240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.133    |\n|    n_updates        | 22132    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3860     |\n|    fps              | 555      |\n|    time_elapsed     | 1294     |\n|    total_timesteps  | 718928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0498   |\n|    n_updates        | 22154    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3864     |\n|    fps              | 555      |\n|    time_elapsed     | 1295     |\n|    total_timesteps  | 719680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 22177    |\n----------------------------------\nEval num_timesteps=720000, episode_reward=520.00 +/- 214.66\nEpisode length: 2618.60 +/- 976.69\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.62e+03 |\n|    mean_reward      | 520      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 720000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0661   |\n|    n_updates        | 22187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3868     |\n|    fps              | 552      |\n|    time_elapsed     | 1303     |\n|    total_timesteps  | 720456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0476   |\n|    n_updates        | 22202    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3872     |\n|    fps              | 552      |\n|    time_elapsed     | 1304     |\n|    total_timesteps  | 721128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.875    |\n|    n_updates        | 22223    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3876     |\n|    fps              | 553      |\n|    time_elapsed     | 1305     |\n|    total_timesteps  | 722216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0835   |\n|    n_updates        | 22257    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3880     |\n|    fps              | 553      |\n|    time_elapsed     | 1306     |\n|    total_timesteps  | 722768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0856   |\n|    n_updates        | 22274    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3884     |\n|    fps              | 553      |\n|    time_elapsed     | 1307     |\n|    total_timesteps  | 723384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 22293    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3888     |\n|    fps              | 553      |\n|    time_elapsed     | 1308     |\n|    total_timesteps  | 724288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.133    |\n|    n_updates        | 22321    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3892     |\n|    fps              | 553      |\n|    time_elapsed     | 1309     |\n|    total_timesteps  | 725056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0629   |\n|    n_updates        | 22345    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3896     |\n|    fps              | 553      |\n|    time_elapsed     | 1311     |\n|    total_timesteps  | 726112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0836   |\n|    n_updates        | 22378    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3900     |\n|    fps              | 553      |\n|    time_elapsed     | 1311     |\n|    total_timesteps  | 726736   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.09     |\n|    n_updates        | 22398    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3904     |\n|    fps              | 554      |\n|    time_elapsed     | 1312     |\n|    total_timesteps  | 727416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0575   |\n|    n_updates        | 22419    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3908     |\n|    fps              | 554      |\n|    time_elapsed     | 1313     |\n|    total_timesteps  | 727840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0618   |\n|    n_updates        | 22432    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3912     |\n|    fps              | 554      |\n|    time_elapsed     | 1316     |\n|    total_timesteps  | 729696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.115    |\n|    n_updates        | 22490    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3916     |\n|    fps              | 554      |\n|    time_elapsed     | 1317     |\n|    total_timesteps  | 730688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0293   |\n|    n_updates        | 22521    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3920     |\n|    fps              | 554      |\n|    time_elapsed     | 1318     |\n|    total_timesteps  | 731088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.35     |\n|    n_updates        | 22534    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3924     |\n|    fps              | 554      |\n|    time_elapsed     | 1319     |\n|    total_timesteps  | 732000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0773   |\n|    n_updates        | 22562    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3928     |\n|    fps              | 554      |\n|    time_elapsed     | 1320     |\n|    total_timesteps  | 732656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0585   |\n|    n_updates        | 22583    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3932     |\n|    fps              | 554      |\n|    time_elapsed     | 1321     |\n|    total_timesteps  | 733384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.05     |\n|    n_updates        | 22606    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3936     |\n|    fps              | 555      |\n|    time_elapsed     | 1321     |\n|    total_timesteps  | 733712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.15     |\n|    n_updates        | 22616    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3940     |\n|    fps              | 555      |\n|    time_elapsed     | 1322     |\n|    total_timesteps  | 734272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0614   |\n|    n_updates        | 22633    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3944     |\n|    fps              | 555      |\n|    time_elapsed     | 1324     |\n|    total_timesteps  | 735744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0766   |\n|    n_updates        | 22679    |\n----------------------------------\nEval num_timesteps=736000, episode_reward=260.00 +/- 192.98\nEpisode length: 1796.20 +/- 385.92\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.8e+03  |\n|    mean_reward      | 260      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 736000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0787   |\n|    n_updates        | 22687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3948     |\n|    fps              | 553      |\n|    time_elapsed     | 1329     |\n|    total_timesteps  | 736032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0635   |\n|    n_updates        | 22688    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3952     |\n|    fps              | 553      |\n|    time_elapsed     | 1330     |\n|    total_timesteps  | 736376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0805   |\n|    n_updates        | 22699    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3956     |\n|    fps              | 553      |\n|    time_elapsed     | 1331     |\n|    total_timesteps  | 737352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0389   |\n|    n_updates        | 22730    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3960     |\n|    fps              | 553      |\n|    time_elapsed     | 1333     |\n|    total_timesteps  | 738816   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.228    |\n|    n_updates        | 22775    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3964     |\n|    fps              | 553      |\n|    time_elapsed     | 1335     |\n|    total_timesteps  | 739600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0573   |\n|    n_updates        | 22800    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3968     |\n|    fps              | 554      |\n|    time_elapsed     | 1335     |\n|    total_timesteps  | 740152   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0798   |\n|    n_updates        | 22817    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3972     |\n|    fps              | 554      |\n|    time_elapsed     | 1337     |\n|    total_timesteps  | 740984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0801   |\n|    n_updates        | 22843    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3976     |\n|    fps              | 554      |\n|    time_elapsed     | 1338     |\n|    total_timesteps  | 741976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0645   |\n|    n_updates        | 22874    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3980     |\n|    fps              | 554      |\n|    time_elapsed     | 1339     |\n|    total_timesteps  | 742576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.145    |\n|    n_updates        | 22893    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3984     |\n|    fps              | 554      |\n|    time_elapsed     | 1339     |\n|    total_timesteps  | 742960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0891   |\n|    n_updates        | 22905    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3988     |\n|    fps              | 554      |\n|    time_elapsed     | 1340     |\n|    total_timesteps  | 743528   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.07     |\n|    n_updates        | 22923    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3992     |\n|    fps              | 554      |\n|    time_elapsed     | 1341     |\n|    total_timesteps  | 744088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 22940    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 3996     |\n|    fps              | 554      |\n|    time_elapsed     | 1342     |\n|    total_timesteps  | 744912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0664   |\n|    n_updates        | 22966    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4000     |\n|    fps              | 554      |\n|    time_elapsed     | 1344     |\n|    total_timesteps  | 745856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.376    |\n|    n_updates        | 22995    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4004     |\n|    fps              | 555      |\n|    time_elapsed     | 1345     |\n|    total_timesteps  | 746624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0718   |\n|    n_updates        | 23019    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4008     |\n|    fps              | 555      |\n|    time_elapsed     | 1346     |\n|    total_timesteps  | 747616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 23050    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4012     |\n|    fps              | 555      |\n|    time_elapsed     | 1347     |\n|    total_timesteps  | 748352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.127    |\n|    n_updates        | 23073    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4016     |\n|    fps              | 555      |\n|    time_elapsed     | 1348     |\n|    total_timesteps  | 749232   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 23101    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4020     |\n|    fps              | 555      |\n|    time_elapsed     | 1350     |\n|    total_timesteps  | 750176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 23130    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4024     |\n|    fps              | 555      |\n|    time_elapsed     | 1351     |\n|    total_timesteps  | 750904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0885   |\n|    n_updates        | 23153    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4028     |\n|    fps              | 555      |\n|    time_elapsed     | 1352     |\n|    total_timesteps  | 751488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 23171    |\n----------------------------------\nEval num_timesteps=752000, episode_reward=242.00 +/- 46.65\nEpisode length: 2167.40 +/- 577.92\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.17e+03 |\n|    mean_reward      | 242      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 752000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0449   |\n|    n_updates        | 23187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4032     |\n|    fps              | 553      |\n|    time_elapsed     | 1358     |\n|    total_timesteps  | 752192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 23193    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4036     |\n|    fps              | 553      |\n|    time_elapsed     | 1359     |\n|    total_timesteps  | 753024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.966    |\n|    n_updates        | 23219    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4040     |\n|    fps              | 553      |\n|    time_elapsed     | 1361     |\n|    total_timesteps  | 753912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.268    |\n|    n_updates        | 23247    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4044     |\n|    fps              | 554      |\n|    time_elapsed     | 1362     |\n|    total_timesteps  | 754584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.107    |\n|    n_updates        | 23268    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4048     |\n|    fps              | 554      |\n|    time_elapsed     | 1363     |\n|    total_timesteps  | 755432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.293    |\n|    n_updates        | 23295    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4052     |\n|    fps              | 554      |\n|    time_elapsed     | 1364     |\n|    total_timesteps  | 756400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0565   |\n|    n_updates        | 23325    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4056     |\n|    fps              | 554      |\n|    time_elapsed     | 1365     |\n|    total_timesteps  | 756648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.152    |\n|    n_updates        | 23333    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4060     |\n|    fps              | 554      |\n|    time_elapsed     | 1366     |\n|    total_timesteps  | 757824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.08     |\n|    n_updates        | 23369    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4064     |\n|    fps              | 554      |\n|    time_elapsed     | 1368     |\n|    total_timesteps  | 758840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0689   |\n|    n_updates        | 23401    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4068     |\n|    fps              | 554      |\n|    time_elapsed     | 1369     |\n|    total_timesteps  | 759632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.152    |\n|    n_updates        | 23426    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4072     |\n|    fps              | 554      |\n|    time_elapsed     | 1370     |\n|    total_timesteps  | 760504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.209    |\n|    n_updates        | 23453    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4076     |\n|    fps              | 554      |\n|    time_elapsed     | 1371     |\n|    total_timesteps  | 761040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.904    |\n|    n_updates        | 23470    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4080     |\n|    fps              | 555      |\n|    time_elapsed     | 1372     |\n|    total_timesteps  | 761824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 23494    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4084     |\n|    fps              | 555      |\n|    time_elapsed     | 1374     |\n|    total_timesteps  | 763560   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0883   |\n|    n_updates        | 23549    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4088     |\n|    fps              | 555      |\n|    time_elapsed     | 1375     |\n|    total_timesteps  | 764128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.818    |\n|    n_updates        | 23566    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4092     |\n|    fps              | 555      |\n|    time_elapsed     | 1376     |\n|    total_timesteps  | 764928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0937   |\n|    n_updates        | 23591    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4096     |\n|    fps              | 555      |\n|    time_elapsed     | 1377     |\n|    total_timesteps  | 765672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0516   |\n|    n_updates        | 23615    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4100     |\n|    fps              | 555      |\n|    time_elapsed     | 1379     |\n|    total_timesteps  | 766824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0889   |\n|    n_updates        | 23651    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 210      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4104     |\n|    fps              | 556      |\n|    time_elapsed     | 1380     |\n|    total_timesteps  | 767784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.1      |\n|    n_updates        | 23681    |\n----------------------------------\nEval num_timesteps=768000, episode_reward=60.00 +/- 0.00\nEpisode length: 1412.20 +/- 102.40\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.41e+03 |\n|    mean_reward      | 60       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 768000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0671   |\n|    n_updates        | 23687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 213      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4108     |\n|    fps              | 554      |\n|    time_elapsed     | 1386     |\n|    total_timesteps  | 769040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.123    |\n|    n_updates        | 23720    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 211      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4112     |\n|    fps              | 554      |\n|    time_elapsed     | 1387     |\n|    total_timesteps  | 769904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.044    |\n|    n_updates        | 23747    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 219      |\n|    ep_rew_mean      | 19.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4116     |\n|    fps              | 555      |\n|    time_elapsed     | 1388     |\n|    total_timesteps  | 770672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0971   |\n|    n_updates        | 23771    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 217      |\n|    ep_rew_mean      | 19.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4120     |\n|    fps              | 555      |\n|    time_elapsed     | 1389     |\n|    total_timesteps  | 771048   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 23783    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 214      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4124     |\n|    fps              | 555      |\n|    time_elapsed     | 1390     |\n|    total_timesteps  | 771768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.92     |\n|    n_updates        | 23805    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4128     |\n|    fps              | 555      |\n|    time_elapsed     | 1390     |\n|    total_timesteps  | 772264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 23821    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4132     |\n|    fps              | 555      |\n|    time_elapsed     | 1391     |\n|    total_timesteps  | 772912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 23841    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4136     |\n|    fps              | 555      |\n|    time_elapsed     | 1392     |\n|    total_timesteps  | 773552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0611   |\n|    n_updates        | 23861    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4140     |\n|    fps              | 555      |\n|    time_elapsed     | 1393     |\n|    total_timesteps  | 774272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0651   |\n|    n_updates        | 23883    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4144     |\n|    fps              | 555      |\n|    time_elapsed     | 1395     |\n|    total_timesteps  | 775264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 23914    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4148     |\n|    fps              | 555      |\n|    time_elapsed     | 1396     |\n|    total_timesteps  | 775984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.289    |\n|    n_updates        | 23937    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4152     |\n|    fps              | 555      |\n|    time_elapsed     | 1397     |\n|    total_timesteps  | 776792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0625   |\n|    n_updates        | 23962    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 208      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4156     |\n|    fps              | 556      |\n|    time_elapsed     | 1398     |\n|    total_timesteps  | 777456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0888   |\n|    n_updates        | 23983    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4160     |\n|    fps              | 556      |\n|    time_elapsed     | 1399     |\n|    total_timesteps  | 778392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 24012    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 209      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4164     |\n|    fps              | 556      |\n|    time_elapsed     | 1401     |\n|    total_timesteps  | 779520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0557   |\n|    n_updates        | 24047    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4168     |\n|    fps              | 556      |\n|    time_elapsed     | 1402     |\n|    total_timesteps  | 780184   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.211    |\n|    n_updates        | 24068    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4172     |\n|    fps              | 556      |\n|    time_elapsed     | 1403     |\n|    total_timesteps  | 780840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0755   |\n|    n_updates        | 24089    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4176     |\n|    fps              | 556      |\n|    time_elapsed     | 1404     |\n|    total_timesteps  | 781616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0484   |\n|    n_updates        | 24113    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4180     |\n|    fps              | 556      |\n|    time_elapsed     | 1404     |\n|    total_timesteps  | 782112   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.08     |\n|    n_updates        | 24128    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4184     |\n|    fps              | 556      |\n|    time_elapsed     | 1406     |\n|    total_timesteps  | 783568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0517   |\n|    n_updates        | 24174    |\n----------------------------------\nEval num_timesteps=784000, episode_reward=540.00 +/- 244.79\nEpisode length: 2338.60 +/- 559.53\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.34e+03 |\n|    mean_reward      | 540      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 784000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0565   |\n|    n_updates        | 24187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4188     |\n|    fps              | 554      |\n|    time_elapsed     | 1413     |\n|    total_timesteps  | 784288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.1      |\n|    n_updates        | 24196    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4192     |\n|    fps              | 554      |\n|    time_elapsed     | 1414     |\n|    total_timesteps  | 784744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0561   |\n|    n_updates        | 24211    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4196     |\n|    fps              | 554      |\n|    time_elapsed     | 1415     |\n|    total_timesteps  | 785192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.95     |\n|    n_updates        | 24225    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4200     |\n|    fps              | 554      |\n|    time_elapsed     | 1416     |\n|    total_timesteps  | 786224   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0948   |\n|    n_updates        | 24257    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4204     |\n|    fps              | 555      |\n|    time_elapsed     | 1417     |\n|    total_timesteps  | 786992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.04     |\n|    n_updates        | 24281    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4208     |\n|    fps              | 555      |\n|    time_elapsed     | 1418     |\n|    total_timesteps  | 787504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 24297    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4212     |\n|    fps              | 555      |\n|    time_elapsed     | 1420     |\n|    total_timesteps  | 789056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0886   |\n|    n_updates        | 24345    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4216     |\n|    fps              | 555      |\n|    time_elapsed     | 1422     |\n|    total_timesteps  | 790032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0687   |\n|    n_updates        | 24376    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4220     |\n|    fps              | 555      |\n|    time_elapsed     | 1422     |\n|    total_timesteps  | 790568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0658   |\n|    n_updates        | 24393    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4224     |\n|    fps              | 555      |\n|    time_elapsed     | 1423     |\n|    total_timesteps  | 791296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0346   |\n|    n_updates        | 24415    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4228     |\n|    fps              | 555      |\n|    time_elapsed     | 1424     |\n|    total_timesteps  | 791872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 24433    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4232     |\n|    fps              | 555      |\n|    time_elapsed     | 1425     |\n|    total_timesteps  | 792696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 24459    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4236     |\n|    fps              | 555      |\n|    time_elapsed     | 1426     |\n|    total_timesteps  | 793056   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.049    |\n|    n_updates        | 24470    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4240     |\n|    fps              | 556      |\n|    time_elapsed     | 1427     |\n|    total_timesteps  | 793712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.111    |\n|    n_updates        | 24491    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4244     |\n|    fps              | 556      |\n|    time_elapsed     | 1428     |\n|    total_timesteps  | 794448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.854    |\n|    n_updates        | 24514    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4248     |\n|    fps              | 556      |\n|    time_elapsed     | 1429     |\n|    total_timesteps  | 795064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.079    |\n|    n_updates        | 24533    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4252     |\n|    fps              | 556      |\n|    time_elapsed     | 1430     |\n|    total_timesteps  | 795984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0447   |\n|    n_updates        | 24562    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4256     |\n|    fps              | 556      |\n|    time_elapsed     | 1431     |\n|    total_timesteps  | 796600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0313   |\n|    n_updates        | 24581    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4260     |\n|    fps              | 556      |\n|    time_elapsed     | 1432     |\n|    total_timesteps  | 797208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0464   |\n|    n_updates        | 24600    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4264     |\n|    fps              | 556      |\n|    time_elapsed     | 1433     |\n|    total_timesteps  | 797616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0766   |\n|    n_updates        | 24613    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4268     |\n|    fps              | 556      |\n|    time_elapsed     | 1434     |\n|    total_timesteps  | 798696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 24647    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4272     |\n|    fps              | 556      |\n|    time_elapsed     | 1435     |\n|    total_timesteps  | 799616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0363   |\n|    n_updates        | 24675    |\n----------------------------------\nEval num_timesteps=800000, episode_reward=272.00 +/- 124.48\nEpisode length: 1817.00 +/- 527.20\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.82e+03 |\n|    mean_reward      | 272      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 800000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0583   |\n|    n_updates        | 24687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4276     |\n|    fps              | 555      |\n|    time_elapsed     | 1441     |\n|    total_timesteps  | 800600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0502   |\n|    n_updates        | 24706    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4280     |\n|    fps              | 555      |\n|    time_elapsed     | 1442     |\n|    total_timesteps  | 800976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0844   |\n|    n_updates        | 24718    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4284     |\n|    fps              | 555      |\n|    time_elapsed     | 1443     |\n|    total_timesteps  | 801576   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.162    |\n|    n_updates        | 24737    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4288     |\n|    fps              | 555      |\n|    time_elapsed     | 1444     |\n|    total_timesteps  | 802320   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.125    |\n|    n_updates        | 24760    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4292     |\n|    fps              | 555      |\n|    time_elapsed     | 1446     |\n|    total_timesteps  | 803464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0912   |\n|    n_updates        | 24796    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4296     |\n|    fps              | 555      |\n|    time_elapsed     | 1447     |\n|    total_timesteps  | 804480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0614   |\n|    n_updates        | 24827    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4300     |\n|    fps              | 555      |\n|    time_elapsed     | 1448     |\n|    total_timesteps  | 805216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.033    |\n|    n_updates        | 24850    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4304     |\n|    fps              | 555      |\n|    time_elapsed     | 1449     |\n|    total_timesteps  | 805696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.938    |\n|    n_updates        | 24865    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4308     |\n|    fps              | 556      |\n|    time_elapsed     | 1450     |\n|    total_timesteps  | 806648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.01     |\n|    n_updates        | 24895    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4312     |\n|    fps              | 556      |\n|    time_elapsed     | 1452     |\n|    total_timesteps  | 807848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.104    |\n|    n_updates        | 24933    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4316     |\n|    fps              | 556      |\n|    time_elapsed     | 1453     |\n|    total_timesteps  | 808952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.01     |\n|    n_updates        | 24967    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4320     |\n|    fps              | 556      |\n|    time_elapsed     | 1454     |\n|    total_timesteps  | 809192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0578   |\n|    n_updates        | 24975    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4324     |\n|    fps              | 556      |\n|    time_elapsed     | 1455     |\n|    total_timesteps  | 810304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0572   |\n|    n_updates        | 25009    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4328     |\n|    fps              | 556      |\n|    time_elapsed     | 1456     |\n|    total_timesteps  | 810800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.94     |\n|    n_updates        | 25025    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4332     |\n|    fps              | 556      |\n|    time_elapsed     | 1457     |\n|    total_timesteps  | 811784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0861   |\n|    n_updates        | 25056    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4336     |\n|    fps              | 556      |\n|    time_elapsed     | 1458     |\n|    total_timesteps  | 812240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.121    |\n|    n_updates        | 25070    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4340     |\n|    fps              | 557      |\n|    time_elapsed     | 1460     |\n|    total_timesteps  | 813392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.156    |\n|    n_updates        | 25106    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4344     |\n|    fps              | 557      |\n|    time_elapsed     | 1460     |\n|    total_timesteps  | 813808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0345   |\n|    n_updates        | 25119    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4348     |\n|    fps              | 557      |\n|    time_elapsed     | 1462     |\n|    total_timesteps  | 814928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.974    |\n|    n_updates        | 25154    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4352     |\n|    fps              | 557      |\n|    time_elapsed     | 1463     |\n|    total_timesteps  | 815696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0924   |\n|    n_updates        | 25178    |\n----------------------------------\nEval num_timesteps=816000, episode_reward=70.00 +/- 0.00\nEpisode length: 2113.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.11e+03 |\n|    mean_reward      | 70       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 816000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.202    |\n|    n_updates        | 25187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 19.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4356     |\n|    fps              | 555      |\n|    time_elapsed     | 1470     |\n|    total_timesteps  | 816624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.07     |\n|    n_updates        | 25207    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4360     |\n|    fps              | 555      |\n|    time_elapsed     | 1471     |\n|    total_timesteps  | 817496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0458   |\n|    n_updates        | 25234    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4364     |\n|    fps              | 555      |\n|    time_elapsed     | 1472     |\n|    total_timesteps  | 818144   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0456   |\n|    n_updates        | 25254    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4368     |\n|    fps              | 555      |\n|    time_elapsed     | 1473     |\n|    total_timesteps  | 818800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0596   |\n|    n_updates        | 25275    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4372     |\n|    fps              | 555      |\n|    time_elapsed     | 1475     |\n|    total_timesteps  | 820080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0619   |\n|    n_updates        | 25315    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 19.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4376     |\n|    fps              | 556      |\n|    time_elapsed     | 1476     |\n|    total_timesteps  | 820840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.306    |\n|    n_updates        | 25339    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4380     |\n|    fps              | 556      |\n|    time_elapsed     | 1477     |\n|    total_timesteps  | 821520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0502   |\n|    n_updates        | 25360    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 19.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4384     |\n|    fps              | 556      |\n|    time_elapsed     | 1478     |\n|    total_timesteps  | 822280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0737   |\n|    n_updates        | 25384    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4388     |\n|    fps              | 556      |\n|    time_elapsed     | 1479     |\n|    total_timesteps  | 823088   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.04     |\n|    n_updates        | 25409    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4392     |\n|    fps              | 556      |\n|    time_elapsed     | 1481     |\n|    total_timesteps  | 824264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0475   |\n|    n_updates        | 25446    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 19.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4396     |\n|    fps              | 556      |\n|    time_elapsed     | 1482     |\n|    total_timesteps  | 825208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0945   |\n|    n_updates        | 25475    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 19.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4400     |\n|    fps              | 556      |\n|    time_elapsed     | 1482     |\n|    total_timesteps  | 825480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0937   |\n|    n_updates        | 25484    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 19.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4404     |\n|    fps              | 556      |\n|    time_elapsed     | 1484     |\n|    total_timesteps  | 826464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.04     |\n|    n_updates        | 25514    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4408     |\n|    fps              | 556      |\n|    time_elapsed     | 1485     |\n|    total_timesteps  | 827216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.872    |\n|    n_updates        | 25538    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 19.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4412     |\n|    fps              | 557      |\n|    time_elapsed     | 1486     |\n|    total_timesteps  | 827976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.03     |\n|    n_updates        | 25562    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4416     |\n|    fps              | 557      |\n|    time_elapsed     | 1487     |\n|    total_timesteps  | 828936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.25     |\n|    n_updates        | 25592    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4420     |\n|    fps              | 557      |\n|    time_elapsed     | 1489     |\n|    total_timesteps  | 829976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.038    |\n|    n_updates        | 25624    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4424     |\n|    fps              | 557      |\n|    time_elapsed     | 1489     |\n|    total_timesteps  | 830520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 25641    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4428     |\n|    fps              | 557      |\n|    time_elapsed     | 1491     |\n|    total_timesteps  | 831440   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.103    |\n|    n_updates        | 25670    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4432     |\n|    fps              | 557      |\n|    time_elapsed     | 1491     |\n|    total_timesteps  | 831584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 25674    |\n----------------------------------\nEval num_timesteps=832000, episode_reward=250.00 +/- 0.00\nEpisode length: 1940.20 +/- 3.92\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.94e+03 |\n|    mean_reward      | 250      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 832000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.935    |\n|    n_updates        | 25687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4436     |\n|    fps              | 555      |\n|    time_elapsed     | 1498     |\n|    total_timesteps  | 832704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.3      |\n|    n_updates        | 25709    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4440     |\n|    fps              | 555      |\n|    time_elapsed     | 1498     |\n|    total_timesteps  | 833032   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.161    |\n|    n_updates        | 25720    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4444     |\n|    fps              | 556      |\n|    time_elapsed     | 1499     |\n|    total_timesteps  | 833944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.77     |\n|    n_updates        | 25748    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4448     |\n|    fps              | 556      |\n|    time_elapsed     | 1500     |\n|    total_timesteps  | 834264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0308   |\n|    n_updates        | 25758    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4452     |\n|    fps              | 556      |\n|    time_elapsed     | 1501     |\n|    total_timesteps  | 835360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0596   |\n|    n_updates        | 25792    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4456     |\n|    fps              | 556      |\n|    time_elapsed     | 1502     |\n|    total_timesteps  | 835960   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.255    |\n|    n_updates        | 25811    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4460     |\n|    fps              | 556      |\n|    time_elapsed     | 1504     |\n|    total_timesteps  | 836984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 25843    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4464     |\n|    fps              | 556      |\n|    time_elapsed     | 1505     |\n|    total_timesteps  | 837808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0202   |\n|    n_updates        | 25869    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4468     |\n|    fps              | 556      |\n|    time_elapsed     | 1506     |\n|    total_timesteps  | 838520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.1      |\n|    n_updates        | 25891    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4472     |\n|    fps              | 556      |\n|    time_elapsed     | 1507     |\n|    total_timesteps  | 839216   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0972   |\n|    n_updates        | 25913    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4476     |\n|    fps              | 556      |\n|    time_elapsed     | 1509     |\n|    total_timesteps  | 840552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.06     |\n|    n_updates        | 25955    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4480     |\n|    fps              | 556      |\n|    time_elapsed     | 1509     |\n|    total_timesteps  | 840728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 2.2      |\n|    n_updates        | 25960    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4484     |\n|    fps              | 557      |\n|    time_elapsed     | 1510     |\n|    total_timesteps  | 841728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0668   |\n|    n_updates        | 25991    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4488     |\n|    fps              | 557      |\n|    time_elapsed     | 1511     |\n|    total_timesteps  | 842016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0721   |\n|    n_updates        | 26000    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4492     |\n|    fps              | 557      |\n|    time_elapsed     | 1512     |\n|    total_timesteps  | 842952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 26030    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4496     |\n|    fps              | 557      |\n|    time_elapsed     | 1513     |\n|    total_timesteps  | 843696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0677   |\n|    n_updates        | 26053    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4500     |\n|    fps              | 557      |\n|    time_elapsed     | 1515     |\n|    total_timesteps  | 844544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.09     |\n|    n_updates        | 26079    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4504     |\n|    fps              | 557      |\n|    time_elapsed     | 1516     |\n|    total_timesteps  | 845272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.882    |\n|    n_updates        | 26102    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4508     |\n|    fps              | 557      |\n|    time_elapsed     | 1517     |\n|    total_timesteps  | 846128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0775   |\n|    n_updates        | 26129    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4512     |\n|    fps              | 557      |\n|    time_elapsed     | 1518     |\n|    total_timesteps  | 846712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0785   |\n|    n_updates        | 26147    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4516     |\n|    fps              | 557      |\n|    time_elapsed     | 1518     |\n|    total_timesteps  | 847248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.191    |\n|    n_updates        | 26164    |\n----------------------------------\nEval num_timesteps=848000, episode_reward=330.00 +/- 97.98\nEpisode length: 2791.40 +/- 246.91\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.79e+03 |\n|    mean_reward      | 330      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 848000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.029    |\n|    n_updates        | 26187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4520     |\n|    fps              | 555      |\n|    time_elapsed     | 1527     |\n|    total_timesteps  | 848152   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.052    |\n|    n_updates        | 26192    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4524     |\n|    fps              | 555      |\n|    time_elapsed     | 1528     |\n|    total_timesteps  | 848992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.962    |\n|    n_updates        | 26218    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4528     |\n|    fps              | 555      |\n|    time_elapsed     | 1529     |\n|    total_timesteps  | 849584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.377    |\n|    n_updates        | 26237    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4532     |\n|    fps              | 555      |\n|    time_elapsed     | 1530     |\n|    total_timesteps  | 850408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.091    |\n|    n_updates        | 26263    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4536     |\n|    fps              | 555      |\n|    time_elapsed     | 1531     |\n|    total_timesteps  | 851064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 26283    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4540     |\n|    fps              | 555      |\n|    time_elapsed     | 1532     |\n|    total_timesteps  | 851760   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0617   |\n|    n_updates        | 26305    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4544     |\n|    fps              | 555      |\n|    time_elapsed     | 1533     |\n|    total_timesteps  | 852744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.18     |\n|    n_updates        | 26336    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4548     |\n|    fps              | 555      |\n|    time_elapsed     | 1534     |\n|    total_timesteps  | 853192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0441   |\n|    n_updates        | 26350    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4552     |\n|    fps              | 556      |\n|    time_elapsed     | 1535     |\n|    total_timesteps  | 854040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0975   |\n|    n_updates        | 26376    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4556     |\n|    fps              | 556      |\n|    time_elapsed     | 1537     |\n|    total_timesteps  | 855368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.101    |\n|    n_updates        | 26418    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4560     |\n|    fps              | 556      |\n|    time_elapsed     | 1538     |\n|    total_timesteps  | 855984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.952    |\n|    n_updates        | 26437    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4564     |\n|    fps              | 556      |\n|    time_elapsed     | 1539     |\n|    total_timesteps  | 856544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0942   |\n|    n_updates        | 26454    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4568     |\n|    fps              | 556      |\n|    time_elapsed     | 1540     |\n|    total_timesteps  | 857192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.057    |\n|    n_updates        | 26475    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4572     |\n|    fps              | 556      |\n|    time_elapsed     | 1540     |\n|    total_timesteps  | 857560   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0621   |\n|    n_updates        | 26486    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4576     |\n|    fps              | 556      |\n|    time_elapsed     | 1541     |\n|    total_timesteps  | 858360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0606   |\n|    n_updates        | 26511    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4580     |\n|    fps              | 556      |\n|    time_elapsed     | 1543     |\n|    total_timesteps  | 859168   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0755   |\n|    n_updates        | 26536    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4584     |\n|    fps              | 556      |\n|    time_elapsed     | 1544     |\n|    total_timesteps  | 859824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0502   |\n|    n_updates        | 26557    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4588     |\n|    fps              | 556      |\n|    time_elapsed     | 1545     |\n|    total_timesteps  | 860712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0718   |\n|    n_updates        | 26585    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4592     |\n|    fps              | 557      |\n|    time_elapsed     | 1546     |\n|    total_timesteps  | 861488   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.155    |\n|    n_updates        | 26609    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4596     |\n|    fps              | 557      |\n|    time_elapsed     | 1547     |\n|    total_timesteps  | 862448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0634   |\n|    n_updates        | 26639    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4600     |\n|    fps              | 557      |\n|    time_elapsed     | 1548     |\n|    total_timesteps  | 863208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0638   |\n|    n_updates        | 26663    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4604     |\n|    fps              | 557      |\n|    time_elapsed     | 1549     |\n|    total_timesteps  | 863856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.15     |\n|    n_updates        | 26683    |\n----------------------------------\nEval num_timesteps=864000, episode_reward=352.00 +/- 187.87\nEpisode length: 1989.80 +/- 137.04\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.99e+03 |\n|    mean_reward      | 352      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 864000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0398   |\n|    n_updates        | 26687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4608     |\n|    fps              | 555      |\n|    time_elapsed     | 1555     |\n|    total_timesteps  | 864600   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.148    |\n|    n_updates        | 26706    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4612     |\n|    fps              | 555      |\n|    time_elapsed     | 1557     |\n|    total_timesteps  | 865392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0937   |\n|    n_updates        | 26731    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4616     |\n|    fps              | 556      |\n|    time_elapsed     | 1559     |\n|    total_timesteps  | 867008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0654   |\n|    n_updates        | 26781    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4620     |\n|    fps              | 556      |\n|    time_elapsed     | 1559     |\n|    total_timesteps  | 867432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0654   |\n|    n_updates        | 26795    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4624     |\n|    fps              | 556      |\n|    time_elapsed     | 1560     |\n|    total_timesteps  | 868080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.776    |\n|    n_updates        | 26815    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4628     |\n|    fps              | 556      |\n|    time_elapsed     | 1561     |\n|    total_timesteps  | 868760   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 26836    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4632     |\n|    fps              | 556      |\n|    time_elapsed     | 1563     |\n|    total_timesteps  | 869800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0705   |\n|    n_updates        | 26869    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4636     |\n|    fps              | 556      |\n|    time_elapsed     | 1564     |\n|    total_timesteps  | 870352   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.882    |\n|    n_updates        | 26886    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4640     |\n|    fps              | 556      |\n|    time_elapsed     | 1565     |\n|    total_timesteps  | 871048   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.044    |\n|    n_updates        | 26908    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4644     |\n|    fps              | 556      |\n|    time_elapsed     | 1566     |\n|    total_timesteps  | 871808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 26931    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4648     |\n|    fps              | 556      |\n|    time_elapsed     | 1567     |\n|    total_timesteps  | 872672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.194    |\n|    n_updates        | 26958    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4652     |\n|    fps              | 556      |\n|    time_elapsed     | 1569     |\n|    total_timesteps  | 873720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.127    |\n|    n_updates        | 26991    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4656     |\n|    fps              | 556      |\n|    time_elapsed     | 1570     |\n|    total_timesteps  | 874712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 27022    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4660     |\n|    fps              | 557      |\n|    time_elapsed     | 1571     |\n|    total_timesteps  | 875504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0642   |\n|    n_updates        | 27047    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4664     |\n|    fps              | 557      |\n|    time_elapsed     | 1571     |\n|    total_timesteps  | 875792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.199    |\n|    n_updates        | 27056    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4668     |\n|    fps              | 557      |\n|    time_elapsed     | 1573     |\n|    total_timesteps  | 876592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.115    |\n|    n_updates        | 27081    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4672     |\n|    fps              | 557      |\n|    time_elapsed     | 1574     |\n|    total_timesteps  | 877240   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0652   |\n|    n_updates        | 27101    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4676     |\n|    fps              | 557      |\n|    time_elapsed     | 1575     |\n|    total_timesteps  | 877992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.959    |\n|    n_updates        | 27125    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4680     |\n|    fps              | 557      |\n|    time_elapsed     | 1575     |\n|    total_timesteps  | 878248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0776   |\n|    n_updates        | 27133    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4684     |\n|    fps              | 557      |\n|    time_elapsed     | 1577     |\n|    total_timesteps  | 879496   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0757   |\n|    n_updates        | 27172    |\n----------------------------------\nEval num_timesteps=880000, episode_reward=456.00 +/- 304.93\nEpisode length: 2004.20 +/- 481.64\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2e+03    |\n|    mean_reward      | 456      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 880000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.208    |\n|    n_updates        | 27187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4688     |\n|    fps              | 555      |\n|    time_elapsed     | 1584     |\n|    total_timesteps  | 880512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0733   |\n|    n_updates        | 27203    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4692     |\n|    fps              | 555      |\n|    time_elapsed     | 1584     |\n|    total_timesteps  | 881128   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0778   |\n|    n_updates        | 27223    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4696     |\n|    fps              | 556      |\n|    time_elapsed     | 1585     |\n|    total_timesteps  | 881592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.999    |\n|    n_updates        | 27237    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4700     |\n|    fps              | 556      |\n|    time_elapsed     | 1586     |\n|    total_timesteps  | 882200   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.02     |\n|    n_updates        | 27256    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4704     |\n|    fps              | 556      |\n|    time_elapsed     | 1587     |\n|    total_timesteps  | 882792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0643   |\n|    n_updates        | 27275    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4708     |\n|    fps              | 556      |\n|    time_elapsed     | 1588     |\n|    total_timesteps  | 883296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.1      |\n|    n_updates        | 27290    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4712     |\n|    fps              | 556      |\n|    time_elapsed     | 1589     |\n|    total_timesteps  | 884104   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.06     |\n|    n_updates        | 27316    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4716     |\n|    fps              | 556      |\n|    time_elapsed     | 1590     |\n|    total_timesteps  | 884784   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 27337    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4720     |\n|    fps              | 556      |\n|    time_elapsed     | 1590     |\n|    total_timesteps  | 885360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0601   |\n|    n_updates        | 27355    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4724     |\n|    fps              | 556      |\n|    time_elapsed     | 1592     |\n|    total_timesteps  | 886624   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 27394    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4728     |\n|    fps              | 556      |\n|    time_elapsed     | 1593     |\n|    total_timesteps  | 887400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.801    |\n|    n_updates        | 27419    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4732     |\n|    fps              | 556      |\n|    time_elapsed     | 1594     |\n|    total_timesteps  | 888040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.874    |\n|    n_updates        | 27439    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4736     |\n|    fps              | 556      |\n|    time_elapsed     | 1595     |\n|    total_timesteps  | 888680   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.171    |\n|    n_updates        | 27459    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4740     |\n|    fps              | 557      |\n|    time_elapsed     | 1596     |\n|    total_timesteps  | 889400   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.056    |\n|    n_updates        | 27481    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4744     |\n|    fps              | 557      |\n|    time_elapsed     | 1598     |\n|    total_timesteps  | 890328   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0676   |\n|    n_updates        | 27510    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4748     |\n|    fps              | 557      |\n|    time_elapsed     | 1599     |\n|    total_timesteps  | 891424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.122    |\n|    n_updates        | 27544    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4752     |\n|    fps              | 557      |\n|    time_elapsed     | 1600     |\n|    total_timesteps  | 892208   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 27569    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4756     |\n|    fps              | 557      |\n|    time_elapsed     | 1602     |\n|    total_timesteps  | 893304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0555   |\n|    n_updates        | 27603    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4760     |\n|    fps              | 557      |\n|    time_elapsed     | 1603     |\n|    total_timesteps  | 894360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.41     |\n|    n_updates        | 27636    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4764     |\n|    fps              | 557      |\n|    time_elapsed     | 1604     |\n|    total_timesteps  | 894752   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.03     |\n|    n_updates        | 27648    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4768     |\n|    fps              | 557      |\n|    time_elapsed     | 1605     |\n|    total_timesteps  | 895744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.927    |\n|    n_updates        | 27679    |\n----------------------------------\nEval num_timesteps=896000, episode_reward=192.00 +/- 119.06\nEpisode length: 2196.20 +/- 182.26\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.2e+03  |\n|    mean_reward      | 192      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 896000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.044    |\n|    n_updates        | 27687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4772     |\n|    fps              | 555      |\n|    time_elapsed     | 1612     |\n|    total_timesteps  | 896648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0511   |\n|    n_updates        | 27708    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4776     |\n|    fps              | 555      |\n|    time_elapsed     | 1613     |\n|    total_timesteps  | 897136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.183    |\n|    n_updates        | 27723    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4780     |\n|    fps              | 556      |\n|    time_elapsed     | 1614     |\n|    total_timesteps  | 897792   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0591   |\n|    n_updates        | 27743    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4784     |\n|    fps              | 556      |\n|    time_elapsed     | 1615     |\n|    total_timesteps  | 898136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0453   |\n|    n_updates        | 27754    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4788     |\n|    fps              | 556      |\n|    time_elapsed     | 1615     |\n|    total_timesteps  | 898688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.108    |\n|    n_updates        | 27771    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4792     |\n|    fps              | 556      |\n|    time_elapsed     | 1616     |\n|    total_timesteps  | 899408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0685   |\n|    n_updates        | 27794    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4796     |\n|    fps              | 556      |\n|    time_elapsed     | 1617     |\n|    total_timesteps  | 900104   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.485    |\n|    n_updates        | 27816    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4800     |\n|    fps              | 556      |\n|    time_elapsed     | 1618     |\n|    total_timesteps  | 900904   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0976   |\n|    n_updates        | 27841    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4804     |\n|    fps              | 556      |\n|    time_elapsed     | 1619     |\n|    total_timesteps  | 901408   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0515   |\n|    n_updates        | 27856    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4808     |\n|    fps              | 556      |\n|    time_elapsed     | 1621     |\n|    total_timesteps  | 902304   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.163    |\n|    n_updates        | 27884    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4812     |\n|    fps              | 556      |\n|    time_elapsed     | 1621     |\n|    total_timesteps  | 902840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.089    |\n|    n_updates        | 27901    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4816     |\n|    fps              | 556      |\n|    time_elapsed     | 1622     |\n|    total_timesteps  | 903664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.8      |\n|    n_updates        | 27927    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 16.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4820     |\n|    fps              | 556      |\n|    time_elapsed     | 1623     |\n|    total_timesteps  | 904264   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0803   |\n|    n_updates        | 27946    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4824     |\n|    fps              | 556      |\n|    time_elapsed     | 1625     |\n|    total_timesteps  | 905064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 27971    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4828     |\n|    fps              | 557      |\n|    time_elapsed     | 1626     |\n|    total_timesteps  | 906280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0935   |\n|    n_updates        | 28009    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4832     |\n|    fps              | 557      |\n|    time_elapsed     | 1628     |\n|    total_timesteps  | 907176   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0716   |\n|    n_updates        | 28037    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4836     |\n|    fps              | 557      |\n|    time_elapsed     | 1628     |\n|    total_timesteps  | 907776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0754   |\n|    n_updates        | 28055    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4840     |\n|    fps              | 557      |\n|    time_elapsed     | 1630     |\n|    total_timesteps  | 908712   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.177    |\n|    n_updates        | 28085    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4844     |\n|    fps              | 557      |\n|    time_elapsed     | 1631     |\n|    total_timesteps  | 909928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.999    |\n|    n_updates        | 28123    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4848     |\n|    fps              | 557      |\n|    time_elapsed     | 1632     |\n|    total_timesteps  | 910432   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0562   |\n|    n_updates        | 28138    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4852     |\n|    fps              | 557      |\n|    time_elapsed     | 1633     |\n|    total_timesteps  | 910896   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.424    |\n|    n_updates        | 28153    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4856     |\n|    fps              | 557      |\n|    time_elapsed     | 1634     |\n|    total_timesteps  | 911840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.138    |\n|    n_updates        | 28182    |\n----------------------------------\nEval num_timesteps=912000, episode_reward=376.00 +/- 41.76\nEpisode length: 1965.80 +/- 304.11\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.97e+03 |\n|    mean_reward      | 376      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 912000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.109    |\n|    n_updates        | 28187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4860     |\n|    fps              | 556      |\n|    time_elapsed     | 1640     |\n|    total_timesteps  | 912392   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0747   |\n|    n_updates        | 28200    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4864     |\n|    fps              | 556      |\n|    time_elapsed     | 1641     |\n|    total_timesteps  | 913016   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0996   |\n|    n_updates        | 28219    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4868     |\n|    fps              | 556      |\n|    time_elapsed     | 1642     |\n|    total_timesteps  | 914040   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.164    |\n|    n_updates        | 28251    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4872     |\n|    fps              | 556      |\n|    time_elapsed     | 1643     |\n|    total_timesteps  | 914592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.338    |\n|    n_updates        | 28268    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4876     |\n|    fps              | 556      |\n|    time_elapsed     | 1644     |\n|    total_timesteps  | 914936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.15     |\n|    n_updates        | 28279    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4880     |\n|    fps              | 556      |\n|    time_elapsed     | 1645     |\n|    total_timesteps  | 915984   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.116    |\n|    n_updates        | 28312    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4884     |\n|    fps              | 556      |\n|    time_elapsed     | 1646     |\n|    total_timesteps  | 916344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0532   |\n|    n_updates        | 28323    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4888     |\n|    fps              | 556      |\n|    time_elapsed     | 1647     |\n|    total_timesteps  | 917288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.062    |\n|    n_updates        | 28353    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4892     |\n|    fps              | 556      |\n|    time_elapsed     | 1648     |\n|    total_timesteps  | 917872   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.72     |\n|    n_updates        | 28371    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 184      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4896     |\n|    fps              | 556      |\n|    time_elapsed     | 1649     |\n|    total_timesteps  | 918376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.815    |\n|    n_updates        | 28387    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4900     |\n|    fps              | 556      |\n|    time_elapsed     | 1649     |\n|    total_timesteps  | 918952   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0807   |\n|    n_updates        | 28405    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4904     |\n|    fps              | 557      |\n|    time_elapsed     | 1650     |\n|    total_timesteps  | 919648   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0607   |\n|    n_updates        | 28426    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4908     |\n|    fps              | 557      |\n|    time_elapsed     | 1652     |\n|    total_timesteps  | 920632   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.841    |\n|    n_updates        | 28457    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4912     |\n|    fps              | 557      |\n|    time_elapsed     | 1652     |\n|    total_timesteps  | 920976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0485   |\n|    n_updates        | 28468    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4916     |\n|    fps              | 557      |\n|    time_elapsed     | 1653     |\n|    total_timesteps  | 921384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0727   |\n|    n_updates        | 28481    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4920     |\n|    fps              | 557      |\n|    time_elapsed     | 1654     |\n|    total_timesteps  | 922456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0456   |\n|    n_updates        | 28514    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 181      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4924     |\n|    fps              | 557      |\n|    time_elapsed     | 1655     |\n|    total_timesteps  | 922856   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.15     |\n|    n_updates        | 28527    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 182      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4928     |\n|    fps              | 557      |\n|    time_elapsed     | 1656     |\n|    total_timesteps  | 923520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.115    |\n|    n_updates        | 28547    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4932     |\n|    fps              | 557      |\n|    time_elapsed     | 1657     |\n|    total_timesteps  | 924248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.135    |\n|    n_updates        | 28570    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4936     |\n|    fps              | 557      |\n|    time_elapsed     | 1659     |\n|    total_timesteps  | 925456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.152    |\n|    n_updates        | 28608    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4940     |\n|    fps              | 557      |\n|    time_elapsed     | 1660     |\n|    total_timesteps  | 925968   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0562   |\n|    n_updates        | 28624    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4944     |\n|    fps              | 557      |\n|    time_elapsed     | 1661     |\n|    total_timesteps  | 927064   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0523   |\n|    n_updates        | 28658    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 170      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4948     |\n|    fps              | 557      |\n|    time_elapsed     | 1662     |\n|    total_timesteps  | 927544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0769   |\n|    n_updates        | 28673    |\n----------------------------------\nEval num_timesteps=928000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.93e+03 |\n|    mean_reward      | 60       |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 928000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.142    |\n|    n_updates        | 28687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4952     |\n|    fps              | 556      |\n|    time_elapsed     | 1668     |\n|    total_timesteps  | 928616   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0627   |\n|    n_updates        | 28707    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 172      |\n|    ep_rew_mean      | 15.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4956     |\n|    fps              | 556      |\n|    time_elapsed     | 1669     |\n|    total_timesteps  | 929360   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0373   |\n|    n_updates        | 28730    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4960     |\n|    fps              | 556      |\n|    time_elapsed     | 1670     |\n|    total_timesteps  | 930008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.157    |\n|    n_updates        | 28750    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 17       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4964     |\n|    fps              | 556      |\n|    time_elapsed     | 1672     |\n|    total_timesteps  | 930824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.154    |\n|    n_updates        | 28776    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4968     |\n|    fps              | 556      |\n|    time_elapsed     | 1672     |\n|    total_timesteps  | 931384   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0573   |\n|    n_updates        | 28793    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4972     |\n|    fps              | 556      |\n|    time_elapsed     | 1674     |\n|    total_timesteps  | 932256   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.344    |\n|    n_updates        | 28820    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4976     |\n|    fps              | 556      |\n|    time_elapsed     | 1674     |\n|    total_timesteps  | 932480   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0552   |\n|    n_updates        | 28827    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4980     |\n|    fps              | 557      |\n|    time_elapsed     | 1675     |\n|    total_timesteps  | 933592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.243    |\n|    n_updates        | 28862    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4984     |\n|    fps              | 557      |\n|    time_elapsed     | 1676     |\n|    total_timesteps  | 934024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.234    |\n|    n_updates        | 28876    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4988     |\n|    fps              | 557      |\n|    time_elapsed     | 1677     |\n|    total_timesteps  | 934824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.03     |\n|    n_updates        | 28901    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4992     |\n|    fps              | 557      |\n|    time_elapsed     | 1678     |\n|    total_timesteps  | 935136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0682   |\n|    n_updates        | 28910    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 16.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 4996     |\n|    fps              | 557      |\n|    time_elapsed     | 1680     |\n|    total_timesteps  | 936472   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.13     |\n|    n_updates        | 28952    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5000     |\n|    fps              | 557      |\n|    time_elapsed     | 1681     |\n|    total_timesteps  | 937776   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0683   |\n|    n_updates        | 28993    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5004     |\n|    fps              | 557      |\n|    time_elapsed     | 1683     |\n|    total_timesteps  | 938672   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0908   |\n|    n_updates        | 29021    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5008     |\n|    fps              | 557      |\n|    time_elapsed     | 1684     |\n|    total_timesteps  | 939512   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0595   |\n|    n_updates        | 29047    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5012     |\n|    fps              | 557      |\n|    time_elapsed     | 1684     |\n|    total_timesteps  | 939976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0702   |\n|    n_updates        | 29062    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5016     |\n|    fps              | 558      |\n|    time_elapsed     | 1687     |\n|    total_timesteps  | 941744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.24     |\n|    n_updates        | 29117    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5020     |\n|    fps              | 558      |\n|    time_elapsed     | 1688     |\n|    total_timesteps  | 942248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0943   |\n|    n_updates        | 29133    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5024     |\n|    fps              | 558      |\n|    time_elapsed     | 1688     |\n|    total_timesteps  | 942568   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.02     |\n|    n_updates        | 29143    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5028     |\n|    fps              | 558      |\n|    time_elapsed     | 1690     |\n|    total_timesteps  | 943592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0654   |\n|    n_updates        | 29175    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5032     |\n|    fps              | 558      |\n|    time_elapsed     | 1690     |\n|    total_timesteps  | 943992   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.153    |\n|    n_updates        | 29187    |\n----------------------------------\nEval num_timesteps=944000, episode_reward=1008.00 +/- 743.54\nEpisode length: 2529.00 +/- 611.40\n---------------------------------\n| eval/              |          |\n|    mean_ep_length  | 2.53e+03 |\n|    mean_reward     | 1.01e+03 |\n| time/              |          |\n|    total_timesteps | 944000   |\n---------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5036     |\n|    fps              | 556      |\n|    time_elapsed     | 1698     |\n|    total_timesteps  | 944608   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0452   |\n|    n_updates        | 29206    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5040     |\n|    fps              | 556      |\n|    time_elapsed     | 1699     |\n|    total_timesteps  | 945744   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0827   |\n|    n_updates        | 29242    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5044     |\n|    fps              | 556      |\n|    time_elapsed     | 1701     |\n|    total_timesteps  | 946704   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0998   |\n|    n_updates        | 29272    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5048     |\n|    fps              | 556      |\n|    time_elapsed     | 1702     |\n|    total_timesteps  | 947824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.11     |\n|    n_updates        | 29307    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5052     |\n|    fps              | 556      |\n|    time_elapsed     | 1704     |\n|    total_timesteps  | 948720   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0887   |\n|    n_updates        | 29335    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5056     |\n|    fps              | 556      |\n|    time_elapsed     | 1704     |\n|    total_timesteps  | 949072   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.954    |\n|    n_updates        | 29346    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5060     |\n|    fps              | 556      |\n|    time_elapsed     | 1705     |\n|    total_timesteps  | 949840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0757   |\n|    n_updates        | 29370    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5064     |\n|    fps              | 557      |\n|    time_elapsed     | 1707     |\n|    total_timesteps  | 950824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0816   |\n|    n_updates        | 29401    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 17.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5068     |\n|    fps              | 557      |\n|    time_elapsed     | 1707     |\n|    total_timesteps  | 951456   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0754   |\n|    n_updates        | 29420    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 18       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5072     |\n|    fps              | 557      |\n|    time_elapsed     | 1709     |\n|    total_timesteps  | 952504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.123    |\n|    n_updates        | 29453    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5076     |\n|    fps              | 557      |\n|    time_elapsed     | 1710     |\n|    total_timesteps  | 952912   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.113    |\n|    n_updates        | 29466    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 205      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5080     |\n|    fps              | 557      |\n|    time_elapsed     | 1711     |\n|    total_timesteps  | 953768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0872   |\n|    n_updates        | 29493    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5084     |\n|    fps              | 557      |\n|    time_elapsed     | 1711     |\n|    total_timesteps  | 954272   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.128    |\n|    n_updates        | 29508    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5088     |\n|    fps              | 557      |\n|    time_elapsed     | 1712     |\n|    total_timesteps  | 954976   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.106    |\n|    n_updates        | 29530    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5092     |\n|    fps              | 557      |\n|    time_elapsed     | 1714     |\n|    total_timesteps  | 955944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0663   |\n|    n_updates        | 29561    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 203      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5096     |\n|    fps              | 557      |\n|    time_elapsed     | 1715     |\n|    total_timesteps  | 956464   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.119    |\n|    n_updates        | 29577    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 206      |\n|    ep_rew_mean      | 19.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5100     |\n|    fps              | 557      |\n|    time_elapsed     | 1716     |\n|    total_timesteps  | 957120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0411   |\n|    n_updates        | 29597    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5104     |\n|    fps              | 557      |\n|    time_elapsed     | 1717     |\n|    total_timesteps  | 957848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0852   |\n|    n_updates        | 29620    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 18.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5108     |\n|    fps              | 557      |\n|    time_elapsed     | 1718     |\n|    total_timesteps  | 958824   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.043    |\n|    n_updates        | 29651    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5112     |\n|    fps              | 558      |\n|    time_elapsed     | 1719     |\n|    total_timesteps  | 959344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.927    |\n|    n_updates        | 29667    |\n----------------------------------\nEval num_timesteps=960000, episode_reward=208.00 +/- 31.87\nEpisode length: 1719.40 +/- 163.28\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.72e+03 |\n|    mean_reward      | 208      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 960000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0481   |\n|    n_updates        | 29687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5116     |\n|    fps              | 556      |\n|    time_elapsed     | 1726     |\n|    total_timesteps  | 960944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0758   |\n|    n_updates        | 29717    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5120     |\n|    fps              | 556      |\n|    time_elapsed     | 1727     |\n|    total_timesteps  | 962152   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.89     |\n|    n_updates        | 29755    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 19.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5124     |\n|    fps              | 556      |\n|    time_elapsed     | 1728     |\n|    total_timesteps  | 962840   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.985    |\n|    n_updates        | 29776    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5128     |\n|    fps              | 556      |\n|    time_elapsed     | 1729     |\n|    total_timesteps  | 963320   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.1      |\n|    n_updates        | 29791    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5132     |\n|    fps              | 557      |\n|    time_elapsed     | 1731     |\n|    total_timesteps  | 964448   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.063    |\n|    n_updates        | 29826    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 207      |\n|    ep_rew_mean      | 19.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5136     |\n|    fps              | 557      |\n|    time_elapsed     | 1733     |\n|    total_timesteps  | 965768   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.161    |\n|    n_updates        | 29868    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 211      |\n|    ep_rew_mean      | 20.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5140     |\n|    fps              | 557      |\n|    time_elapsed     | 1734     |\n|    total_timesteps  | 966664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.193    |\n|    n_updates        | 29896    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 211      |\n|    ep_rew_mean      | 20.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5144     |\n|    fps              | 557      |\n|    time_elapsed     | 1734     |\n|    total_timesteps  | 966944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.112    |\n|    n_updates        | 29904    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 204      |\n|    ep_rew_mean      | 19.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5148     |\n|    fps              | 557      |\n|    time_elapsed     | 1735     |\n|    total_timesteps  | 967504   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0455   |\n|    n_updates        | 29922    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5152     |\n|    fps              | 557      |\n|    time_elapsed     | 1736     |\n|    total_timesteps  | 968296   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.105    |\n|    n_updates        | 29947    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 199      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5156     |\n|    fps              | 557      |\n|    time_elapsed     | 1738     |\n|    total_timesteps  | 969280   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 29977    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 18.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5160     |\n|    fps              | 557      |\n|    time_elapsed     | 1738     |\n|    total_timesteps  | 969592   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0392   |\n|    n_updates        | 29987    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 201      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5164     |\n|    fps              | 557      |\n|    time_elapsed     | 1739     |\n|    total_timesteps  | 970424   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0648   |\n|    n_updates        | 30013    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 202      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5168     |\n|    fps              | 557      |\n|    time_elapsed     | 1740     |\n|    total_timesteps  | 971136   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0574   |\n|    n_updates        | 30035    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5172     |\n|    fps              | 557      |\n|    time_elapsed     | 1741     |\n|    total_timesteps  | 971760   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.115    |\n|    n_updates        | 30055    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5176     |\n|    fps              | 557      |\n|    time_elapsed     | 1742     |\n|    total_timesteps  | 972008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0861   |\n|    n_updates        | 30063    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 190      |\n|    ep_rew_mean      | 17.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5180     |\n|    fps              | 558      |\n|    time_elapsed     | 1743     |\n|    total_timesteps  | 972848   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.153    |\n|    n_updates        | 30089    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5184     |\n|    fps              | 558      |\n|    time_elapsed     | 1744     |\n|    total_timesteps  | 973640   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0463   |\n|    n_updates        | 30114    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5188     |\n|    fps              | 558      |\n|    time_elapsed     | 1744     |\n|    total_timesteps  | 973936   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0623   |\n|    n_updates        | 30123    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5192     |\n|    fps              | 558      |\n|    time_elapsed     | 1746     |\n|    total_timesteps  | 974944   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.1      |\n|    n_updates        | 30154    |\n----------------------------------\nEval num_timesteps=976000, episode_reward=418.00 +/- 73.32\nEpisode length: 1717.80 +/- 170.43\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 1.72e+03 |\n|    mean_reward      | 418      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 976000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0658   |\n|    n_updates        | 30187    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 191      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5196     |\n|    fps              | 557      |\n|    time_elapsed     | 1752     |\n|    total_timesteps  | 976024   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.159    |\n|    n_updates        | 30188    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 189      |\n|    ep_rew_mean      | 17.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5200     |\n|    fps              | 557      |\n|    time_elapsed     | 1753     |\n|    total_timesteps  | 976560   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.132    |\n|    n_updates        | 30205    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 194      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5204     |\n|    fps              | 557      |\n|    time_elapsed     | 1753     |\n|    total_timesteps  | 977120   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0827   |\n|    n_updates        | 30222    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 18.2     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5208     |\n|    fps              | 557      |\n|    time_elapsed     | 1754     |\n|    total_timesteps  | 977760   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0602   |\n|    n_updates        | 30242    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 192      |\n|    ep_rew_mean      | 18.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5212     |\n|    fps              | 557      |\n|    time_elapsed     | 1755     |\n|    total_timesteps  | 978552   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.126    |\n|    n_updates        | 30267    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5216     |\n|    fps              | 557      |\n|    time_elapsed     | 1756     |\n|    total_timesteps  | 979312   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.199    |\n|    n_updates        | 30291    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 185      |\n|    ep_rew_mean      | 17.1     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5220     |\n|    fps              | 557      |\n|    time_elapsed     | 1757     |\n|    total_timesteps  | 979520   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 30297    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 178      |\n|    ep_rew_mean      | 16.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5224     |\n|    fps              | 557      |\n|    time_elapsed     | 1758     |\n|    total_timesteps  | 980376   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.998    |\n|    n_updates        | 30324    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 176      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5228     |\n|    fps              | 557      |\n|    time_elapsed     | 1760     |\n|    total_timesteps  | 981696   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.347    |\n|    n_updates        | 30365    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5232     |\n|    fps              | 557      |\n|    time_elapsed     | 1761     |\n|    total_timesteps  | 982416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0627   |\n|    n_updates        | 30388    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 179      |\n|    ep_rew_mean      | 16.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5236     |\n|    fps              | 557      |\n|    time_elapsed     | 1762     |\n|    total_timesteps  | 983080   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.146    |\n|    n_updates        | 30409    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5240     |\n|    fps              | 557      |\n|    time_elapsed     | 1763     |\n|    total_timesteps  | 983728   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.95     |\n|    n_updates        | 30429    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 15.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5244     |\n|    fps              | 557      |\n|    time_elapsed     | 1764     |\n|    total_timesteps  | 984688   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.95     |\n|    n_updates        | 30459    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 177      |\n|    ep_rew_mean      | 15.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5248     |\n|    fps              | 557      |\n|    time_elapsed     | 1765     |\n|    total_timesteps  | 984864   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0349   |\n|    n_updates        | 30464    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5252     |\n|    fps              | 558      |\n|    time_elapsed     | 1766     |\n|    total_timesteps  | 985800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0677   |\n|    n_updates        | 30494    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 175      |\n|    ep_rew_mean      | 16       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5256     |\n|    fps              | 558      |\n|    time_elapsed     | 1766     |\n|    total_timesteps  | 986192   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0769   |\n|    n_updates        | 30506    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 173      |\n|    ep_rew_mean      | 15.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5260     |\n|    fps              | 558      |\n|    time_elapsed     | 1768     |\n|    total_timesteps  | 987288   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0269   |\n|    n_updates        | 30540    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 174      |\n|    ep_rew_mean      | 15.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5264     |\n|    fps              | 558      |\n|    time_elapsed     | 1770     |\n|    total_timesteps  | 988656   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0518   |\n|    n_updates        | 30583    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 180      |\n|    ep_rew_mean      | 16.5     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5268     |\n|    fps              | 558      |\n|    time_elapsed     | 1771     |\n|    total_timesteps  | 989544   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0521   |\n|    n_updates        | 30611    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 183      |\n|    ep_rew_mean      | 16.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5272     |\n|    fps              | 558      |\n|    time_elapsed     | 1772     |\n|    total_timesteps  | 990248   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.114    |\n|    n_updates        | 30633    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 186      |\n|    ep_rew_mean      | 17.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5276     |\n|    fps              | 558      |\n|    time_elapsed     | 1773     |\n|    total_timesteps  | 991008   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0409   |\n|    n_updates        | 30656    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 188      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5280     |\n|    fps              | 558      |\n|    time_elapsed     | 1774     |\n|    total_timesteps  | 991584   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.118    |\n|    n_updates        | 30674    |\n----------------------------------\nEval num_timesteps=992000, episode_reward=568.00 +/- 88.86\nEpisode length: 2649.00 +/- 213.35\n----------------------------------\n| eval/               |          |\n|    mean_ep_length   | 2.65e+03 |\n|    mean_reward      | 568      |\n| rollout/            |          |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    total_timesteps  | 992000   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.102    |\n|    n_updates        | 30687    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 187      |\n|    ep_rew_mean      | 17.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5284     |\n|    fps              | 556      |\n|    time_elapsed     | 1783     |\n|    total_timesteps  | 992920   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0443   |\n|    n_updates        | 30716    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 193      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5288     |\n|    fps              | 556      |\n|    time_elapsed     | 1784     |\n|    total_timesteps  | 993808   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 1.04     |\n|    n_updates        | 30744    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 195      |\n|    ep_rew_mean      | 18.8     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5292     |\n|    fps              | 556      |\n|    time_elapsed     | 1785     |\n|    total_timesteps  | 994664   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0941   |\n|    n_updates        | 30771    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 19.3     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5296     |\n|    fps              | 557      |\n|    time_elapsed     | 1786     |\n|    total_timesteps  | 995368   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0594   |\n|    n_updates        | 30793    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 19       |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5300     |\n|    fps              | 557      |\n|    time_elapsed     | 1787     |\n|    total_timesteps  | 996104   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.151    |\n|    n_updates        | 30816    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 196      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5304     |\n|    fps              | 557      |\n|    time_elapsed     | 1788     |\n|    total_timesteps  | 996800   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0691   |\n|    n_updates        | 30837    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 18.6     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5308     |\n|    fps              | 557      |\n|    time_elapsed     | 1790     |\n|    total_timesteps  | 997736   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0824   |\n|    n_updates        | 30867    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 197      |\n|    ep_rew_mean      | 18.4     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5312     |\n|    fps              | 557      |\n|    time_elapsed     | 1791     |\n|    total_timesteps  | 998344   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.176    |\n|    n_updates        | 30886    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 200      |\n|    ep_rew_mean      | 18.9     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5316     |\n|    fps              | 557      |\n|    time_elapsed     | 1791     |\n|    total_timesteps  | 998928   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0578   |\n|    n_updates        | 30904    |\n----------------------------------\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 198      |\n|    ep_rew_mean      | 18.7     |\n|    exploration_rate | 0.0388   |\n| time/               |          |\n|    episodes         | 5320     |\n|    fps              | 557      |\n|    time_elapsed     | 1792     |\n|    total_timesteps  | 999416   |\n| train/              |          |\n|    learning_rate    | 3.36e-05 |\n|    loss             | 0.0425   |\n|    n_updates        | 30919    |\n----------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1,000,000/1,000,000 \u001b[0m [ \u001b[33m0:29:52\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m540 it/s\u001b[0m ]\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">1,000,000/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:29:52</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">540 it/s</span> ]\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"DQN training complete and saved.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"eval_env = make_eval_env()\n\nmean_reward, std_reward = evaluate_policy(\n    dqn_model,\n    eval_env,\n    n_eval_episodes=10,\n    deterministic=True\n)\n\nprint(f\"DQN Evaluation → Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:57:36.084083Z","iopub.execute_input":"2025-12-14T21:57:36.084443Z","iopub.status.idle":"2025-12-14T21:57:48.530223Z","shell.execute_reply.started":"2025-12-14T21:57:36.084418Z","shell.execute_reply":"2025-12-14T21:57:48.529562Z"}},"outputs":[{"name":"stdout","text":"DQN Evaluation → Mean reward: 677.00 ± 362.24\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## A2C","metadata":{}},{"cell_type":"code","source":"def objective_a2c(trial):\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True)\n    n_steps = trial.suggest_categorical(\"n_steps\", [5, 10, 20])\n    ent_coef = trial.suggest_float(\"ent_coef\", 0.0, 0.05)\n\n    env = make_atari_env(ENV_NAME, n_envs=4, seed=42)\n    env = VecFrameStack(env, n_stack=N_STACK)\n    env = VecMonitor(env)\n\n    model = A2C(\n        \"CnnPolicy\",\n        env,\n        learning_rate=learning_rate,\n        n_steps=n_steps,\n        gamma=0.99,\n        ent_coef=ent_coef,\n        vf_coef=0.5,\n        verbose=0,\n        policy_kwargs={\"normalize_images\": False}\n    )\n\n    model.learn(total_timesteps=100000)\n\n    eval_env = make_atari_env(ENV_NAME, n_envs=1, seed=42)\n    eval_env = VecFrameStack(eval_env, n_stack=N_STACK)\n    mean_reward, _ = evaluate_policy(model, eval_env, n_eval_episodes=10)\n\n    env.close(); eval_env.close()\n    return mean_reward\n\nstudy_a2c = optuna.create_study(direction=\"maximize\", study_name=\"a2c_ms_pacman\")\nstudy_a2c.optimize(objective_a2c, n_trials=N_TRIALS, show_progress_bar=True)\nprint(\"\\nA2C Best hyperparameters:\", study_a2c.best_params)\nprint(\"A2C Best value:\", study_a2c.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T21:57:48.530973Z","iopub.execute_input":"2025-12-14T21:57:48.531252Z","iopub.status.idle":"2025-12-14T22:45:30.281911Z","shell.execute_reply.started":"2025-12-14T21:57:48.531225Z","shell.execute_reply":"2025-12-14T22:45:30.281087Z"}},"outputs":[{"name":"stderr","text":"[I 2025-12-14 21:57:48,534] A new study created in memory with name: a2c_ms_pacman\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db4f2e760c94007841da9604c6a2f66"}},"metadata":{}},{"name":"stdout","text":"[I 2025-12-14 22:00:58,405] Trial 0 finished with value: 70.0 and parameters: {'learning_rate': 4.0224807931440906e-05, 'n_steps': 10, 'ent_coef': 0.010299910062654079}. Best is trial 0 with value: 70.0.\n[I 2025-12-14 22:04:11,042] Trial 1 finished with value: 491.0 and parameters: {'learning_rate': 0.0002387576051438125, 'n_steps': 20, 'ent_coef': 0.04964542537992159}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:07:12,590] Trial 2 finished with value: 210.0 and parameters: {'learning_rate': 1.1327930163029249e-05, 'n_steps': 20, 'ent_coef': 0.022209937468495245}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:10:21,656] Trial 3 finished with value: 60.0 and parameters: {'learning_rate': 4.798710000201115e-05, 'n_steps': 10, 'ent_coef': 0.02340498410129891}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:13:45,853] Trial 4 finished with value: 70.0 and parameters: {'learning_rate': 5.8788636286929145e-05, 'n_steps': 5, 'ent_coef': 0.011835980415190663}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:17:08,951] Trial 5 finished with value: 175.0 and parameters: {'learning_rate': 2.8392479800543966e-05, 'n_steps': 5, 'ent_coef': 0.026022996909867913}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:20:24,827] Trial 6 finished with value: 210.0 and parameters: {'learning_rate': 0.0003192803264231546, 'n_steps': 10, 'ent_coef': 0.028786837198914835}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:23:45,050] Trial 7 finished with value: 210.0 and parameters: {'learning_rate': 1.4714693435247305e-05, 'n_steps': 5, 'ent_coef': 0.004865371823672676}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:26:56,743] Trial 8 finished with value: 210.0 and parameters: {'learning_rate': 0.0001881836130060731, 'n_steps': 20, 'ent_coef': 0.0002325444449156833}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:30:02,427] Trial 9 finished with value: 90.0 and parameters: {'learning_rate': 1.0839922227569685e-05, 'n_steps': 20, 'ent_coef': 0.0457891411529411}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:33:07,187] Trial 10 finished with value: 88.0 and parameters: {'learning_rate': 0.00012373134003923003, 'n_steps': 20, 'ent_coef': 0.0495762895448978}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:36:15,290] Trial 11 finished with value: 365.0 and parameters: {'learning_rate': 0.00037013649218440626, 'n_steps': 20, 'ent_coef': 0.037753567294409346}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:39:21,106] Trial 12 finished with value: 70.0 and parameters: {'learning_rate': 0.0004947472739280501, 'n_steps': 20, 'ent_coef': 0.038036406397288836}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:42:23,721] Trial 13 finished with value: 60.0 and parameters: {'learning_rate': 0.00013909844408454167, 'n_steps': 20, 'ent_coef': 0.04012479907235182}. Best is trial 1 with value: 491.0.\n[I 2025-12-14 22:45:30,276] Trial 14 finished with value: 70.0 and parameters: {'learning_rate': 0.00029981869173487254, 'n_steps': 20, 'ent_coef': 0.03592197848333481}. Best is trial 1 with value: 491.0.\n\nA2C Best hyperparameters: {'learning_rate': 0.0002387576051438125, 'n_steps': 20, 'ent_coef': 0.04964542537992159}\nA2C Best value: 491.0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"print(\"Training A2C...\")\n\na2c_best_params = study_a2c.best_params\n\na2c_train_env = make_atari_env(ENV_NAME, n_envs=N_ENVS, seed=42)\na2c_train_env = VecFrameStack(a2c_train_env, n_stack=N_STACK)\na2c_train_env = VecMonitor(a2c_train_env)\n\na2c_model = A2C(\n    \"CnnPolicy\",\n    a2c_train_env,\n    learning_rate=a2c_best_params[\"learning_rate\"],\n    n_steps=a2c_best_params[\"n_steps\"],\n    gamma=0.99,\n    ent_coef=a2c_best_params[\"ent_coef\"],\n    vf_coef=0.5,\n    verbose=1,\n    tensorboard_log=\"./logs/optimized/\",\n    policy_kwargs={\"normalize_images\": False}\n)\n\na2c_eval_callback = EvalCallback(\n    make_eval_env(),\n    best_model_save_path=\"./models/best_a2c/\",\n    log_path=\"./logs/a2c_eval/\",\n    eval_freq=2000,\n    deterministic=True\n)\n\na2c_model.learn(\n    total_timesteps=TOTAL_TIMESTEPS,\n    callback=[a2c_eval_callback],\n    progress_bar=True,\n    tb_log_name=\"a2c_training\"\n)\n\na2c_model.save(\"./models/a2c_ms_pacman_final\")\nprint(\"A2C training complete and saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T22:51:00.044293Z","iopub.execute_input":"2025-12-14T22:51:00.044931Z","iopub.status.idle":"2025-12-14T23:22:14.734151Z","shell.execute_reply.started":"2025-12-14T22:51:00.044909Z","shell.execute_reply":"2025-12-14T23:22:14.733379Z"}},"outputs":[{"name":"stdout","text":"Training A2C...\nUsing cuda device\nWrapping the env in a VecTransposeImage.\nLogging to ./logs/optimized/a2c_training_1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x78109e0d77d0> != <stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x78108ea392d0>\n  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n","output_type":"stream"},{"name":"stdout","text":"Eval num_timesteps=16000, episode_reward=60.00 +/- 0.00\nEpisode length: 1857.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.86e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 16000    |\n| train/                |          |\n|    entropy_loss       | -1.83    |\n|    explained_variance | 0.109    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 99       |\n|    policy_loss        | -0.36    |\n|    value_loss         | 2.62     |\n------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 204      |\n|    ep_rew_mean     | 14.3     |\n| time/              |          |\n|    fps             | 513      |\n|    iterations      | 100      |\n|    time_elapsed    | 31       |\n|    total_timesteps | 16000    |\n---------------------------------\nEval num_timesteps=32000, episode_reward=60.00 +/- 0.00\nEpisode length: 1857.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.86e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 32000    |\n| train/                |          |\n|    entropy_loss       | -1.94    |\n|    explained_variance | 0.171    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 199      |\n|    policy_loss        | 1.01     |\n|    value_loss         | 1.31     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 194      |\n|    ep_rew_mean     | 9.83     |\n| time/              |          |\n|    fps             | 529      |\n|    iterations      | 200      |\n|    time_elapsed    | 60       |\n|    total_timesteps | 32000    |\n---------------------------------\nEval num_timesteps=48000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.93e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 48000    |\n| train/                |          |\n|    entropy_loss       | -1.84    |\n|    explained_variance | 0.345    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 299      |\n|    policy_loss        | 1.57     |\n|    value_loss         | 2.38     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 217      |\n|    ep_rew_mean     | 11.5     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 300      |\n|    time_elapsed    | 90       |\n|    total_timesteps | 48000    |\n---------------------------------\nEval num_timesteps=64000, episode_reward=70.00 +/- 0.00\nEpisode length: 2121.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.12e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 64000    |\n| train/                |          |\n|    entropy_loss       | -1.95    |\n|    explained_variance | 0.7      |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 399      |\n|    policy_loss        | 1.33     |\n|    value_loss         | 2.05     |\n------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 205      |\n|    ep_rew_mean     | 11.4     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 400      |\n|    time_elapsed    | 119      |\n|    total_timesteps | 64000    |\n---------------------------------\nEval num_timesteps=80000, episode_reward=318.00 +/- 83.52\nEpisode length: 1980.20 +/- 195.21\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.98e+03 |\n|    mean_reward        | 318      |\n| time/                 |          |\n|    total_timesteps    | 80000    |\n| train/                |          |\n|    entropy_loss       | -2       |\n|    explained_variance | -0.0379  |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 499      |\n|    policy_loss        | -3.2     |\n|    value_loss         | 11.3     |\n------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 202      |\n|    ep_rew_mean     | 13       |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 500      |\n|    time_elapsed    | 149      |\n|    total_timesteps | 80000    |\n---------------------------------\nEval num_timesteps=96000, episode_reward=70.00 +/- 0.00\nEpisode length: 2113.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.11e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 96000    |\n| train/                |          |\n|    entropy_loss       | -1.69    |\n|    explained_variance | -0.0617  |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 599      |\n|    policy_loss        | 0.403    |\n|    value_loss         | 1.15     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 198      |\n|    ep_rew_mean     | 12.4     |\n| time/              |          |\n|    fps             | 534      |\n|    iterations      | 600      |\n|    time_elapsed    | 179      |\n|    total_timesteps | 96000    |\n---------------------------------\nEval num_timesteps=112000, episode_reward=114.00 +/- 4.90\nEpisode length: 2474.60 +/- 90.14\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.47e+03 |\n|    mean_reward        | 114      |\n| time/                 |          |\n|    total_timesteps    | 112000   |\n| train/                |          |\n|    entropy_loss       | -2.08    |\n|    explained_variance | 0.67     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 699      |\n|    policy_loss        | 0.231    |\n|    value_loss         | 1.24     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 217      |\n|    ep_rew_mean     | 15.5     |\n| time/              |          |\n|    fps             | 531      |\n|    iterations      | 700      |\n|    time_elapsed    | 210      |\n|    total_timesteps | 112000   |\n---------------------------------\nEval num_timesteps=128000, episode_reward=172.00 +/- 40.69\nEpisode length: 2290.60 +/- 390.13\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.29e+03 |\n|    mean_reward        | 172      |\n| time/                 |          |\n|    total_timesteps    | 128000   |\n| train/                |          |\n|    entropy_loss       | -1.95    |\n|    explained_variance | 0.565    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 799      |\n|    policy_loss        | -0.086   |\n|    value_loss         | 0.971    |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 210      |\n|    ep_rew_mean     | 14.1     |\n| time/              |          |\n|    fps             | 530      |\n|    iterations      | 800      |\n|    time_elapsed    | 241      |\n|    total_timesteps | 128000   |\n---------------------------------\nEval num_timesteps=144000, episode_reward=510.00 +/- 82.95\nEpisode length: 3367.40 +/- 391.08\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 3.37e+03 |\n|    mean_reward        | 510      |\n| time/                 |          |\n|    total_timesteps    | 144000   |\n| train/                |          |\n|    entropy_loss       | -1.87    |\n|    explained_variance | 0.728    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 899      |\n|    policy_loss        | 0.103    |\n|    value_loss         | 1.01     |\n------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 223      |\n|    ep_rew_mean     | 14.3     |\n| time/              |          |\n|    fps             | 523      |\n|    iterations      | 900      |\n|    time_elapsed    | 275      |\n|    total_timesteps | 144000   |\n---------------------------------\nEval num_timesteps=160000, episode_reward=70.00 +/- 0.00\nEpisode length: 2073.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.07e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 160000   |\n| train/                |          |\n|    entropy_loss       | -1.96    |\n|    explained_variance | 0.743    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 999      |\n|    policy_loss        | -0.403   |\n|    value_loss         | 0.393    |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 209      |\n|    ep_rew_mean     | 13.4     |\n| time/              |          |\n|    fps             | 524      |\n|    iterations      | 1000     |\n|    time_elapsed    | 304      |\n|    total_timesteps | 160000   |\n---------------------------------\nEval num_timesteps=176000, episode_reward=60.00 +/- 0.00\nEpisode length: 1857.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.86e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 176000   |\n| train/                |          |\n|    entropy_loss       | -1.98    |\n|    explained_variance | 0.758    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1099     |\n|    policy_loss        | 0.221    |\n|    value_loss         | 2.27     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 177      |\n|    ep_rew_mean     | 11.1     |\n| time/              |          |\n|    fps             | 527      |\n|    iterations      | 1100     |\n|    time_elapsed    | 333      |\n|    total_timesteps | 176000   |\n---------------------------------\nEval num_timesteps=192000, episode_reward=70.00 +/- 0.00\nEpisode length: 2073.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.07e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 192000   |\n| train/                |          |\n|    entropy_loss       | -1.85    |\n|    explained_variance | 0.416    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1199     |\n|    policy_loss        | 0.377    |\n|    value_loss         | 2.2      |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 210      |\n|    ep_rew_mean     | 14.1     |\n| time/              |          |\n|    fps             | 528      |\n|    iterations      | 1200     |\n|    time_elapsed    | 363      |\n|    total_timesteps | 192000   |\n---------------------------------\nEval num_timesteps=208000, episode_reward=70.00 +/- 0.00\nEpisode length: 2073.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.07e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 208000   |\n| train/                |          |\n|    entropy_loss       | -1.94    |\n|    explained_variance | 0.554    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1299     |\n|    policy_loss        | 0.519    |\n|    value_loss         | 1.52     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 231      |\n|    ep_rew_mean     | 14.9     |\n| time/              |          |\n|    fps             | 528      |\n|    iterations      | 1300     |\n|    time_elapsed    | 393      |\n|    total_timesteps | 208000   |\n---------------------------------\nEval num_timesteps=224000, episode_reward=70.00 +/- 0.00\nEpisode length: 2073.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.07e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 224000   |\n| train/                |          |\n|    entropy_loss       | -1.93    |\n|    explained_variance | 0.396    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1399     |\n|    policy_loss        | -1.92    |\n|    value_loss         | 3.4      |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 197      |\n|    ep_rew_mean     | 12.9     |\n| time/              |          |\n|    fps             | 529      |\n|    iterations      | 1400     |\n|    time_elapsed    | 422      |\n|    total_timesteps | 224000   |\n---------------------------------\nEval num_timesteps=240000, episode_reward=70.00 +/- 0.00\nEpisode length: 2073.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.07e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 240000   |\n| train/                |          |\n|    entropy_loss       | -1.96    |\n|    explained_variance | 0.367    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1499     |\n|    policy_loss        | 0.685    |\n|    value_loss         | 1.85     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 209      |\n|    ep_rew_mean     | 13.4     |\n| time/              |          |\n|    fps             | 530      |\n|    iterations      | 1500     |\n|    time_elapsed    | 452      |\n|    total_timesteps | 240000   |\n---------------------------------\nEval num_timesteps=256000, episode_reward=94.00 +/- 19.60\nEpisode length: 1991.40 +/- 66.63\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.99e+03 |\n|    mean_reward        | 94       |\n| time/                 |          |\n|    total_timesteps    | 256000   |\n| train/                |          |\n|    entropy_loss       | -2.11    |\n|    explained_variance | 0.668    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1599     |\n|    policy_loss        | 0.31     |\n|    value_loss         | 0.95     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 12.8     |\n| time/              |          |\n|    fps             | 531      |\n|    iterations      | 1600     |\n|    time_elapsed    | 481      |\n|    total_timesteps | 256000   |\n---------------------------------\nEval num_timesteps=272000, episode_reward=156.00 +/- 19.60\nEpisode length: 2037.80 +/- 535.81\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.04e+03 |\n|    mean_reward        | 156      |\n| time/                 |          |\n|    total_timesteps    | 272000   |\n| train/                |          |\n|    entropy_loss       | -1.75    |\n|    explained_variance | 0.742    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1699     |\n|    policy_loss        | 0.346    |\n|    value_loss         | 1.09     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 196      |\n|    ep_rew_mean     | 11.9     |\n| time/              |          |\n|    fps             | 531      |\n|    iterations      | 1700     |\n|    time_elapsed    | 511      |\n|    total_timesteps | 272000   |\n---------------------------------\nEval num_timesteps=288000, episode_reward=244.00 +/- 54.26\nEpisode length: 2071.40 +/- 28.80\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.07e+03 |\n|    mean_reward        | 244      |\n| time/                 |          |\n|    total_timesteps    | 288000   |\n| train/                |          |\n|    entropy_loss       | -2.01    |\n|    explained_variance | 0.577    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1799     |\n|    policy_loss        | -0.381   |\n|    value_loss         | 2.16     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 204      |\n|    ep_rew_mean     | 14.1     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 1800     |\n|    time_elapsed    | 541      |\n|    total_timesteps | 288000   |\n---------------------------------\nEval num_timesteps=304000, episode_reward=70.00 +/- 0.00\nEpisode length: 2121.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.12e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 304000   |\n| train/                |          |\n|    entropy_loss       | -2.11    |\n|    explained_variance | 0.524    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1899     |\n|    policy_loss        | 0.545    |\n|    value_loss         | 1.02     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 197      |\n|    ep_rew_mean     | 12.7     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 1900     |\n|    time_elapsed    | 571      |\n|    total_timesteps | 304000   |\n---------------------------------\nEval num_timesteps=320000, episode_reward=100.00 +/- 20.00\nEpisode length: 1850.60 +/- 92.39\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.85e+03 |\n|    mean_reward        | 100      |\n| time/                 |          |\n|    total_timesteps    | 320000   |\n| train/                |          |\n|    entropy_loss       | -2.05    |\n|    explained_variance | 0.722    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 1999     |\n|    policy_loss        | 0.947    |\n|    value_loss         | 1.44     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 184      |\n|    ep_rew_mean     | 12.5     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2000     |\n|    time_elapsed    | 600      |\n|    total_timesteps | 320000   |\n---------------------------------\nEval num_timesteps=336000, episode_reward=232.00 +/- 169.75\nEpisode length: 2445.80 +/- 370.62\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.45e+03 |\n|    mean_reward        | 232      |\n| time/                 |          |\n|    total_timesteps    | 336000   |\n| train/                |          |\n|    entropy_loss       | -2.03    |\n|    explained_variance | 0.321    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2099     |\n|    policy_loss        | -0.451   |\n|    value_loss         | 2.32     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 202      |\n|    ep_rew_mean     | 12.7     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 2100     |\n|    time_elapsed    | 630      |\n|    total_timesteps | 336000   |\n---------------------------------\nEval num_timesteps=352000, episode_reward=70.00 +/- 0.00\nEpisode length: 2121.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.12e+03 |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 352000   |\n| train/                |          |\n|    entropy_loss       | -2.09    |\n|    explained_variance | 0.478    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2199     |\n|    policy_loss        | 0.4      |\n|    value_loss         | 2.01     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 194      |\n|    ep_rew_mean     | 12.7     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 2200     |\n|    time_elapsed    | 660      |\n|    total_timesteps | 352000   |\n---------------------------------\nEval num_timesteps=368000, episode_reward=60.00 +/- 0.00\nEpisode length: 1857.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.86e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 368000   |\n| train/                |          |\n|    entropy_loss       | -1.99    |\n|    explained_variance | 0.725    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2299     |\n|    policy_loss        | 1.1      |\n|    value_loss         | 2.36     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 203      |\n|    ep_rew_mean     | 13.6     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2300     |\n|    time_elapsed    | 689      |\n|    total_timesteps | 368000   |\n---------------------------------\nEval num_timesteps=384000, episode_reward=274.00 +/- 92.00\nEpisode length: 2447.40 +/- 447.12\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.45e+03 |\n|    mean_reward        | 274      |\n| time/                 |          |\n|    total_timesteps    | 384000   |\n| train/                |          |\n|    entropy_loss       | -2.02    |\n|    explained_variance | 0.848    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2399     |\n|    policy_loss        | -0.443   |\n|    value_loss         | 0.698    |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 14.3     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2400     |\n|    time_elapsed    | 719      |\n|    total_timesteps | 384000   |\n---------------------------------\nEval num_timesteps=400000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.93e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 400000   |\n| train/                |          |\n|    entropy_loss       | -1.93    |\n|    explained_variance | 0.133    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2499     |\n|    policy_loss        | -1.64    |\n|    value_loss         | 2.96     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 183      |\n|    ep_rew_mean     | 12.6     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2500     |\n|    time_elapsed    | 749      |\n|    total_timesteps | 400000   |\n---------------------------------\nEval num_timesteps=416000, episode_reward=554.00 +/- 78.38\nEpisode length: 2572.20 +/- 101.90\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.57e+03 |\n|    mean_reward        | 554      |\n| time/                 |          |\n|    total_timesteps    | 416000   |\n| train/                |          |\n|    entropy_loss       | -2.07    |\n|    explained_variance | -0.1     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2599     |\n|    policy_loss        | 1.99     |\n|    value_loss         | 2.61     |\n------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 203      |\n|    ep_rew_mean     | 14.4     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2600     |\n|    time_elapsed    | 780      |\n|    total_timesteps | 416000   |\n---------------------------------\nEval num_timesteps=432000, episode_reward=204.00 +/- 4.90\nEpisode length: 2676.20 +/- 3.92\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.68e+03 |\n|    mean_reward        | 204      |\n| time/                 |          |\n|    total_timesteps    | 432000   |\n| train/                |          |\n|    entropy_loss       | -1.89    |\n|    explained_variance | 0.762    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2699     |\n|    policy_loss        | 0.702    |\n|    value_loss         | 1.66     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 190      |\n|    ep_rew_mean     | 13.9     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 2700     |\n|    time_elapsed    | 811      |\n|    total_timesteps | 432000   |\n---------------------------------\nEval num_timesteps=448000, episode_reward=210.00 +/- 0.00\nEpisode length: 1497.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.5e+03  |\n|    mean_reward        | 210      |\n| time/                 |          |\n|    total_timesteps    | 448000   |\n| train/                |          |\n|    entropy_loss       | -1.85    |\n|    explained_variance | 0.319    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2799     |\n|    policy_loss        | -1.22    |\n|    value_loss         | 7.85     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 195      |\n|    ep_rew_mean     | 15.1     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2800     |\n|    time_elapsed    | 839      |\n|    total_timesteps | 448000   |\n---------------------------------\nEval num_timesteps=464000, episode_reward=1068.00 +/- 632.12\nEpisode length: 2476.20 +/- 105.60\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.48e+03 |\n|    mean_reward        | 1.07e+03 |\n| time/                 |          |\n|    total_timesteps    | 464000   |\n| train/                |          |\n|    entropy_loss       | -2       |\n|    explained_variance | 0.671    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2899     |\n|    policy_loss        | -0.119   |\n|    value_loss         | 1.07     |\n------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 208      |\n|    ep_rew_mean     | 16       |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 2900     |\n|    time_elapsed    | 869      |\n|    total_timesteps | 464000   |\n---------------------------------\nEval num_timesteps=480000, episode_reward=122.00 +/- 63.69\nEpisode length: 2196.20 +/- 101.90\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.2e+03  |\n|    mean_reward        | 122      |\n| time/                 |          |\n|    total_timesteps    | 480000   |\n| train/                |          |\n|    entropy_loss       | -1.84    |\n|    explained_variance | 0.837    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 2999     |\n|    policy_loss        | -0.903   |\n|    value_loss         | 1.08     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 208      |\n|    ep_rew_mean     | 13.8     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 3000     |\n|    time_elapsed    | 899      |\n|    total_timesteps | 480000   |\n---------------------------------\nEval num_timesteps=496000, episode_reward=390.00 +/- 85.56\nEpisode length: 2369.00 +/- 193.20\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.37e+03 |\n|    mean_reward        | 390      |\n| time/                 |          |\n|    total_timesteps    | 496000   |\n| train/                |          |\n|    entropy_loss       | -2.07    |\n|    explained_variance | 0.775    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3099     |\n|    policy_loss        | -1       |\n|    value_loss         | 1.5      |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 211      |\n|    ep_rew_mean     | 13.2     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 3100     |\n|    time_elapsed    | 929      |\n|    total_timesteps | 496000   |\n---------------------------------\nEval num_timesteps=512000, episode_reward=486.00 +/- 122.25\nEpisode length: 2175.40 +/- 141.89\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.18e+03 |\n|    mean_reward        | 486      |\n| time/                 |          |\n|    total_timesteps    | 512000   |\n| train/                |          |\n|    entropy_loss       | -2       |\n|    explained_variance | 0.86     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3199     |\n|    policy_loss        | -0.507   |\n|    value_loss         | 0.292    |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 211      |\n|    ep_rew_mean     | 14       |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 3200     |\n|    time_elapsed    | 959      |\n|    total_timesteps | 512000   |\n---------------------------------\nEval num_timesteps=528000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.93e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 528000   |\n| train/                |          |\n|    entropy_loss       | -1.8     |\n|    explained_variance | 0.0656   |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3299     |\n|    policy_loss        | -1.62    |\n|    value_loss         | 6.96     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 208      |\n|    ep_rew_mean     | 15       |\n| time/              |          |\n|    fps             | 534      |\n|    iterations      | 3300     |\n|    time_elapsed    | 988      |\n|    total_timesteps | 528000   |\n---------------------------------\nEval num_timesteps=544000, episode_reward=120.00 +/- 20.00\nEpisode length: 2084.20 +/- 6.40\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.08e+03 |\n|    mean_reward        | 120      |\n| time/                 |          |\n|    total_timesteps    | 544000   |\n| train/                |          |\n|    entropy_loss       | -2.08    |\n|    explained_variance | 0.738    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3399     |\n|    policy_loss        | -0.361   |\n|    value_loss         | 0.857    |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 13.2     |\n| time/              |          |\n|    fps             | 534      |\n|    iterations      | 3400     |\n|    time_elapsed    | 1017     |\n|    total_timesteps | 544000   |\n---------------------------------\nEval num_timesteps=560000, episode_reward=180.00 +/- 26.83\nEpisode length: 1789.80 +/- 116.66\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.79e+03 |\n|    mean_reward        | 180      |\n| time/                 |          |\n|    total_timesteps    | 560000   |\n| train/                |          |\n|    entropy_loss       | -1.9     |\n|    explained_variance | 0.852    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3499     |\n|    policy_loss        | -0.962   |\n|    value_loss         | 1.32     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 197      |\n|    ep_rew_mean     | 14.1     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 3500     |\n|    time_elapsed    | 1046     |\n|    total_timesteps | 560000   |\n---------------------------------\nEval num_timesteps=576000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.93e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 576000   |\n| train/                |          |\n|    entropy_loss       | -2       |\n|    explained_variance | 0.812    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3599     |\n|    policy_loss        | 0.736    |\n|    value_loss         | 1.17     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 206      |\n|    ep_rew_mean     | 14       |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 3600     |\n|    time_elapsed    | 1075     |\n|    total_timesteps | 576000   |\n---------------------------------\nEval num_timesteps=592000, episode_reward=60.00 +/- 0.00\nEpisode length: 1929.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.93e+03 |\n|    mean_reward        | 60       |\n| time/                 |          |\n|    total_timesteps    | 592000   |\n| train/                |          |\n|    entropy_loss       | -1.85    |\n|    explained_variance | 0.77     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3699     |\n|    policy_loss        | 0.249    |\n|    value_loss         | 1.64     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 196      |\n|    ep_rew_mean     | 13.4     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 3700     |\n|    time_elapsed    | 1104     |\n|    total_timesteps | 592000   |\n---------------------------------\nEval num_timesteps=608000, episode_reward=452.00 +/- 137.17\nEpisode length: 1997.80 +/- 226.31\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2e+03    |\n|    mean_reward        | 452      |\n| time/                 |          |\n|    total_timesteps    | 608000   |\n| train/                |          |\n|    entropy_loss       | -1.93    |\n|    explained_variance | 0.0102   |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3799     |\n|    policy_loss        | 0.661    |\n|    value_loss         | 2.12     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 197      |\n|    ep_rew_mean     | 14.6     |\n| time/              |          |\n|    fps             | 536      |\n|    iterations      | 3800     |\n|    time_elapsed    | 1134     |\n|    total_timesteps | 608000   |\n---------------------------------\nEval num_timesteps=624000, episode_reward=390.00 +/- 0.00\nEpisode length: 2452.20 +/- 86.40\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.45e+03 |\n|    mean_reward        | 390      |\n| time/                 |          |\n|    total_timesteps    | 624000   |\n| train/                |          |\n|    entropy_loss       | -1.84    |\n|    explained_variance | 0.634    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3899     |\n|    policy_loss        | 0.0517   |\n|    value_loss         | 2        |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 205      |\n|    ep_rew_mean     | 15.9     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 3900     |\n|    time_elapsed    | 1164     |\n|    total_timesteps | 624000   |\n---------------------------------\nEval num_timesteps=640000, episode_reward=210.00 +/- 0.00\nEpisode length: 2937.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.94e+03 |\n|    mean_reward        | 210      |\n| time/                 |          |\n|    total_timesteps    | 640000   |\n| train/                |          |\n|    entropy_loss       | -1.47    |\n|    explained_variance | 0.758    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 3999     |\n|    policy_loss        | 0.0565   |\n|    value_loss         | 2.87     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 210      |\n|    ep_rew_mean     | 16.8     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4000     |\n|    time_elapsed    | 1196     |\n|    total_timesteps | 640000   |\n---------------------------------\nEval num_timesteps=656000, episode_reward=150.00 +/- 0.00\nEpisode length: 1969.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.97e+03 |\n|    mean_reward        | 150      |\n| time/                 |          |\n|    total_timesteps    | 656000   |\n| train/                |          |\n|    entropy_loss       | -1.8     |\n|    explained_variance | 0.357    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4099     |\n|    policy_loss        | -0.128   |\n|    value_loss         | 3.58     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 206      |\n|    ep_rew_mean     | 16.8     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4100     |\n|    time_elapsed    | 1225     |\n|    total_timesteps | 656000   |\n---------------------------------\nEval num_timesteps=672000, episode_reward=446.00 +/- 54.26\nEpisode length: 1981.80 +/- 114.67\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.98e+03 |\n|    mean_reward        | 446      |\n| time/                 |          |\n|    total_timesteps    | 672000   |\n| train/                |          |\n|    entropy_loss       | -1.57    |\n|    explained_variance | 0.709    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4199     |\n|    policy_loss        | 0.433    |\n|    value_loss         | 7.02     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 218      |\n|    ep_rew_mean     | 15.7     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4200     |\n|    time_elapsed    | 1253     |\n|    total_timesteps | 672000   |\n---------------------------------\nEval num_timesteps=688000, episode_reward=230.00 +/- 0.00\nEpisode length: 2561.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.56e+03 |\n|    mean_reward        | 230      |\n| time/                 |          |\n|    total_timesteps    | 688000   |\n| train/                |          |\n|    entropy_loss       | -1.89    |\n|    explained_variance | 0.825    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4299     |\n|    policy_loss        | 0.747    |\n|    value_loss         | 3.38     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 208      |\n|    ep_rew_mean     | 16.1     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4300     |\n|    time_elapsed    | 1284     |\n|    total_timesteps | 688000   |\n---------------------------------\nEval num_timesteps=704000, episode_reward=252.00 +/- 296.74\nEpisode length: 2135.40 +/- 357.68\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.14e+03 |\n|    mean_reward        | 252      |\n| time/                 |          |\n|    total_timesteps    | 704000   |\n| train/                |          |\n|    entropy_loss       | -1.98    |\n|    explained_variance | 0.384    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4399     |\n|    policy_loss        | 0.701    |\n|    value_loss         | 2.83     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 182      |\n|    ep_rew_mean     | 12.7     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4400     |\n|    time_elapsed    | 1314     |\n|    total_timesteps | 704000   |\n---------------------------------\nEval num_timesteps=720000, episode_reward=320.00 +/- 26.83\nEpisode length: 2349.80 +/- 450.30\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.35e+03 |\n|    mean_reward        | 320      |\n| time/                 |          |\n|    total_timesteps    | 720000   |\n| train/                |          |\n|    entropy_loss       | -1.96    |\n|    explained_variance | 0.57     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4499     |\n|    policy_loss        | -0.349   |\n|    value_loss         | 0.83     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 190      |\n|    ep_rew_mean     | 13.9     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4500     |\n|    time_elapsed    | 1344     |\n|    total_timesteps | 720000   |\n---------------------------------\nEval num_timesteps=736000, episode_reward=668.00 +/- 180.04\nEpisode length: 2300.20 +/- 322.30\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.3e+03  |\n|    mean_reward        | 668      |\n| time/                 |          |\n|    total_timesteps    | 736000   |\n| train/                |          |\n|    entropy_loss       | -1.92    |\n|    explained_variance | 0.35     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4599     |\n|    policy_loss        | 0.569    |\n|    value_loss         | 1.44     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 196      |\n|    ep_rew_mean     | 13.5     |\n| time/              |          |\n|    fps             | 535      |\n|    iterations      | 4600     |\n|    time_elapsed    | 1374     |\n|    total_timesteps | 736000   |\n---------------------------------\nEval num_timesteps=752000, episode_reward=464.00 +/- 72.00\nEpisode length: 3481.00 +/- 252.17\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 3.48e+03 |\n|    mean_reward        | 464      |\n| time/                 |          |\n|    total_timesteps    | 752000   |\n| train/                |          |\n|    entropy_loss       | -1.93    |\n|    explained_variance | 0.425    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4699     |\n|    policy_loss        | 0.0291   |\n|    value_loss         | 2.75     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 215      |\n|    ep_rew_mean     | 16.3     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 4700     |\n|    time_elapsed    | 1408     |\n|    total_timesteps | 752000   |\n---------------------------------\nEval num_timesteps=768000, episode_reward=286.00 +/- 138.65\nEpisode length: 1921.00 +/- 205.40\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.92e+03 |\n|    mean_reward        | 286      |\n| time/                 |          |\n|    total_timesteps    | 768000   |\n| train/                |          |\n|    entropy_loss       | -2.05    |\n|    explained_variance | 0.81     |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4799     |\n|    policy_loss        | 0.647    |\n|    value_loss         | 0.664    |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 14.6     |\n| time/              |          |\n|    fps             | 534      |\n|    iterations      | 4800     |\n|    time_elapsed    | 1437     |\n|    total_timesteps | 768000   |\n---------------------------------\nEval num_timesteps=784000, episode_reward=210.00 +/- 0.00\nEpisode length: 2937.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.94e+03 |\n|    mean_reward        | 210      |\n| time/                 |          |\n|    total_timesteps    | 784000   |\n| train/                |          |\n|    entropy_loss       | -1.69    |\n|    explained_variance | 0.248    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4899     |\n|    policy_loss        | -1.88    |\n|    value_loss         | 5.87     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 194      |\n|    ep_rew_mean     | 15.1     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 4900     |\n|    time_elapsed    | 1469     |\n|    total_timesteps | 784000   |\n---------------------------------\nEval num_timesteps=800000, episode_reward=214.00 +/- 8.00\nEpisode length: 1997.80 +/- 102.40\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2e+03    |\n|    mean_reward        | 214      |\n| time/                 |          |\n|    total_timesteps    | 800000   |\n| train/                |          |\n|    entropy_loss       | -1.82    |\n|    explained_variance | 0.562    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 4999     |\n|    policy_loss        | 2.24     |\n|    value_loss         | 3.61     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 191      |\n|    ep_rew_mean     | 15.4     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5000     |\n|    time_elapsed    | 1498     |\n|    total_timesteps | 800000   |\n---------------------------------\nEval num_timesteps=816000, episode_reward=130.00 +/- 73.48\nEpisode length: 2122.60 +/- 7.84\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.12e+03 |\n|    mean_reward        | 130      |\n| time/                 |          |\n|    total_timesteps    | 816000   |\n| train/                |          |\n|    entropy_loss       | -1.33    |\n|    explained_variance | 0.705    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5099     |\n|    policy_loss        | -0.862   |\n|    value_loss         | 2.21     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 203      |\n|    ep_rew_mean     | 15.4     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5100     |\n|    time_elapsed    | 1528     |\n|    total_timesteps | 816000   |\n---------------------------------\nEval num_timesteps=832000, episode_reward=654.00 +/- 191.06\nEpisode length: 2964.20 +/- 368.40\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.96e+03 |\n|    mean_reward        | 654      |\n| time/                 |          |\n|    total_timesteps    | 832000   |\n| train/                |          |\n|    entropy_loss       | -2.06    |\n|    explained_variance | 0.609    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5199     |\n|    policy_loss        | 0.465    |\n|    value_loss         | 1.19     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 205      |\n|    ep_rew_mean     | 14.6     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5200     |\n|    time_elapsed    | 1560     |\n|    total_timesteps | 832000   |\n---------------------------------\nEval num_timesteps=848000, episode_reward=478.00 +/- 210.66\nEpisode length: 2097.00 +/- 391.92\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.1e+03  |\n|    mean_reward        | 478      |\n| time/                 |          |\n|    total_timesteps    | 848000   |\n| train/                |          |\n|    entropy_loss       | -2.01    |\n|    explained_variance | 0.659    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5299     |\n|    policy_loss        | 0.98     |\n|    value_loss         | 3.72     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 191      |\n|    ep_rew_mean     | 14.6     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5300     |\n|    time_elapsed    | 1590     |\n|    total_timesteps | 848000   |\n---------------------------------\nEval num_timesteps=864000, episode_reward=606.00 +/- 577.32\nEpisode length: 2413.80 +/- 335.49\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.41e+03 |\n|    mean_reward        | 606      |\n| time/                 |          |\n|    total_timesteps    | 864000   |\n| train/                |          |\n|    entropy_loss       | -1.85    |\n|    explained_variance | 0.813    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5399     |\n|    policy_loss        | 1.48     |\n|    value_loss         | 1.62     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 203      |\n|    ep_rew_mean     | 16.2     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5400     |\n|    time_elapsed    | 1620     |\n|    total_timesteps | 864000   |\n---------------------------------\nEval num_timesteps=880000, episode_reward=196.00 +/- 42.24\nEpisode length: 1543.40 +/- 184.90\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.54e+03 |\n|    mean_reward        | 196      |\n| time/                 |          |\n|    total_timesteps    | 880000   |\n| train/                |          |\n|    entropy_loss       | -1.96    |\n|    explained_variance | 0.899    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5499     |\n|    policy_loss        | -0.986   |\n|    value_loss         | 1.16     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 207      |\n|    ep_rew_mean     | 16.3     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5500     |\n|    time_elapsed    | 1649     |\n|    total_timesteps | 880000   |\n---------------------------------\nEval num_timesteps=896000, episode_reward=620.00 +/- 189.84\nEpisode length: 2495.40 +/- 365.57\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.5e+03  |\n|    mean_reward        | 620      |\n| time/                 |          |\n|    total_timesteps    | 896000   |\n| train/                |          |\n|    entropy_loss       | -2.09    |\n|    explained_variance | 0.434    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5599     |\n|    policy_loss        | 1.04     |\n|    value_loss         | 2.44     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 182      |\n|    ep_rew_mean     | 12.2     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5600     |\n|    time_elapsed    | 1679     |\n|    total_timesteps | 896000   |\n---------------------------------\nEval num_timesteps=912000, episode_reward=388.00 +/- 64.00\nEpisode length: 2380.20 +/- 161.96\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.38e+03 |\n|    mean_reward        | 388      |\n| time/                 |          |\n|    total_timesteps    | 912000   |\n| train/                |          |\n|    entropy_loss       | -1.95    |\n|    explained_variance | 0.556    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5699     |\n|    policy_loss        | -0.751   |\n|    value_loss         | 1.51     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 203      |\n|    ep_rew_mean     | 15.6     |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5700     |\n|    time_elapsed    | 1709     |\n|    total_timesteps | 912000   |\n---------------------------------\nEval num_timesteps=928000, episode_reward=400.00 +/- 187.94\nEpisode length: 2447.40 +/- 574.70\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.45e+03 |\n|    mean_reward        | 400      |\n| time/                 |          |\n|    total_timesteps    | 928000   |\n| train/                |          |\n|    entropy_loss       | -1.85    |\n|    explained_variance | 0.611    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5799     |\n|    policy_loss        | -2.76    |\n|    value_loss         | 5.08     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 220      |\n|    ep_rew_mean     | 18       |\n| time/              |          |\n|    fps             | 533      |\n|    iterations      | 5800     |\n|    time_elapsed    | 1740     |\n|    total_timesteps | 928000   |\n---------------------------------\nEval num_timesteps=944000, episode_reward=402.00 +/- 37.09\nEpisode length: 2653.80 +/- 65.11\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.65e+03 |\n|    mean_reward        | 402      |\n| time/                 |          |\n|    total_timesteps    | 944000   |\n| train/                |          |\n|    entropy_loss       | -1.92    |\n|    explained_variance | 0.772    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5899     |\n|    policy_loss        | 1.89     |\n|    value_loss         | 2.38     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 183      |\n|    ep_rew_mean     | 13.5     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 5900     |\n|    time_elapsed    | 1772     |\n|    total_timesteps | 944000   |\n---------------------------------\nEval num_timesteps=960000, episode_reward=70.00 +/- 0.00\nEpisode length: 2197.80 +/- 22.40\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.2e+03  |\n|    mean_reward        | 70       |\n| time/                 |          |\n|    total_timesteps    | 960000   |\n| train/                |          |\n|    entropy_loss       | -1.79    |\n|    explained_variance | -0.0145  |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 5999     |\n|    policy_loss        | -0.877   |\n|    value_loss         | 4.79     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 188      |\n|    ep_rew_mean     | 15.1     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 6000     |\n|    time_elapsed    | 1802     |\n|    total_timesteps | 960000   |\n---------------------------------\nEval num_timesteps=976000, episode_reward=428.00 +/- 161.42\nEpisode length: 2373.80 +/- 405.45\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 2.37e+03 |\n|    mean_reward        | 428      |\n| time/                 |          |\n|    total_timesteps    | 976000   |\n| train/                |          |\n|    entropy_loss       | -1.87    |\n|    explained_variance | 0.462    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 6099     |\n|    policy_loss        | 2.71     |\n|    value_loss         | 5.21     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 201      |\n|    ep_rew_mean     | 18       |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 6100     |\n|    time_elapsed    | 1832     |\n|    total_timesteps | 976000   |\n---------------------------------\nEval num_timesteps=992000, episode_reward=210.00 +/- 0.00\nEpisode length: 1497.00 +/- 0.00\n------------------------------------\n| eval/                 |          |\n|    mean_ep_length     | 1.5e+03  |\n|    mean_reward        | 210      |\n| time/                 |          |\n|    total_timesteps    | 992000   |\n| train/                |          |\n|    entropy_loss       | -1.09    |\n|    explained_variance | 0.612    |\n|    learning_rate      | 0.000239 |\n|    n_updates          | 6199     |\n|    policy_loss        | -0.218   |\n|    value_loss         | 4.35     |\n------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 191      |\n|    ep_rew_mean     | 16.6     |\n| time/              |          |\n|    fps             | 532      |\n|    iterations      | 6200     |\n|    time_elapsed    | 1861     |\n|    total_timesteps | 992000   |\n---------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1,000,000/1,000,000 \u001b[0m [ \u001b[33m0:31:11\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m572 it/s\u001b[0m ]\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">1,000,000/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:31:11</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">572 it/s</span> ]\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"A2C training complete and saved.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"eval_env = make_eval_env()\n\nmean_reward, std_reward = evaluate_policy(\n    a2c_model,\n    eval_env,\n    n_eval_episodes=10,\n    deterministic=True\n)\n\nprint(f\"A2C Evaluation → Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T00:13:54.809303Z","iopub.execute_input":"2025-12-15T00:13:54.809599Z","iopub.status.idle":"2025-12-15T00:14:03.875523Z","shell.execute_reply.started":"2025-12-15T00:13:54.809579Z","shell.execute_reply":"2025-12-15T00:14:03.874692Z"}},"outputs":[{"name":"stdout","text":"A2C Evaluation → Mean reward: 210.00 ± 0.00\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## Evaluation & Comparison","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom stable_baselines3.common.evaluation import evaluate_policy\n\n# List of models to evaluate\nmodel_names = [\"PPO\", \"DQN\", \"A2C\"]\nmodel_paths = [\n    \"./models/ppo_ms_pacman_final.zip\",\n    \"./models/dqn_ms_pacman_final.zip\",\n    \"./models/a2c_ms_pacman_final.zip\"\n]\nmodel_classes = [PPO, DQN, A2C]\n\nresults = []\n\nprint(\"Starting final evaluations...\")\n\nfor name, path, model_cls in zip(model_names, model_paths, model_classes):\n    # Load model\n    model = model_cls.load(path)\n    \n    # Evaluate over 20 episodes\n    mean_reward, std_reward = evaluate_policy(\n        model, \n        make_eval_env(), \n        n_eval_episodes=20, \n        deterministic=True\n    )\n    \n    results.append({\n        \"Model\": name,\n        \"Mean Reward\": round(mean_reward, 2),\n        \"Std Dev\": round(std_reward, 2)\n    })\n    print(f\"Finished evaluating {name}\")\n\n# Create and display table\ndf_results = pd.DataFrame(results)\ndf_results.to_csv(\"./results/pacman_comparison_table.csv\", index=False)\nprint(\"\\n--- Final Performance Comparison ---\")\nprint(df_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T00:11:05.408644Z","iopub.execute_input":"2025-12-15T00:11:05.409512Z","iopub.status.idle":"2025-12-15T00:12:32.544821Z","shell.execute_reply.started":"2025-12-15T00:11:05.409487Z","shell.execute_reply":"2025-12-15T00:12:32.544187Z"}},"outputs":[{"name":"stdout","text":"Starting final evaluations...\nFinished evaluating PPO\nFinished evaluating DQN\nFinished evaluating A2C\n\n--- Final Performance Comparison ---\n  Model  Mean Reward  Std Dev\n0   PPO       1675.5   354.31\n1   DQN        680.5   359.49\n2   A2C        210.0     0.00\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## Plotting Training","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_pacman_results(eval_log_paths, labels):\n    plt.figure(figsize=(10, 6))\n    \n    for log_path, label in zip(eval_log_paths, labels):\n        # Load the .npz file created by EvalCallback\n        data = np.load(f\"{log_path}/evaluations.npz\")\n        timesteps = data['timesteps']\n        # results shape is (n_evaluations, n_eval_episodes), we want the mean across episodes\n        mean_rewards = np.mean(data['results'], axis=1)\n        \n        plt.plot(timesteps, mean_rewards, label=label, linewidth=2)\n        plt.fill_between(\n            timesteps, \n            mean_rewards - np.std(data['results'], axis=1), \n            mean_rewards + np.std(data['results'], axis=1), \n            alpha=0.1\n        )\n\n    plt.title(f\"Ms. Pac-Man: Training Progress Comparison (1M steps)\", fontsize=14)\n    plt.xlabel(\"Total Timesteps\", fontsize=12)\n    plt.ylabel(\"Average Evaluation Reward\", fontsize=12)\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.6)\n    plt.savefig(\"./results/training_comparison_plot.png\")\n    plt.show()\n\n# Run the plotting function\neval_paths = [\"./logs/ppo_eval/\", \"./logs/dqn_eval/\", \"./logs/a2c_eval/\"]\nplot_pacman_results(eval_paths, [\"PPO\", \"DQN\", \"A2C\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T00:02:26.217792Z","iopub.execute_input":"2025-12-15T00:02:26.218408Z","iopub.status.idle":"2025-12-15T00:02:26.558063Z","shell.execute_reply.started":"2025-12-15T00:02:26.218382Z","shell.execute_reply":"2025-12-15T00:02:26.557305Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from stable_baselines3.common.vec_env import VecVideoRecorder\n\nos.makedirs(\"./videos\", exist_ok=True)\n\ndef record_gameplay(model, model_name, video_length=2000):\n    \"\"\"\n    Record a single gameplay video for a trained model.\n    \"\"\"\n\n    # Create evaluation environment\n    video_env = make_atari_env(ENV_NAME, n_envs=1, seed=42)\n    video_env = VecFrameStack(video_env, n_stack=N_STACK)\n\n    # Wrap with video recorder\n    video_env = VecVideoRecorder(\n        video_env,\n        video_folder=\"./videos/\",\n        record_video_trigger=lambda step: step == 0,\n        video_length=video_length,\n        name_prefix=model_name\n    )\n\n    obs = video_env.reset()\n    done = False\n    step = 0\n\n    print(f\"Recording video for {model_name}...\")\n\n    while not done and step < video_length:\n        action, _ = model.predict(obs, deterministic=True)\n        obs, _, done, _ = video_env.step(action)\n        step += 1\n\n    video_env.close()\n    print(f\"Saved video: ./videos/{model_name}-step-0.mp4\")\n\n# Load trained models\nppo_model = PPO.load(\"./models/ppo_ms_pacman_final\")\ndqn_model = DQN.load(\"./models/dqn_ms_pacman_final\")\na2c_model = A2C.load(\"./models/a2c_ms_pacman_final\")\n\n# Record gameplay\nrecord_gameplay(ppo_model, \"PPO_MsPacman\")\nrecord_gameplay(dqn_model, \"DQN_MsPacman\")\nrecord_gameplay(a2c_model, \"A2C_MsPacman\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T23:44:03.455732Z","iopub.execute_input":"2025-12-14T23:44:03.456340Z","iopub.status.idle":"2025-12-14T23:44:07.257953Z","shell.execute_reply.started":"2025-12-14T23:44:03.456317Z","shell.execute_reply":"2025-12-14T23:44:07.257237Z"}},"outputs":[{"name":"stdout","text":"Recording video for PPO_MsPacman...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/moviepy/config_defaults.py:1: DeprecationWarning: invalid escape sequence '\\P'\n  \"\"\"\n","output_type":"stream"},{"name":"stdout","text":"Moviepy - Building video /kaggle/working/videos/PPO_MsPacman-step-0-to-step-2000.mp4.\nMoviepy - Writing video /kaggle/working/videos/PPO_MsPacman-step-0-to-step-2000.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready /kaggle/working/videos/PPO_MsPacman-step-0-to-step-2000.mp4\nSaved video: ./videos/PPO_MsPacman-step-0.mp4\nRecording video for DQN_MsPacman...\nMoviepy - Building video /kaggle/working/videos/DQN_MsPacman-step-0-to-step-2000.mp4.\nMoviepy - Writing video /kaggle/working/videos/DQN_MsPacman-step-0-to-step-2000.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                    ","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready /kaggle/working/videos/DQN_MsPacman-step-0-to-step-2000.mp4\nSaved video: ./videos/DQN_MsPacman-step-0.mp4\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Recording video for A2C_MsPacman...\nMoviepy - Building video /kaggle/working/videos/A2C_MsPacman-step-0-to-step-2000.mp4.\nMoviepy - Writing video /kaggle/working/videos/A2C_MsPacman-step-0-to-step-2000.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                    ","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready /kaggle/working/videos/A2C_MsPacman-step-0-to-step-2000.mp4\nSaved video: ./videos/A2C_MsPacman-step-0.mp4\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":40}]}