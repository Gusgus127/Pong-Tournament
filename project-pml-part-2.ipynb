{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Paradigms of Machine Learning\n\n## Project, Part 2: Pong World Tournament\n\n<u>General considerations</u>:\n\n- The proposed solution cannot use methods, functions or parameters declared **_deprecated_** in future versions.\n- This activity must be carried out on a **strictly individual** basis. Any indication of copying will be penalized with a failure for all parties involved and the possible negative evaluation of the subject in its entirety.\n- It is necessary for the student to indicate **all the sources** that she/he has used to carry out the PRA. If not, the student will be considered to have committed plagiarism, being penalized with a failure and the possible negative evaluation of the subject in its entirety.\n\n<u>Delivery format</u>:\n\n- Some exercises may require several minutes of execution, so the delivery must be done in **Notebook format** and in **HTML format**, where the code, results and comments of each exercise can be seen. You can export the notebook to HTML from the menu File $\\to$ Download as $\\to$ HTML.\n- There is a special type of cell to hold text. This type of cell will be very useful to answer the different theoretical questions posed throughout the activity. To change the cell type to this type, in the menu: Cell $\\to$ Cell Type $\\to$ Markdown.","metadata":{"id":"7xrRvDDNLUxK"}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<strong>Name and surname: Albert Saludas & Noa Solé</strong>\n</div>","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nThe [PettingZoo](https://pettingzoo.farama.org/index.html) is a simple, pythonic interface capable of representing **general multi-agent reinforcement learning** (MARL) problems. PettingZoo includes a wide variety of reference environments, helpful utilities, and tools for creating your own custom environments.\n\nThis activity uses the **AEC API**, which supports sequential turn-based environments.\n\nPettingZoo could be combined with [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/) or any other library to train the models.","metadata":{"id":"gee4aY31LUxL"}},{"cell_type":"markdown","source":"## Required libraries and dataset\n\nThe following libraries are required to properly run this activity: \n\n> !pip install swig\n\n> !pip install box2d-py\n\n> !pip install gymnasium\n\n> !pip install \"gymnasium[atari,accept-rom-license]\"\n\n> !pip install \"stable-baselines3[extra]\"\n\n> !pip install \"pettingzoo[all]\"\n\n> !pip install supersuit\n\n**Notes**:\n- **AutoROM** must be installed on the Python environment: `pip install \"autorom[accept-rom-license]\"` and then execute `AutoROM` from the command line.","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y ale-py gymnasium\n!pip install gymnasium==1.0.0\n!pip install ale-py==0.10.1\n!pip install stable-baselines3==2.4.0\n!pip install supersuit==3.9.3\n!pip install pettingzoo==1.24.3\n!pip install AutoROM==0.6.1\n!pip install multi-agent-ale-py==0.1.11\n!pip install wandb==0.19.0\n\n# Accept ROM license\n!AutoROM --accept-license","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T14:33:24.887125Z","iopub.execute_input":"2025-12-13T14:33:24.887279Z","iopub.status.idle":"2025-12-13T14:38:01.548152Z","shell.execute_reply.started":"2025-12-13T14:33:24.887263Z","shell.execute_reply":"2025-12-13T14:38:01.547372Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: ale-py 0.11.2\nUninstalling ale-py-0.11.2:\n  Successfully uninstalled ale-py-0.11.2\nFound existing installation: gymnasium 0.29.0\nUninstalling gymnasium-0.29.0:\n  Successfully uninstalled gymnasium-0.29.0\nCollecting gymnasium==1.0.0\n  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium==1.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: gymnasium\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires ale-py>=0.10.1, which is not installed.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gymnasium-1.0.0\nCollecting ale-py==0.10.1\n  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py==0.10.1) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20->ale-py==0.10.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nDownloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py\nSuccessfully installed ale-py-0.10.1\nCollecting stable-baselines3==2.4.0\n  Downloading stable_baselines3-2.4.0-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (1.0.0)\nRequirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (2.6.0+cu124)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (3.1.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (3.7.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3==2.4.0) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3==2.4.0) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.20.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3==2.4.0) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.4.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.4.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.4.0) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.4.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nDownloading stable_baselines3-2.4.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: stable-baselines3\n    Found existing installation: stable-baselines3 2.1.0\n    Uninstalling stable-baselines3-2.1.0:\n      Successfully uninstalled stable-baselines3-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.4.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.4.0\nCollecting supersuit==3.9.3\n  Downloading SuperSuit-3.9.3-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from supersuit==3.9.3) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from supersuit==3.9.3) (1.0.0)\nCollecting tinyscaler>=1.2.6 (from supersuit==3.9.3)\n  Downloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->supersuit==3.9.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nDownloading SuperSuit-3.9.3-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (563 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tinyscaler, supersuit\nSuccessfully installed supersuit-3.9.3 tinyscaler-1.2.8\nCollecting pettingzoo==1.24.3\n  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3) (1.0.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->pettingzoo==1.24.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pettingzoo\n  Attempting uninstall: pettingzoo\n    Found existing installation: pettingzoo 1.24.0\n    Uninstalling pettingzoo-1.24.0:\n      Successfully uninstalled pettingzoo-1.24.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires pettingzoo==1.24.0, but you have pettingzoo 1.24.3 which is incompatible.\nkaggle-environments 1.18.0 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pettingzoo-1.24.3\nCollecting AutoROM==0.6.1\n  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from AutoROM==0.6.1) (8.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from AutoROM==0.6.1) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (2025.10.5)\nDownloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\nInstalling collected packages: AutoROM\nSuccessfully installed AutoROM-0.6.1\nCollecting multi-agent-ale-py==0.1.11\n  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from multi-agent-ale-py==0.1.11) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->multi-agent-ale-py==0.1.11) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nBuilding wheels for collected packages: multi-agent-ale-py\n  Building wheel for multi-agent-ale-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for multi-agent-ale-py: filename=multi_agent_ale_py-0.1.11-cp311-cp311-linux_x86_64.whl size=721821 sha256=1c12b0e688ac160a47f359badbce26213e5790436f4a8718d71fe83decc5d37a\n  Stored in directory: /root/.cache/pip/wheels/1d/81/76/771ec8e34292c8a71dd6c4a52a1c0401f4d93cbfb54e02fce4\nSuccessfully built multi-agent-ale-py\nInstalling collected packages: multi-agent-ale-py\nSuccessfully installed multi-agent-ale-py-0.1.11\nCollecting wandb==0.19.0\n  Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (8.3.0)\nCollecting docker-pycreds>=0.4.0 (from wandb==0.19.0)\n  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (3.1.45)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (4.5.0)\nCollecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb==0.19.0)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (7.1.3)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.12.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (6.0.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.33.2)\nCollecting setproctitle (from wandb==0.19.0)\n  Downloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (4.15.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb==0.19.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.19.0) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (2025.10.5)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.19.0) (5.0.2)\nDownloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\nInstalling collected packages: setproctitle, protobuf, docker-pycreds, wandb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.21.0\n    Uninstalling wandb-0.21.0:\n      Successfully uninstalled wandb-0.21.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed docker-pycreds-0.4.0 protobuf-5.29.5 setproctitle-1.3.7 wandb-0.19.0\nAutoROM will download the Atari 2600 ROMs.\nThey will be installed to:\n\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n\t/usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms\n\nExisting ROMs will be overwritten.\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/adventure.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/adventure.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/air_raid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/air_raid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/alien.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/alien.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/amidar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/amidar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/assault.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/assault.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asterix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asterix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asteroids.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asteroids.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/backgammon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/backgammon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bank_heist.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/basic_math.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/basic_math.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/battle_zone.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/beam_rider.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/berzerk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/berzerk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/blackjack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/blackjack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bowling.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bowling.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/boxing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/boxing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/breakout.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/breakout.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/carnival.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/carnival.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/casino.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/casino.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/centipede.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/centipede.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/chopper_command.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/combat.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/combat.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crazy_climber.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crossbow.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crossbow.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/darkchambers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/defender.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/defender.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/demon_attack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/donkey_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/double_dunk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/earthworld.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/earthworld.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/elevator_action.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/enduro.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/enduro.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/entombed.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/entombed.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/et.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/et.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/fishing_derby.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/flag_capture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/freeway.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/freeway.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frogger.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frogger.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frostbite.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frostbite.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/galaxian.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/galaxian.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gopher.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gopher.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gravitar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gravitar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hangman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hangman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/haunted_house.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hero.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hero.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/human_cannonball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ice_hockey.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/jamesbond.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/journey_escape.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/joust.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/joust.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kaboom.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kaboom.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kangaroo.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/keystone_kapers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/king_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/king_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/klax.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/klax.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/koolaid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/koolaid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/krull.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/krull.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kung_fu_master.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/laser_gates.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/lost_luggage.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mario_bros.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/maze_craze.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/miniature_golf.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/montezuma_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mr_do.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mr_do.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ms_pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/name_this_game.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/othello.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/othello.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/phoenix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/phoenix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pooyan.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pooyan.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/private_eye.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/private_eye.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/qbert.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/qbert.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/riverraid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/riverraid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/road_runner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/road_runner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/robotank.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/robotank.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/seaquest.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/seaquest.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/sir_lancelot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/skiing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/skiing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/solaris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/solaris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_invaders.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_war.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_war.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/star_gunner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/superman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/superman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/surround.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/surround.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tennis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tennis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tetris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tetris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/time_pilot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/trondead.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/trondead.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/turmoil.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/turmoil.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tutankham.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tutankham.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/up_n_down.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/venture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/venture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_checkers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_chess.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_chess.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_cube.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_cube.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_pinball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/warlords.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/warlords.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/wizard_of_wor.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/word_zapper.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/yars_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/zaxxon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\nDone!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Configuring the environment\n\nThe [Supersuit Wrappers](https://pettingzoo.farama.org/api/wrappers/supersuit_wrappers/) are used to preprocess the data in our environment.\n\nSpecifically, the environment uses the following wrappers:\n1. The `color_reduction_v0` wrapper with `mode='B'` parameter.\n2. The `resize_v1` with parameters `x_size=84` and `y_size=84`.\n3. The `frame_stack_v1` wrapper with params `num_frames=4`.\n4. The `dtype_v0` with param  `dtype=np.float32`.\n5. The `normalize_obs_v0` wrapper with parameters `env_min=0`and `env_max=1`.","metadata":{}},{"cell_type":"markdown","source":"#### The observation Space\n\nTherefore, the **observation** from the environment has the shape:\n- (84 $\\times$ 84 $\\times$ 4)\n\nSo, each image looks like the following one:","metadata":{}},{"cell_type":"markdown","source":"<p style=\"text-align:center;\"><img src=\"data:image/png;base64,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\" /></p>","metadata":{}},{"cell_type":"markdown","source":"### The Action Space\n\nAs described in the [Pong](https://pettingzoo.farama.org/environments/atari/pong/) page, action is `Discrete(6)`, so:\n- Action shape is _(1,)_\n- Action values are in range [0,5]","metadata":{}},{"cell_type":"markdown","source":"## Environment Setup and Preprocessing","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport gymnasium as gym\nimport ale_py\nfrom datetime import datetime\nimport os\nimport sys\nimport yaml\nimport wandb\nfrom wandb.integration.sb3 import WandbCallback\n\nimport supersuit as ss\nfrom pettingzoo.atari import pong_v3\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.callbacks import EvalCallback, CallbackList\nfrom stable_baselines3.common.evaluation import evaluate_policy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T14:39:07.608570Z","iopub.execute_input":"2025-12-13T14:39:07.609111Z","iopub.status.idle":"2025-12-13T14:39:35.145015Z","shell.execute_reply.started":"2025-12-13T14:39:07.609077Z","shell.execute_reply":"2025-12-13T14:39:35.144408Z"}},"outputs":[{"name":"stderr","text":"2025-12-13 14:39:17.020815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765636757.413850      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765636757.548986      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  from pkg_resources import resource_stream, resource_exists\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class PongWrapper(gym.Wrapper):\n    \"\"\"\n    Wrapper for the environment using the supersuit library.\n    \"\"\"\n    def __init__(self, env, frame_stack=4):\n        env = ss.color_reduction_v0(env, mode=\"B\")\n        env = ss.resize_v1(env, x_size=84, y_size=84)\n        env = ss.frame_stack_v1(env, frame_stack, stack_dim=0)\n        env = ss.dtype_v0(env, dtype=np.float32)\n        env = ss.normalize_obs_v0(env, env_min=0, env_max=1)\n        env = ss.reshape_v0(env, (frame_stack, 84, 84))\n        \n        super().__init__(env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T14:39:35.146233Z","iopub.execute_input":"2025-12-13T14:39:35.146951Z","iopub.status.idle":"2025-12-13T14:39:35.151754Z","shell.execute_reply.started":"2025-12-13T14:39:35.146929Z","shell.execute_reply":"2025-12-13T14:39:35.151196Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Create training environment for single-agent Pong\ndef create_single_agent_env(n_envs=4, frame_stack=4):\n    \"\"\"Create vectorized environment for single-agent training\"\"\"\n    env = make_vec_env(\n        \"ALE/Pong-v5\",\n        n_envs=n_envs,\n        wrapper_class=PongWrapper,\n        wrapper_kwargs={\"frame_stack\": frame_stack},\n        env_kwargs={\"frameskip\": 4}\n    )\n    return env\n\n# Test environment\ntrain_env = create_single_agent_env(n_envs=4)\nprint(\"Observation space:\", train_env.observation_space)\nprint(\"Action space:\", train_env.action_space)\nprint(\"Number of actions:\", train_env.action_space.n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T14:39:35.152354Z","iopub.execute_input":"2025-12-13T14:39:35.152848Z","iopub.status.idle":"2025-12-13T14:39:35.806230Z","shell.execute_reply.started":"2025-12-13T14:39:35.152822Z","shell.execute_reply":"2025-12-13T14:39:35.805575Z"}},"outputs":[{"name":"stderr","text":"A.L.E: Arcade Learning Environment (version 0.10.1+unknown)\n[Powered by Stella]\n","output_type":"stream"},{"name":"stdout","text":"Observation space: Box(0.0, 1.0, (4, 84, 84), float32)\nAction space: Discrete(6)\nNumber of actions: 6\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**We choose PPO (Proximal Policy Optimization) because:**\n- It is the most stable on Atari games.\n- It works well with high-dimensional visual inputs.\n- It is widely used in the literature for Pong.\n- SB3 provides a strong implementation with CNN policies.","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"# Define parameter grid for tuning\nparam_grid = [\n    {\n        \"learning_rate\": 2.5e-4,\n        \"n_steps\": 2048,\n        \"batch_size\": 64,\n        \"gamma\": 0.99,\n        \"clip_range\": 0.2,\n    },\n    {\n        \"learning_rate\": 1e-3,\n        \"n_steps\": 1024,\n        \"batch_size\": 128,\n        \"gamma\": 0.95,\n        \"clip_range\": 0.1,\n    },\n    {\n        \"learning_rate\": 5e-4,\n        \"n_steps\": 1024,\n        \"batch_size\": 256,\n        \"gamma\": 0.99,\n        \"clip_range\": 0.3,\n    },\n]\n\ndef tune_parameters(params, trial_name):\n    \"\"\"Train and evaluate with given parameters\"\"\"\n    print(f\"\\nTrial: {trial_name}\")\n    print(f\"Parameters: {params}\")\n    \n    # Create environment\n    env = create_single_agent_env(n_envs=2)\n    \n    # Create model - IMPORTANT: Add normalize_images=False for pre-normalized images\n    model = PPO(\n        \"CnnPolicy\",\n        env,\n        learning_rate=params[\"learning_rate\"],\n        n_steps=params[\"n_steps\"],\n        batch_size=params[\"batch_size\"],\n        n_epochs=4,\n        gamma=params[\"gamma\"],\n        clip_range=params[\"clip_range\"],\n        ent_coef=0.01,\n        verbose=0,\n        policy_kwargs={\"normalize_images\": False}  # ADD THIS LINE\n    )\n    \n    # Train for shorter duration for tuning\n    model.learn(total_timesteps=200000)\n    \n    # Evaluate\n    eval_env = create_single_agent_env(n_envs=1)\n    mean_reward, std_reward = evaluate_policy(\n        model, \n        eval_env, \n        n_eval_episodes=10,\n        deterministic=True\n    )\n    \n    print(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n    \n    env.close()\n    eval_env.close()\n    \n    return mean_reward, params\n\n# Run hyperparameter tuning\nresults = []\nfor i, params in enumerate(param_grid):\n    reward, best_params = tune_parameters(params, f\"Trial_{i+1}\")\n    results.append((reward, best_params))\n\n# Select best parameters\nbest_reward, best_params = max(results, key=lambda x: x[0])\nprint(f\"\\nBest parameters: {best_params}\")\nprint(f\"Best reward: {best_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:40:20.210178Z","iopub.execute_input":"2025-12-12T02:40:20.210806Z","iopub.status.idle":"2025-12-12T03:06:25.044413Z","shell.execute_reply.started":"2025-12-12T02:40:20.210785Z","shell.execute_reply":"2025-12-12T03:06:25.043634Z"}},"outputs":[{"name":"stdout","text":"\nTrial: Trial_1\nParameters: {'learning_rate': 0.00025, 'n_steps': 2048, 'batch_size': 64, 'gamma': 0.99, 'clip_range': 0.2}\nMean reward: -10.20 ± 3.43\n\nTrial: Trial_2\nParameters: {'learning_rate': 0.001, 'n_steps': 1024, 'batch_size': 128, 'gamma': 0.95, 'clip_range': 0.1}\nMean reward: -15.40 ± 2.46\n\nTrial: Trial_3\nParameters: {'learning_rate': 0.0005, 'n_steps': 1024, 'batch_size': 256, 'gamma': 0.99, 'clip_range': 0.3}\nMean reward: -17.40 ± 2.58\n\nBest parameters: {'learning_rate': 0.00025, 'n_steps': 2048, 'batch_size': 64, 'gamma': 0.99, 'clip_range': 0.2}\nBest reward: -10.20\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"best_params = {\n        \"learning_rate\": 2.5e-4,\n        \"n_steps\": 2048,\n        \"batch_size\": 64,\n        \"gamma\": 0.99,\n        \"clip_range\": 0.2,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:45:54.710235Z","iopub.execute_input":"2025-12-12T13:45:54.711116Z","iopub.status.idle":"2025-12-12T13:45:54.715755Z","shell.execute_reply.started":"2025-12-12T13:45:54.711090Z","shell.execute_reply":"2025-12-12T13:45:54.714879Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize wandb\nwandb.init(\n    project=\"pml-pong-tournament\",\n    config=best_params,\n    name=\"ppo-pong-final\",\n    sync_tensorboard=False,\n    save_code=False,\n    mode=\"disabled\"\n)\n\n# Create final training environment\nfinal_env = create_single_agent_env(n_envs=8)\n\n# Create PPO model with best parameters - ADD normalize_images=False\nmodel = PPO(\n    \"CnnPolicy\",\n    final_env,\n    learning_rate=best_params[\"learning_rate\"],\n    n_steps=best_params[\"n_steps\"],\n    batch_size=best_params[\"batch_size\"],\n    n_epochs=4,\n    gamma=best_params[\"gamma\"],\n    clip_range=best_params[\"clip_range\"],\n    ent_coef=0.01,\n    verbose=1,\n    tensorboard_log=\"runs/ppo_pong\",\n    policy_kwargs={\"normalize_images\": False}  # ADD THIS\n)\n\n# Create evaluation callback\neval_env = create_single_agent_env(n_envs=1)\neval_callback = EvalCallback(\n    eval_env,\n    best_model_save_path=\"./models/best/\",\n    log_path=\"./logs/\",\n    eval_freq=10000,\n    deterministic=True,\n)\n\n# Train\nprint(\"Starting final training...\")\nmodel.learn(\n    total_timesteps=1500000,\n    callback=[eval_callback],\n    progress_bar=True,\n    tb_log_name=\"ppo_final\"\n)\n\n# Final evaluation\nmean_reward, std_reward = evaluate_policy(\n    model,\n    eval_env,\n    n_eval_episodes=20,\n    deterministic=True\n)\n\nprint(f\"\\nFinal single-player performance:\")\nprint(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\nprint(f\"Win rate: {(mean_reward + 21) / 42 * 100:.1f}%\")\n\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:46:15.387547Z","iopub.execute_input":"2025-12-12T13:46:15.388423Z","iopub.status.idle":"2025-12-12T14:48:38.034188Z","shell.execute_reply.started":"2025-12-12T13:46:15.388396Z","shell.execute_reply":"2025-12-12T14:48:38.033349Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/notebook/notebookapp.py:188: DeprecationWarning: invalid escape sequence '\\/'\n  print(\"\"\"\n/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n  return LooseVersion(v) >= LooseVersion(check)\n/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_pydrive.py:21: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n  import imp  # pylint: disable=deprecated-module\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py:202: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n  settings = self._wl.settings.copy()\n","output_type":"stream"},{"name":"stdout","text":"Using cuda device\nStarting final training...\nLogging to runs/ppo_pong/ppo_final_1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e9d16f4747440584937ac1c431c090"}},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 924      |\n|    ep_rew_mean     | -20.3    |\n| time/              |          |\n|    fps             | 655      |\n|    iterations      | 1        |\n|    time_elapsed    | 24       |\n|    total_timesteps | 16384    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 930         |\n|    ep_rew_mean          | -20.2       |\n| time/                   |             |\n|    fps                  | 574         |\n|    iterations           | 2           |\n|    time_elapsed         | 57          |\n|    total_timesteps      | 32768       |\n| train/                  |             |\n|    approx_kl            | 0.005244785 |\n|    clip_fraction        | 0.0112      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.79       |\n|    explained_variance   | 0.00403     |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.00768    |\n|    n_updates            | 4           |\n|    policy_gradient_loss | -0.000956   |\n|    value_loss           | 0.053       |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 941          |\n|    ep_rew_mean          | -20.2        |\n| time/                   |              |\n|    fps                  | 555          |\n|    iterations           | 3            |\n|    time_elapsed         | 88           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0062501254 |\n|    clip_fraction        | 0.0391       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.79        |\n|    explained_variance   | 0.562        |\n|    learning_rate        | 0.00025      |\n|    loss                 | -0.00337     |\n|    n_updates            | 8            |\n|    policy_gradient_loss | -0.00422     |\n|    value_loss           | 0.0537       |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 968         |\n|    ep_rew_mean          | -20.1       |\n| time/                   |             |\n|    fps                  | 545         |\n|    iterations           | 4           |\n|    time_elapsed         | 120         |\n|    total_timesteps      | 65536       |\n| train/                  |             |\n|    approx_kl            | 0.007935136 |\n|    clip_fraction        | 0.0692      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.78       |\n|    explained_variance   | 0.522       |\n|    learning_rate        | 0.00025     |\n|    loss                 | 0.00226     |\n|    n_updates            | 12          |\n|    policy_gradient_loss | -0.00778    |\n|    value_loss           | 0.0693      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=80000, episode_reward=-17.80 +/- 2.14\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=-17.80 +/- 2.14\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 1617.80 +/- 319.18\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1617.80 +/- 319.18\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 1.62e+03    |\n|    mean_reward          | -17.8       |\n| time/                   |             |\n|    total_timesteps      | 80000       |\n| train/                  |             |\n|    approx_kl            | 0.008790458 |\n|    clip_fraction        | 0.0804      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.77       |\n|    explained_variance   | 0.522       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.00333    |\n|    n_updates            | 16          |\n|    policy_gradient_loss | -0.0111     |\n|    value_loss           | 0.0682      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 986      |\n|    ep_rew_mean     | -20      |\n| time/              |          |\n|    fps             | 483      |\n|    iterations      | 5        |\n|    time_elapsed    | 169      |\n|    total_timesteps | 81920    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.01e+03    |\n|    ep_rew_mean          | -19.9       |\n| time/                   |             |\n|    fps                  | 488         |\n|    iterations           | 6           |\n|    time_elapsed         | 201         |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.009906276 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.76       |\n|    explained_variance   | 0.526       |\n|    learning_rate        | 0.00025     |\n|    loss                 | 0.0116      |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0148     |\n|    value_loss           | 0.0712      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.06e+03    |\n|    ep_rew_mean          | -19.7       |\n| time/                   |             |\n|    fps                  | 494         |\n|    iterations           | 7           |\n|    time_elapsed         | 232         |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.010091908 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.75       |\n|    explained_variance   | 0.495       |\n|    learning_rate        | 0.00025     |\n|    loss                 | 0.0156      |\n|    n_updates            | 24          |\n|    policy_gradient_loss | -0.0149     |\n|    value_loss           | 0.085       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.11e+03    |\n|    ep_rew_mean          | -19.5       |\n| time/                   |             |\n|    fps                  | 497         |\n|    iterations           | 8           |\n|    time_elapsed         | 263         |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.011509385 |\n|    clip_fraction        | 0.123       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.73       |\n|    explained_variance   | 0.404       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0145     |\n|    n_updates            | 28          |\n|    policy_gradient_loss | -0.0186     |\n|    value_loss           | 0.0799      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.17e+03    |\n|    ep_rew_mean          | -19.2       |\n| time/                   |             |\n|    fps                  | 499         |\n|    iterations           | 9           |\n|    time_elapsed         | 294         |\n|    total_timesteps      | 147456      |\n| train/                  |             |\n|    approx_kl            | 0.012381489 |\n|    clip_fraction        | 0.139       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.71       |\n|    explained_variance   | 0.442       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0369     |\n|    n_updates            | 32          |\n|    policy_gradient_loss | -0.0213     |\n|    value_loss           | 0.0774      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=160000, episode_reward=-15.80 +/- 2.71\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=160000, episode_reward=-15.80 +/- 2.71\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 2169.20 +/- 238.63\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2169.20 +/- 238.63\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.17e+03    |\n|    mean_reward          | -15.8       |\n| time/                   |             |\n|    total_timesteps      | 160000      |\n| train/                  |             |\n|    approx_kl            | 0.013568306 |\n|    clip_fraction        | 0.153       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.441       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0158     |\n|    n_updates            | 36          |\n|    policy_gradient_loss | -0.0228     |\n|    value_loss           | 0.0745      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 1.24e+03 |\n|    ep_rew_mean     | -19      |\n| time/              |          |\n|    fps             | 467      |\n|    iterations      | 10       |\n|    time_elapsed    | 350      |\n|    total_timesteps | 163840   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.31e+03    |\n|    ep_rew_mean          | -18.7       |\n| time/                   |             |\n|    fps                  | 472         |\n|    iterations           | 11          |\n|    time_elapsed         | 381         |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.015617988 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.504       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0288     |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0257     |\n|    value_loss           | 0.0683      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.39e+03    |\n|    ep_rew_mean          | -18.5       |\n| time/                   |             |\n|    fps                  | 476         |\n|    iterations           | 12          |\n|    time_elapsed         | 412         |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.017341334 |\n|    clip_fraction        | 0.194       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.66       |\n|    explained_variance   | 0.47        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0318     |\n|    n_updates            | 44          |\n|    policy_gradient_loss | -0.0276     |\n|    value_loss           | 0.0678      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.45e+03    |\n|    ep_rew_mean          | -18.2       |\n| time/                   |             |\n|    fps                  | 479         |\n|    iterations           | 13          |\n|    time_elapsed         | 444         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.018868841 |\n|    clip_fraction        | 0.208       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.473       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0427     |\n|    n_updates            | 48          |\n|    policy_gradient_loss | -0.0298     |\n|    value_loss           | 0.064       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.54e+03    |\n|    ep_rew_mean          | -17.8       |\n| time/                   |             |\n|    fps                  | 482         |\n|    iterations           | 14          |\n|    time_elapsed         | 475         |\n|    total_timesteps      | 229376      |\n| train/                  |             |\n|    approx_kl            | 0.018786417 |\n|    clip_fraction        | 0.212       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.62       |\n|    explained_variance   | 0.477       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0248     |\n|    n_updates            | 52          |\n|    policy_gradient_loss | -0.0293     |\n|    value_loss           | 0.0691      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=240000, episode_reward=-13.80 +/- 2.04\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=240000, episode_reward=-13.80 +/- 2.04\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 2697.80 +/- 291.31\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2697.80 +/- 291.31\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 2.7e+03    |\n|    mean_reward          | -13.8      |\n| time/                   |            |\n|    total_timesteps      | 240000     |\n| train/                  |            |\n|    approx_kl            | 0.01904076 |\n|    clip_fraction        | 0.217      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.61      |\n|    explained_variance   | 0.508      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0482    |\n|    n_updates            | 56         |\n|    policy_gradient_loss | -0.0309    |\n|    value_loss           | 0.0621     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 1.6e+03  |\n|    ep_rew_mean     | -17.6    |\n| time/              |          |\n|    fps             | 458      |\n|    iterations      | 15       |\n|    time_elapsed    | 535      |\n|    total_timesteps | 245760   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.67e+03    |\n|    ep_rew_mean          | -17.4       |\n| time/                   |             |\n|    fps                  | 462         |\n|    iterations           | 16          |\n|    time_elapsed         | 567         |\n|    total_timesteps      | 262144      |\n| train/                  |             |\n|    approx_kl            | 0.021809539 |\n|    clip_fraction        | 0.231       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.59       |\n|    explained_variance   | 0.539       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0498     |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.0318     |\n|    value_loss           | 0.0619      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.75e+03    |\n|    ep_rew_mean          | -17.1       |\n| time/                   |             |\n|    fps                  | 465         |\n|    iterations           | 17          |\n|    time_elapsed         | 598         |\n|    total_timesteps      | 278528      |\n| train/                  |             |\n|    approx_kl            | 0.023264248 |\n|    clip_fraction        | 0.258       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.57       |\n|    explained_variance   | 0.515       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.056      |\n|    n_updates            | 64          |\n|    policy_gradient_loss | -0.0328     |\n|    value_loss           | 0.0581      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.79e+03    |\n|    ep_rew_mean          | -17         |\n| time/                   |             |\n|    fps                  | 468         |\n|    iterations           | 18          |\n|    time_elapsed         | 629         |\n|    total_timesteps      | 294912      |\n| train/                  |             |\n|    approx_kl            | 0.024281397 |\n|    clip_fraction        | 0.251       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.56       |\n|    explained_variance   | 0.517       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.065      |\n|    n_updates            | 68          |\n|    policy_gradient_loss | -0.0342     |\n|    value_loss           | 0.0597      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 1.88e+03   |\n|    ep_rew_mean          | -16.6      |\n| time/                   |            |\n|    fps                  | 471        |\n|    iterations           | 19         |\n|    time_elapsed         | 660        |\n|    total_timesteps      | 311296     |\n| train/                  |            |\n|    approx_kl            | 0.02545258 |\n|    clip_fraction        | 0.261      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.55      |\n|    explained_variance   | 0.479      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0646    |\n|    n_updates            | 72         |\n|    policy_gradient_loss | -0.0355    |\n|    value_loss           | 0.0588     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=320000, episode_reward=-13.60 +/- 1.36\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=320000, episode_reward=-13.60 +/- 1.36\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3069.80 +/- 355.69\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3069.80 +/- 355.69\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.07e+03    |\n|    mean_reward          | -13.6       |\n| time/                   |             |\n|    total_timesteps      | 320000      |\n| train/                  |             |\n|    approx_kl            | 0.024500465 |\n|    clip_fraction        | 0.255       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.55       |\n|    explained_variance   | 0.458       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0377     |\n|    n_updates            | 76          |\n|    policy_gradient_loss | -0.0354     |\n|    value_loss           | 0.057       |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 1.95e+03 |\n|    ep_rew_mean     | -16.4    |\n| time/              |          |\n|    fps             | 451      |\n|    iterations      | 20       |\n|    time_elapsed    | 725      |\n|    total_timesteps | 327680   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.99e+03    |\n|    ep_rew_mean          | -16.3       |\n| time/                   |             |\n|    fps                  | 455         |\n|    iterations           | 21          |\n|    time_elapsed         | 756         |\n|    total_timesteps      | 344064      |\n| train/                  |             |\n|    approx_kl            | 0.027236002 |\n|    clip_fraction        | 0.266       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.54       |\n|    explained_variance   | 0.483       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0605     |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.0367     |\n|    value_loss           | 0.0583      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.06e+03    |\n|    ep_rew_mean          | -16         |\n| time/                   |             |\n|    fps                  | 458         |\n|    iterations           | 22          |\n|    time_elapsed         | 786         |\n|    total_timesteps      | 360448      |\n| train/                  |             |\n|    approx_kl            | 0.027615149 |\n|    clip_fraction        | 0.274       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.49        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0648     |\n|    n_updates            | 84          |\n|    policy_gradient_loss | -0.0374     |\n|    value_loss           | 0.0616      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.11e+03    |\n|    ep_rew_mean          | -15.9       |\n| time/                   |             |\n|    fps                  | 460         |\n|    iterations           | 23          |\n|    time_elapsed         | 817         |\n|    total_timesteps      | 376832      |\n| train/                  |             |\n|    approx_kl            | 0.028334685 |\n|    clip_fraction        | 0.278       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.435       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0533     |\n|    n_updates            | 88          |\n|    policy_gradient_loss | -0.0396     |\n|    value_loss           | 0.0603      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.17e+03    |\n|    ep_rew_mean          | -15.6       |\n| time/                   |             |\n|    fps                  | 463         |\n|    iterations           | 24          |\n|    time_elapsed         | 849         |\n|    total_timesteps      | 393216      |\n| train/                  |             |\n|    approx_kl            | 0.029300714 |\n|    clip_fraction        | 0.282       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.5        |\n|    explained_variance   | 0.497       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.054      |\n|    n_updates            | 92          |\n|    policy_gradient_loss | -0.0375     |\n|    value_loss           | 0.0558      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=400000, episode_reward=-7.20 +/- 2.48\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=400000, episode_reward=-7.20 +/- 2.48\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3680.00 +/- 227.44\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3680.00 +/- 227.44\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.68e+03   |\n|    mean_reward          | -7.2       |\n| time/                   |            |\n|    total_timesteps      | 400000     |\n| train/                  |            |\n|    approx_kl            | 0.03025235 |\n|    clip_fraction        | 0.285      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.5       |\n|    explained_variance   | 0.439      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0468    |\n|    n_updates            | 96         |\n|    policy_gradient_loss | -0.0408    |\n|    value_loss           | 0.0597     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.24e+03 |\n|    ep_rew_mean     | -15.3    |\n| time/              |          |\n|    fps             | 445      |\n|    iterations      | 25       |\n|    time_elapsed    | 919      |\n|    total_timesteps | 409600   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.29e+03    |\n|    ep_rew_mean          | -15         |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 26          |\n|    time_elapsed         | 951         |\n|    total_timesteps      | 425984      |\n| train/                  |             |\n|    approx_kl            | 0.033062547 |\n|    clip_fraction        | 0.293       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.46       |\n|    explained_variance   | 0.522       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0669     |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.0398     |\n|    value_loss           | 0.0563      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.31e+03    |\n|    ep_rew_mean          | -14.9       |\n| time/                   |             |\n|    fps                  | 450         |\n|    iterations           | 27          |\n|    time_elapsed         | 981         |\n|    total_timesteps      | 442368      |\n| train/                  |             |\n|    approx_kl            | 0.033224963 |\n|    clip_fraction        | 0.301       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.44       |\n|    explained_variance   | 0.563       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0374     |\n|    n_updates            | 104         |\n|    policy_gradient_loss | -0.0392     |\n|    value_loss           | 0.0561      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 2.37e+03   |\n|    ep_rew_mean          | -14.7      |\n| time/                   |            |\n|    fps                  | 453        |\n|    iterations           | 28         |\n|    time_elapsed         | 1012       |\n|    total_timesteps      | 458752     |\n| train/                  |            |\n|    approx_kl            | 0.03476198 |\n|    clip_fraction        | 0.31       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.43      |\n|    explained_variance   | 0.509      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0771    |\n|    n_updates            | 108        |\n|    policy_gradient_loss | -0.0404    |\n|    value_loss           | 0.0543     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.41e+03    |\n|    ep_rew_mean          | -14.6       |\n| time/                   |             |\n|    fps                  | 455         |\n|    iterations           | 29          |\n|    time_elapsed         | 1043        |\n|    total_timesteps      | 475136      |\n| train/                  |             |\n|    approx_kl            | 0.036931463 |\n|    clip_fraction        | 0.316       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.55        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.04       |\n|    n_updates            | 112         |\n|    policy_gradient_loss | -0.0412     |\n|    value_loss           | 0.0529      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=480000, episode_reward=-8.20 +/- 3.19\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=480000, episode_reward=-8.20 +/- 3.19\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3782.00 +/- 766.56\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3782.00 +/- 766.56\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.78e+03    |\n|    mean_reward          | -8.2        |\n| time/                   |             |\n|    total_timesteps      | 480000      |\n| train/                  |             |\n|    approx_kl            | 0.038228832 |\n|    clip_fraction        | 0.32        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.436       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0881     |\n|    n_updates            | 116         |\n|    policy_gradient_loss | -0.0432     |\n|    value_loss           | 0.0524      |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.48e+03 |\n|    ep_rew_mean     | -14.3    |\n| time/              |          |\n|    fps             | 440      |\n|    iterations      | 30       |\n|    time_elapsed    | 1115     |\n|    total_timesteps | 491520   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.55e+03    |\n|    ep_rew_mean          | -14         |\n| time/                   |             |\n|    fps                  | 442         |\n|    iterations           | 31          |\n|    time_elapsed         | 1147        |\n|    total_timesteps      | 507904      |\n| train/                  |             |\n|    approx_kl            | 0.039299265 |\n|    clip_fraction        | 0.318       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.513       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0701     |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.0439     |\n|    value_loss           | 0.0573      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.61e+03    |\n|    ep_rew_mean          | -13.7       |\n| time/                   |             |\n|    fps                  | 445         |\n|    iterations           | 32          |\n|    time_elapsed         | 1177        |\n|    total_timesteps      | 524288      |\n| train/                  |             |\n|    approx_kl            | 0.038711935 |\n|    clip_fraction        | 0.32        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.532       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0467     |\n|    n_updates            | 124         |\n|    policy_gradient_loss | -0.0418     |\n|    value_loss           | 0.0572      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 2.67e+03   |\n|    ep_rew_mean          | -13.5      |\n| time/                   |            |\n|    fps                  | 447        |\n|    iterations           | 33         |\n|    time_elapsed         | 1209       |\n|    total_timesteps      | 540672     |\n| train/                  |            |\n|    approx_kl            | 0.03906715 |\n|    clip_fraction        | 0.323      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.41      |\n|    explained_variance   | 0.517      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.068     |\n|    n_updates            | 128        |\n|    policy_gradient_loss | -0.0444    |\n|    value_loss           | 0.0503     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.7e+03     |\n|    ep_rew_mean          | -13.4       |\n| time/                   |             |\n|    fps                  | 449         |\n|    iterations           | 34          |\n|    time_elapsed         | 1240        |\n|    total_timesteps      | 557056      |\n| train/                  |             |\n|    approx_kl            | 0.040259466 |\n|    clip_fraction        | 0.323       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.533       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0716     |\n|    n_updates            | 132         |\n|    policy_gradient_loss | -0.0437     |\n|    value_loss           | 0.0523      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=560000, episode_reward=-8.80 +/- 2.32\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=560000, episode_reward=-8.80 +/- 2.32\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4027.60 +/- 222.09\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4027.60 +/- 222.09\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4.03e+03   |\n|    mean_reward          | -8.8       |\n| time/                   |            |\n|    total_timesteps      | 560000     |\n| train/                  |            |\n|    approx_kl            | 0.04198306 |\n|    clip_fraction        | 0.327      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.4       |\n|    explained_variance   | 0.514      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.056     |\n|    n_updates            | 136        |\n|    policy_gradient_loss | -0.0449    |\n|    value_loss           | 0.0573     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.78e+03 |\n|    ep_rew_mean     | -12.9    |\n| time/              |          |\n|    fps             | 435      |\n|    iterations      | 35       |\n|    time_elapsed    | 1315     |\n|    total_timesteps | 573440   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.78e+03    |\n|    ep_rew_mean          | -12.8       |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 36          |\n|    time_elapsed         | 1346        |\n|    total_timesteps      | 589824      |\n| train/                  |             |\n|    approx_kl            | 0.043406956 |\n|    clip_fraction        | 0.336       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.57        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0545     |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.0462     |\n|    value_loss           | 0.0546      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 2.85e+03   |\n|    ep_rew_mean          | -12.4      |\n| time/                   |            |\n|    fps                  | 440        |\n|    iterations           | 37         |\n|    time_elapsed         | 1377       |\n|    total_timesteps      | 606208     |\n| train/                  |            |\n|    approx_kl            | 0.04391153 |\n|    clip_fraction        | 0.328      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.566      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0893    |\n|    n_updates            | 144        |\n|    policy_gradient_loss | -0.0449    |\n|    value_loss           | 0.0585     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 2.9e+03    |\n|    ep_rew_mean          | -12        |\n| time/                   |            |\n|    fps                  | 441        |\n|    iterations           | 38         |\n|    time_elapsed         | 1409       |\n|    total_timesteps      | 622592     |\n| train/                  |            |\n|    approx_kl            | 0.04624012 |\n|    clip_fraction        | 0.345      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.518      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0361    |\n|    n_updates            | 148        |\n|    policy_gradient_loss | -0.0485    |\n|    value_loss           | 0.0533     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 2.94e+03   |\n|    ep_rew_mean          | -11.8      |\n| time/                   |            |\n|    fps                  | 443        |\n|    iterations           | 39         |\n|    time_elapsed         | 1440       |\n|    total_timesteps      | 638976     |\n| train/                  |            |\n|    approx_kl            | 0.04554232 |\n|    clip_fraction        | 0.336      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.39      |\n|    explained_variance   | 0.499      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0915    |\n|    n_updates            | 152        |\n|    policy_gradient_loss | -0.0501    |\n|    value_loss           | 0.0503     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=640000, episode_reward=-4.80 +/- 4.40\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=640000, episode_reward=-4.80 +/- 4.40\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3582.40 +/- 249.12\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3582.40 +/- 249.12\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 3.58e+03  |\n|    mean_reward          | -4.8      |\n| time/                   |           |\n|    total_timesteps      | 640000    |\n| train/                  |           |\n|    approx_kl            | 0.0466209 |\n|    clip_fraction        | 0.343     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.36     |\n|    explained_variance   | 0.522     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0578   |\n|    n_updates            | 156       |\n|    policy_gradient_loss | -0.0476   |\n|    value_loss           | 0.0541    |\n---------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.98e+03 |\n|    ep_rew_mean     | -11.6    |\n| time/              |          |\n|    fps             | 433      |\n|    iterations      | 40       |\n|    time_elapsed    | 1510     |\n|    total_timesteps | 655360   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.04e+03    |\n|    ep_rew_mean          | -11.2       |\n| time/                   |             |\n|    fps                  | 435         |\n|    iterations           | 41          |\n|    time_elapsed         | 1541        |\n|    total_timesteps      | 671744      |\n| train/                  |             |\n|    approx_kl            | 0.049638275 |\n|    clip_fraction        | 0.341       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | 0.544       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0703     |\n|    n_updates            | 160         |\n|    policy_gradient_loss | -0.0464     |\n|    value_loss           | 0.0539      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.05e+03    |\n|    ep_rew_mean          | -11.1       |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 42          |\n|    time_elapsed         | 1572        |\n|    total_timesteps      | 688128      |\n| train/                  |             |\n|    approx_kl            | 0.048605934 |\n|    clip_fraction        | 0.351       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.589       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0658     |\n|    n_updates            | 164         |\n|    policy_gradient_loss | -0.0464     |\n|    value_loss           | 0.0523      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.1e+03     |\n|    ep_rew_mean          | -10.5       |\n| time/                   |             |\n|    fps                  | 439         |\n|    iterations           | 43          |\n|    time_elapsed         | 1604        |\n|    total_timesteps      | 704512      |\n| train/                  |             |\n|    approx_kl            | 0.051348206 |\n|    clip_fraction        | 0.345       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | 0.577       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0478     |\n|    n_updates            | 168         |\n|    policy_gradient_loss | -0.0458     |\n|    value_loss           | 0.0553      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=720000, episode_reward=0.60 +/- 3.93\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=720000, episode_reward=0.60 +/- 3.93\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3800.80 +/- 227.18\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3800.80 +/- 227.18\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.8e+03     |\n|    mean_reward          | 0.6         |\n| time/                   |             |\n|    total_timesteps      | 720000      |\n| train/                  |             |\n|    approx_kl            | 0.051307425 |\n|    clip_fraction        | 0.354       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.628       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0646     |\n|    n_updates            | 172         |\n|    policy_gradient_loss | -0.0456     |\n|    value_loss           | 0.0544      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.11e+03 |\n|    ep_rew_mean     | -10.4    |\n| time/              |          |\n|    fps             | 429      |\n|    iterations      | 44       |\n|    time_elapsed    | 1676     |\n|    total_timesteps | 720896   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.13e+03    |\n|    ep_rew_mean          | -10.1       |\n| time/                   |             |\n|    fps                  | 431         |\n|    iterations           | 45          |\n|    time_elapsed         | 1707        |\n|    total_timesteps      | 737280      |\n| train/                  |             |\n|    approx_kl            | 0.050916016 |\n|    clip_fraction        | 0.347       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.28       |\n|    explained_variance   | 0.647       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0587     |\n|    n_updates            | 176         |\n|    policy_gradient_loss | -0.0428     |\n|    value_loss           | 0.0554      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.16e+03    |\n|    ep_rew_mean          | -9.75       |\n| time/                   |             |\n|    fps                  | 433         |\n|    iterations           | 46          |\n|    time_elapsed         | 1738        |\n|    total_timesteps      | 753664      |\n| train/                  |             |\n|    approx_kl            | 0.054841038 |\n|    clip_fraction        | 0.354       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.28       |\n|    explained_variance   | 0.581       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0888     |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.0454     |\n|    value_loss           | 0.0562      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.18e+03   |\n|    ep_rew_mean          | -9.55      |\n| time/                   |            |\n|    fps                  | 434        |\n|    iterations           | 47         |\n|    time_elapsed         | 1770       |\n|    total_timesteps      | 770048     |\n| train/                  |            |\n|    approx_kl            | 0.05817882 |\n|    clip_fraction        | 0.357      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.27      |\n|    explained_variance   | 0.57       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0358    |\n|    n_updates            | 184        |\n|    policy_gradient_loss | -0.047     |\n|    value_loss           | 0.0588     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.21e+03    |\n|    ep_rew_mean          | -9.27       |\n| time/                   |             |\n|    fps                  | 436         |\n|    iterations           | 48          |\n|    time_elapsed         | 1802        |\n|    total_timesteps      | 786432      |\n| train/                  |             |\n|    approx_kl            | 0.054588877 |\n|    clip_fraction        | 0.355       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | 0.654       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0608     |\n|    n_updates            | 188         |\n|    policy_gradient_loss | -0.0433     |\n|    value_loss           | 0.0544      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=800000, episode_reward=-2.20 +/- 3.66\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=800000, episode_reward=-2.20 +/- 3.66\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4000.00 +/- 469.11\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4000.00 +/- 469.11\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4e+03      |\n|    mean_reward          | -2.2       |\n| time/                   |            |\n|    total_timesteps      | 800000     |\n| train/                  |            |\n|    approx_kl            | 0.05970619 |\n|    clip_fraction        | 0.354      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.24      |\n|    explained_variance   | 0.612      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0704    |\n|    n_updates            | 192        |\n|    policy_gradient_loss | -0.047     |\n|    value_loss           | 0.0528     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.22e+03 |\n|    ep_rew_mean     | -9.12    |\n| time/              |          |\n|    fps             | 427      |\n|    iterations      | 49       |\n|    time_elapsed    | 1876     |\n|    total_timesteps | 802816   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.23e+03    |\n|    ep_rew_mean          | -8.82       |\n| time/                   |             |\n|    fps                  | 429         |\n|    iterations           | 50          |\n|    time_elapsed         | 1907        |\n|    total_timesteps      | 819200      |\n| train/                  |             |\n|    approx_kl            | 0.059920657 |\n|    clip_fraction        | 0.359       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.576       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0696     |\n|    n_updates            | 196         |\n|    policy_gradient_loss | -0.0448     |\n|    value_loss           | 0.0521      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.26e+03    |\n|    ep_rew_mean          | -8.58       |\n| time/                   |             |\n|    fps                  | 430         |\n|    iterations           | 51          |\n|    time_elapsed         | 1939        |\n|    total_timesteps      | 835584      |\n| train/                  |             |\n|    approx_kl            | 0.061960228 |\n|    clip_fraction        | 0.359       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.597       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0787     |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.0457     |\n|    value_loss           | 0.053       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.27e+03   |\n|    ep_rew_mean          | -8.51      |\n| time/                   |            |\n|    fps                  | 432        |\n|    iterations           | 52         |\n|    time_elapsed         | 1970       |\n|    total_timesteps      | 851968     |\n| train/                  |            |\n|    approx_kl            | 0.06183557 |\n|    clip_fraction        | 0.353      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.22      |\n|    explained_variance   | 0.603      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0571    |\n|    n_updates            | 204        |\n|    policy_gradient_loss | -0.0443    |\n|    value_loss           | 0.0515     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.28e+03    |\n|    ep_rew_mean          | -8.14       |\n| time/                   |             |\n|    fps                  | 433         |\n|    iterations           | 53          |\n|    time_elapsed         | 2001        |\n|    total_timesteps      | 868352      |\n| train/                  |             |\n|    approx_kl            | 0.064447485 |\n|    clip_fraction        | 0.365       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | 0.623       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0612     |\n|    n_updates            | 208         |\n|    policy_gradient_loss | -0.0468     |\n|    value_loss           | 0.0529      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=880000, episode_reward=-0.80 +/- 4.12\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=880000, episode_reward=-0.80 +/- 4.12\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3404.00 +/- 157.98\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3404.00 +/- 157.98\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.4e+03     |\n|    mean_reward          | -0.8        |\n| time/                   |             |\n|    total_timesteps      | 880000      |\n| train/                  |             |\n|    approx_kl            | 0.057882603 |\n|    clip_fraction        | 0.352       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | 0.625       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0636     |\n|    n_updates            | 212         |\n|    policy_gradient_loss | -0.045      |\n|    value_loss           | 0.0557      |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.3e+03  |\n|    ep_rew_mean     | -7.74    |\n| time/              |          |\n|    fps             | 427      |\n|    iterations      | 54       |\n|    time_elapsed    | 2070     |\n|    total_timesteps | 884736   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.29e+03   |\n|    ep_rew_mean          | -7.56      |\n| time/                   |            |\n|    fps                  | 428        |\n|    iterations           | 55         |\n|    time_elapsed         | 2101       |\n|    total_timesteps      | 901120     |\n| train/                  |            |\n|    approx_kl            | 0.06178787 |\n|    clip_fraction        | 0.358      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.21      |\n|    explained_variance   | 0.594      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0746    |\n|    n_updates            | 216        |\n|    policy_gradient_loss | -0.0459    |\n|    value_loss           | 0.065      |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.31e+03   |\n|    ep_rew_mean          | -7.31      |\n| time/                   |            |\n|    fps                  | 430        |\n|    iterations           | 56         |\n|    time_elapsed         | 2133       |\n|    total_timesteps      | 917504     |\n| train/                  |            |\n|    approx_kl            | 0.06406678 |\n|    clip_fraction        | 0.361      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.2       |\n|    explained_variance   | 0.607      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0407    |\n|    n_updates            | 220        |\n|    policy_gradient_loss | -0.0464    |\n|    value_loss           | 0.0588     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.29e+03    |\n|    ep_rew_mean          | -7.34       |\n| time/                   |             |\n|    fps                  | 430         |\n|    iterations           | 57          |\n|    time_elapsed         | 2168        |\n|    total_timesteps      | 933888      |\n| train/                  |             |\n|    approx_kl            | 0.063667126 |\n|    clip_fraction        | 0.368       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.2        |\n|    explained_variance   | 0.601       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0613     |\n|    n_updates            | 224         |\n|    policy_gradient_loss | -0.0461     |\n|    value_loss           | 0.0579      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.3e+03    |\n|    ep_rew_mean          | -7.22      |\n| time/                   |            |\n|    fps                  | 431        |\n|    iterations           | 58         |\n|    time_elapsed         | 2201       |\n|    total_timesteps      | 950272     |\n| train/                  |            |\n|    approx_kl            | 0.06693305 |\n|    clip_fraction        | 0.363      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.19      |\n|    explained_variance   | 0.631      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0607    |\n|    n_updates            | 228        |\n|    policy_gradient_loss | -0.048     |\n|    value_loss           | 0.058      |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=960000, episode_reward=-0.40 +/- 4.18\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=960000, episode_reward=-0.40 +/- 4.18\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3867.40 +/- 198.32\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3867.40 +/- 198.32\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.87e+03   |\n|    mean_reward          | -0.4       |\n| time/                   |            |\n|    total_timesteps      | 960000     |\n| train/                  |            |\n|    approx_kl            | 0.06566869 |\n|    clip_fraction        | 0.36       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.19      |\n|    explained_variance   | 0.622      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0285    |\n|    n_updates            | 232        |\n|    policy_gradient_loss | -0.0447    |\n|    value_loss           | 0.0582     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.31e+03 |\n|    ep_rew_mean     | -6.88    |\n| time/              |          |\n|    fps             | 424      |\n|    iterations      | 59       |\n|    time_elapsed    | 2275     |\n|    total_timesteps | 966656   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.32e+03    |\n|    ep_rew_mean          | -6.78       |\n| time/                   |             |\n|    fps                  | 426         |\n|    iterations           | 60          |\n|    time_elapsed         | 2306        |\n|    total_timesteps      | 983040      |\n| train/                  |             |\n|    approx_kl            | 0.068784855 |\n|    clip_fraction        | 0.368       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.2        |\n|    explained_variance   | 0.595       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.065      |\n|    n_updates            | 236         |\n|    policy_gradient_loss | -0.0499     |\n|    value_loss           | 0.0538      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.35e+03   |\n|    ep_rew_mean          | -6.44      |\n| time/                   |            |\n|    fps                  | 427        |\n|    iterations           | 61         |\n|    time_elapsed         | 2338       |\n|    total_timesteps      | 999424     |\n| train/                  |            |\n|    approx_kl            | 0.06533186 |\n|    clip_fraction        | 0.359      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.2       |\n|    explained_variance   | 0.652      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0506    |\n|    n_updates            | 240        |\n|    policy_gradient_loss | -0.0475    |\n|    value_loss           | 0.0536     |\n----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 3.34e+03  |\n|    ep_rew_mean          | -6.34     |\n| time/                   |           |\n|    fps                  | 428       |\n|    iterations           | 62        |\n|    time_elapsed         | 2368      |\n|    total_timesteps      | 1015808   |\n| train/                  |           |\n|    approx_kl            | 0.0689959 |\n|    clip_fraction        | 0.366     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.19     |\n|    explained_variance   | 0.66      |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0612   |\n|    n_updates            | 244       |\n|    policy_gradient_loss | -0.0485   |\n|    value_loss           | 0.0502    |\n---------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.35e+03   |\n|    ep_rew_mean          | -6.16      |\n| time/                   |            |\n|    fps                  | 430        |\n|    iterations           | 63         |\n|    time_elapsed         | 2399       |\n|    total_timesteps      | 1032192    |\n| train/                  |            |\n|    approx_kl            | 0.06830033 |\n|    clip_fraction        | 0.364      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.18      |\n|    explained_variance   | 0.599      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0628    |\n|    n_updates            | 248        |\n|    policy_gradient_loss | -0.0478    |\n|    value_loss           | 0.0589     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1040000, episode_reward=2.40 +/- 4.22\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1040000, episode_reward=2.40 +/- 4.22\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4286.40 +/- 306.82\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4286.40 +/- 306.82\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4.29e+03   |\n|    mean_reward          | 2.4        |\n| time/                   |            |\n|    total_timesteps      | 1040000    |\n| train/                  |            |\n|    approx_kl            | 0.06774712 |\n|    clip_fraction        | 0.366      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.17      |\n|    explained_variance   | 0.632      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0424    |\n|    n_updates            | 252        |\n|    policy_gradient_loss | -0.0473    |\n|    value_loss           | 0.0551     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.36e+03 |\n|    ep_rew_mean     | -6.17    |\n| time/              |          |\n|    fps             | 423      |\n|    iterations      | 64       |\n|    time_elapsed    | 2477     |\n|    total_timesteps | 1048576  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.4e+03    |\n|    ep_rew_mean          | -5.84      |\n| time/                   |            |\n|    fps                  | 424        |\n|    iterations           | 65         |\n|    time_elapsed         | 2508       |\n|    total_timesteps      | 1064960    |\n| train/                  |            |\n|    approx_kl            | 0.07189326 |\n|    clip_fraction        | 0.375      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.17      |\n|    explained_variance   | 0.634      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0585    |\n|    n_updates            | 256        |\n|    policy_gradient_loss | -0.0473    |\n|    value_loss           | 0.0573     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.43e+03   |\n|    ep_rew_mean          | -5.45      |\n| time/                   |            |\n|    fps                  | 425        |\n|    iterations           | 66         |\n|    time_elapsed         | 2540       |\n|    total_timesteps      | 1081344    |\n| train/                  |            |\n|    approx_kl            | 0.07549776 |\n|    clip_fraction        | 0.372      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.15      |\n|    explained_variance   | 0.606      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0707    |\n|    n_updates            | 260        |\n|    policy_gradient_loss | -0.0474    |\n|    value_loss           | 0.053      |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.44e+03    |\n|    ep_rew_mean          | -5.37       |\n| time/                   |             |\n|    fps                  | 426         |\n|    iterations           | 67          |\n|    time_elapsed         | 2571        |\n|    total_timesteps      | 1097728     |\n| train/                  |             |\n|    approx_kl            | 0.073987946 |\n|    clip_fraction        | 0.369       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | 0.624       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0635     |\n|    n_updates            | 264         |\n|    policy_gradient_loss | -0.0468     |\n|    value_loss           | 0.0534      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.46e+03   |\n|    ep_rew_mean          | -5.08      |\n| time/                   |            |\n|    fps                  | 427        |\n|    iterations           | 68         |\n|    time_elapsed         | 2603       |\n|    total_timesteps      | 1114112    |\n| train/                  |            |\n|    approx_kl            | 0.07458916 |\n|    clip_fraction        | 0.369      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.13      |\n|    explained_variance   | 0.663      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0616    |\n|    n_updates            | 268        |\n|    policy_gradient_loss | -0.0453    |\n|    value_loss           | 0.0563     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1120000, episode_reward=7.20 +/- 1.47\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1120000, episode_reward=7.20 +/- 1.47\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3753.80 +/- 219.42\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3753.80 +/- 219.42\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.75e+03   |\n|    mean_reward          | 7.2        |\n| time/                   |            |\n|    total_timesteps      | 1120000    |\n| train/                  |            |\n|    approx_kl            | 0.07743374 |\n|    clip_fraction        | 0.372      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.639      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.107     |\n|    n_updates            | 272        |\n|    policy_gradient_loss | -0.0479    |\n|    value_loss           | 0.0549     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.47e+03 |\n|    ep_rew_mean     | -4.89    |\n| time/              |          |\n|    fps             | 422      |\n|    iterations      | 69       |\n|    time_elapsed    | 2675     |\n|    total_timesteps | 1130496  |\n---------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 3.5e+03   |\n|    ep_rew_mean          | -4.73     |\n| time/                   |           |\n|    fps                  | 423       |\n|    iterations           | 70        |\n|    time_elapsed         | 2707      |\n|    total_timesteps      | 1146880   |\n| train/                  |           |\n|    approx_kl            | 0.0762427 |\n|    clip_fraction        | 0.368     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.12     |\n|    explained_variance   | 0.607     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0602   |\n|    n_updates            | 276       |\n|    policy_gradient_loss | -0.0461   |\n|    value_loss           | 0.055     |\n---------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.51e+03   |\n|    ep_rew_mean          | -4.56      |\n| time/                   |            |\n|    fps                  | 424        |\n|    iterations           | 71         |\n|    time_elapsed         | 2738       |\n|    total_timesteps      | 1163264    |\n| train/                  |            |\n|    approx_kl            | 0.07968908 |\n|    clip_fraction        | 0.373      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.624      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0658    |\n|    n_updates            | 280        |\n|    policy_gradient_loss | -0.046     |\n|    value_loss           | 0.0562     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.52e+03   |\n|    ep_rew_mean          | -4.4       |\n| time/                   |            |\n|    fps                  | 425        |\n|    iterations           | 72         |\n|    time_elapsed         | 2770       |\n|    total_timesteps      | 1179648    |\n| train/                  |            |\n|    approx_kl            | 0.07542262 |\n|    clip_fraction        | 0.368      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.619      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0499    |\n|    n_updates            | 284        |\n|    policy_gradient_loss | -0.0465    |\n|    value_loss           | 0.059      |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.53e+03   |\n|    ep_rew_mean          | -3.98      |\n| time/                   |            |\n|    fps                  | 426        |\n|    iterations           | 73         |\n|    time_elapsed         | 2802       |\n|    total_timesteps      | 1196032    |\n| train/                  |            |\n|    approx_kl            | 0.07961108 |\n|    clip_fraction        | 0.367      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.09      |\n|    explained_variance   | 0.602      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0655    |\n|    n_updates            | 288        |\n|    policy_gradient_loss | -0.0458    |\n|    value_loss           | 0.0553     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1200000, episode_reward=4.80 +/- 5.15\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1200000, episode_reward=4.80 +/- 5.15\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3629.40 +/- 460.29\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3629.40 +/- 460.29\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.63e+03   |\n|    mean_reward          | 4.8        |\n| time/                   |            |\n|    total_timesteps      | 1200000    |\n| train/                  |            |\n|    approx_kl            | 0.07763674 |\n|    clip_fraction        | 0.369      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.1       |\n|    explained_variance   | 0.625      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0402    |\n|    n_updates            | 292        |\n|    policy_gradient_loss | -0.0476    |\n|    value_loss           | 0.0548     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.56e+03 |\n|    ep_rew_mean     | -3.82    |\n| time/              |          |\n|    fps             | 421      |\n|    iterations      | 74       |\n|    time_elapsed    | 2873     |\n|    total_timesteps | 1212416  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.55e+03   |\n|    ep_rew_mean          | -3.86      |\n| time/                   |            |\n|    fps                  | 422        |\n|    iterations           | 75         |\n|    time_elapsed         | 2905       |\n|    total_timesteps      | 1228800    |\n| train/                  |            |\n|    approx_kl            | 0.07597473 |\n|    clip_fraction        | 0.367      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.09      |\n|    explained_variance   | 0.632      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0812    |\n|    n_updates            | 296        |\n|    policy_gradient_loss | -0.044     |\n|    value_loss           | 0.0569     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.56e+03   |\n|    ep_rew_mean          | -3.75      |\n| time/                   |            |\n|    fps                  | 423        |\n|    iterations           | 76         |\n|    time_elapsed         | 2937       |\n|    total_timesteps      | 1245184    |\n| train/                  |            |\n|    approx_kl            | 0.07574594 |\n|    clip_fraction        | 0.366      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.665      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0717    |\n|    n_updates            | 300        |\n|    policy_gradient_loss | -0.0454    |\n|    value_loss           | 0.0571     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.57e+03    |\n|    ep_rew_mean          | -3.61       |\n| time/                   |             |\n|    fps                  | 424         |\n|    iterations           | 77          |\n|    time_elapsed         | 2968        |\n|    total_timesteps      | 1261568     |\n| train/                  |             |\n|    approx_kl            | 0.077426866 |\n|    clip_fraction        | 0.368       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.654       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0671     |\n|    n_updates            | 304         |\n|    policy_gradient_loss | -0.0464     |\n|    value_loss           | 0.0574      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.58e+03   |\n|    ep_rew_mean          | -3.52      |\n| time/                   |            |\n|    fps                  | 425        |\n|    iterations           | 78         |\n|    time_elapsed         | 3000       |\n|    total_timesteps      | 1277952    |\n| train/                  |            |\n|    approx_kl            | 0.08016868 |\n|    clip_fraction        | 0.377      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.12      |\n|    explained_variance   | 0.63       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0644    |\n|    n_updates            | 308        |\n|    policy_gradient_loss | -0.0491    |\n|    value_loss           | 0.0584     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1280000, episode_reward=0.20 +/- 4.71\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1280000, episode_reward=0.20 +/- 4.71\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3963.80 +/- 389.55\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3963.80 +/- 389.55\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.96e+03    |\n|    mean_reward          | 0.2         |\n| time/                   |             |\n|    total_timesteps      | 1280000     |\n| train/                  |             |\n|    approx_kl            | 0.088987075 |\n|    clip_fraction        | 0.381       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | 0.615       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.107      |\n|    n_updates            | 312         |\n|    policy_gradient_loss | -0.0496     |\n|    value_loss           | 0.0577      |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.58e+03 |\n|    ep_rew_mean     | -3.55    |\n| time/              |          |\n|    fps             | 420      |\n|    iterations      | 79       |\n|    time_elapsed    | 3074     |\n|    total_timesteps | 1294336  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.6e+03    |\n|    ep_rew_mean          | -3.26      |\n| time/                   |            |\n|    fps                  | 421        |\n|    iterations           | 80         |\n|    time_elapsed         | 3106       |\n|    total_timesteps      | 1310720    |\n| train/                  |            |\n|    approx_kl            | 0.08453786 |\n|    clip_fraction        | 0.382      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.09      |\n|    explained_variance   | 0.584      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0689    |\n|    n_updates            | 316        |\n|    policy_gradient_loss | -0.0503    |\n|    value_loss           | 0.0577     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.6e+03    |\n|    ep_rew_mean          | -3.26      |\n| time/                   |            |\n|    fps                  | 422        |\n|    iterations           | 81         |\n|    time_elapsed         | 3137       |\n|    total_timesteps      | 1327104    |\n| train/                  |            |\n|    approx_kl            | 0.08230361 |\n|    clip_fraction        | 0.38       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.599      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0571    |\n|    n_updates            | 320        |\n|    policy_gradient_loss | -0.0495    |\n|    value_loss           | 0.0601     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.58e+03    |\n|    ep_rew_mean          | -3.48       |\n| time/                   |             |\n|    fps                  | 423         |\n|    iterations           | 82          |\n|    time_elapsed         | 3169        |\n|    total_timesteps      | 1343488     |\n| train/                  |             |\n|    approx_kl            | 0.084196076 |\n|    clip_fraction        | 0.378       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.655       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0755     |\n|    n_updates            | 324         |\n|    policy_gradient_loss | -0.0482     |\n|    value_loss           | 0.0603      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.59e+03   |\n|    ep_rew_mean          | -3.29      |\n| time/                   |            |\n|    fps                  | 424        |\n|    iterations           | 83         |\n|    time_elapsed         | 3200       |\n|    total_timesteps      | 1359872    |\n| train/                  |            |\n|    approx_kl            | 0.08594806 |\n|    clip_fraction        | 0.375      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.08      |\n|    explained_variance   | 0.67       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0828    |\n|    n_updates            | 328        |\n|    policy_gradient_loss | -0.049     |\n|    value_loss           | 0.053      |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1360000, episode_reward=6.20 +/- 2.99\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1360000, episode_reward=6.20 +/- 2.99\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3711.20 +/- 349.13\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3711.20 +/- 349.13\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.71e+03   |\n|    mean_reward          | 6.2        |\n| time/                   |            |\n|    total_timesteps      | 1360000    |\n| train/                  |            |\n|    approx_kl            | 0.08504768 |\n|    clip_fraction        | 0.367      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.06      |\n|    explained_variance   | 0.674      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.106     |\n|    n_updates            | 332        |\n|    policy_gradient_loss | -0.0473    |\n|    value_loss           | 0.0549     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.61e+03 |\n|    ep_rew_mean     | -2.68    |\n| time/              |          |\n|    fps             | 420      |\n|    iterations      | 84       |\n|    time_elapsed    | 3272     |\n|    total_timesteps | 1376256  |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.62e+03    |\n|    ep_rew_mean          | -2.48       |\n| time/                   |             |\n|    fps                  | 421         |\n|    iterations           | 85          |\n|    time_elapsed         | 3303        |\n|    total_timesteps      | 1392640     |\n| train/                  |             |\n|    approx_kl            | 0.088844575 |\n|    clip_fraction        | 0.374       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 0.692       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0787     |\n|    n_updates            | 336         |\n|    policy_gradient_loss | -0.0479     |\n|    value_loss           | 0.0507      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.64e+03   |\n|    ep_rew_mean          | -2.29      |\n| time/                   |            |\n|    fps                  | 422        |\n|    iterations           | 86         |\n|    time_elapsed         | 3335       |\n|    total_timesteps      | 1409024    |\n| train/                  |            |\n|    approx_kl            | 0.08895618 |\n|    clip_fraction        | 0.373      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.06      |\n|    explained_variance   | 0.642      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0773    |\n|    n_updates            | 340        |\n|    policy_gradient_loss | -0.0486    |\n|    value_loss           | 0.0579     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.62e+03   |\n|    ep_rew_mean          | -2.36      |\n| time/                   |            |\n|    fps                  | 423        |\n|    iterations           | 87         |\n|    time_elapsed         | 3366       |\n|    total_timesteps      | 1425408    |\n| train/                  |            |\n|    approx_kl            | 0.09485498 |\n|    clip_fraction        | 0.376      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.05      |\n|    explained_variance   | 0.599      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0713    |\n|    n_updates            | 344        |\n|    policy_gradient_loss | -0.0485    |\n|    value_loss           | 0.0568     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1440000, episode_reward=3.00 +/- 3.03\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1440000, episode_reward=3.00 +/- 3.03\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3836.20 +/- 284.52\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3836.20 +/- 284.52\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 3.84e+03  |\n|    mean_reward          | 3         |\n| time/                   |           |\n|    total_timesteps      | 1440000   |\n| train/                  |           |\n|    approx_kl            | 0.0899919 |\n|    clip_fraction        | 0.389     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.09     |\n|    explained_variance   | 0.613     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0694   |\n|    n_updates            | 348       |\n|    policy_gradient_loss | -0.0506   |\n|    value_loss           | 0.0557    |\n---------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.62e+03 |\n|    ep_rew_mean     | -2.2     |\n| time/              |          |\n|    fps             | 419      |\n|    iterations      | 88       |\n|    time_elapsed    | 3439     |\n|    total_timesteps | 1441792  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.62e+03   |\n|    ep_rew_mean          | -2.53      |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 89         |\n|    time_elapsed         | 3470       |\n|    total_timesteps      | 1458176    |\n| train/                  |            |\n|    approx_kl            | 0.08989362 |\n|    clip_fraction        | 0.382      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.07      |\n|    explained_variance   | 0.646      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0925    |\n|    n_updates            | 352        |\n|    policy_gradient_loss | -0.0486    |\n|    value_loss           | 0.0517     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.62e+03   |\n|    ep_rew_mean          | -2.64      |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 90         |\n|    time_elapsed         | 3502       |\n|    total_timesteps      | 1474560    |\n| train/                  |            |\n|    approx_kl            | 0.09421677 |\n|    clip_fraction        | 0.385      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.06      |\n|    explained_variance   | 0.606      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0812    |\n|    n_updates            | 356        |\n|    policy_gradient_loss | -0.0494    |\n|    value_loss           | 0.0554     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.61e+03    |\n|    ep_rew_mean          | -2.69       |\n| time/                   |             |\n|    fps                  | 421         |\n|    iterations           | 91          |\n|    time_elapsed         | 3534        |\n|    total_timesteps      | 1490944     |\n| train/                  |             |\n|    approx_kl            | 0.096824095 |\n|    clip_fraction        | 0.38        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.654       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0706     |\n|    n_updates            | 360         |\n|    policy_gradient_loss | -0.0489     |\n|    value_loss           | 0.0536      |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 3.58e+03  |\n|    ep_rew_mean          | -2.73     |\n| time/                   |           |\n|    fps                  | 422       |\n|    iterations           | 92        |\n|    time_elapsed         | 3565      |\n|    total_timesteps      | 1507328   |\n| train/                  |           |\n|    approx_kl            | 0.0937615 |\n|    clip_fraction        | 0.383     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.04     |\n|    explained_variance   | 0.67      |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0704   |\n|    n_updates            | 364       |\n|    policy_gradient_loss | -0.0465   |\n|    value_loss           | 0.0577    |\n---------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"\nFinal single-player performance:\nMean reward: 7.60 ± 3.80\nWin rate: 68.1%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport supersuit as ss\nfrom pettingzoo.atari import pong_v3\nfrom stable_baselines3 import PPO\nimport imageio\nimport warnings\nimport os\nimport random\nimport logging\nimport sys\nimport importlib\n\nwarnings.filterwarnings('ignore')\n\n# --- CONFIGURATION ---\n# IMPORTANT: Update your group name here (e.g., 'G01', 'G02', etc.)\nGROUP_NAME = \"G03\" \n# Update this path to where your model is saved relative to the notebook/script\nMODEL_PATH = \"models/best/best_model.zip\" \n# ---\n\n# Helper function to create the environment (copied from your utils.py/wrappers.py)\ndef make_env(render_mode=\"rgb_array\"):\n    \"\"\"Creates the pre-processed Pong environment.\"\"\"\n    env = pong_v3.env(num_players=2, render_mode=render_mode)\n    # Apply the same SuperSuit wrappers as used in training/tournament setup\n    env = ss.sticky_actions_v0(env, repeat_action_probability=0.25)\n    env = ss.color_reduction_v0(env, mode=\"B\")\n    env = ss.resize_v1(env, x_size=84, y_size=84)\n    env = ss.frame_stack_v1(env, 4, stack_dim=0)\n    env = ss.dtype_v0(env, dtype=np.float32)\n    env = ss.normalize_obs_v0(env, env_min=0, env_max=1)\n    env = ss.reshape_v0(env, (4, 84, 84))\n    \n    # Resetting the environment with seed as done in the professor's setup\n    MAX_INT = int(10e6)\n    seed = random.randint(0, MAX_INT)\n    env.reset(seed=seed)\n    env.action_space(env.possible_agents[0]).seed(seed)\n    \n    return env\n\n# 1. Load Your Model\nprint(f\"Attempting to load PPO model from: {MODEL_PATH}\")\ntry:\n    trained_model = PPO.load(MODEL_PATH)\n    print(\"Model loaded successfully.\")\nexcept Exception as e:\n    print(f\"ERROR: Failed to load model. Check path and file integrity. Error: {e}\")\n    # Exit or use a dummy model if critical\n    # sys.exit(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T16:51:43.980529Z","iopub.execute_input":"2025-12-12T16:51:43.981240Z","iopub.status.idle":"2025-12-12T16:51:44.217833Z","shell.execute_reply.started":"2025-12-12T16:51:43.981206Z","shell.execute_reply":"2025-12-12T16:51:44.216996Z"}},"outputs":[{"name":"stdout","text":"Attempting to load PPO model from: models/best/best_model.zip\nModel loaded successfully.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class RandomAgent:\n    \"\"\"\n    A simple agent that chooses a random action.\n    It takes an observation but ignores it, matching the expected \n    interface for tournament agents (which often come from SB3/RLlib).\n    \"\"\"\n    def __init__(self, action_space):\n        self.action_space = action_space\n\n    def predict(self, observation, deterministic=True):\n        \"\"\"\n        Returns a random action. The 'deterministic' argument is ignored.\n        Returns: (action, None) to match SB3's .predict() signature.\n        \"\"\"\n        # .sample() gets a random action from the discrete action space\n        action = self.action_space.sample()\n        return action, None\n\n    # Dummy methods for compatibility with tournament runner if needed\n    def learn(self, *args, **kwargs):\n        pass\n\n    def save(self, *args, **kwargs):\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T16:52:27.409407Z","iopub.execute_input":"2025-12-12T16:52:27.409632Z","iopub.status.idle":"2025-12-12T16:52:27.414505Z","shell.execute_reply.started":"2025-12-12T16:52:27.409615Z","shell.execute_reply":"2025-12-12T16:52:27.413765Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def evaluate_agent(ppo_model, opponent_agent, n_episodes=20, video_path='pong_ppo_vs_random.mp4'):\n    \"\"\"\n    Evaluates the PPO model against a specified opponent agent.\n    PPO model plays first_0 (Right), Opponent plays second_0 (Left).\n    \"\"\"\n    env = make_env(render_mode=\"rgb_array\")\n    \n    total_rewards = {'first_0': 0, 'second_0': 0}\n    wins = {'first_0': 0, 'second_0': 0}\n    video_frames = []\n    \n    print(\"\\n--- Starting PPO Agent vs Random Agent Evaluation ---\")\n    print(f\"PPO Agent: Right Paddle ('first_0') | Opponent: Left Paddle ('second_0')\")\n\n    for episode in range(n_episodes):\n        env.reset()\n        episode_rewards = {'first_0': 0, 'second_0': 0}\n        \n        # PettingZoo Agent Iteration Loop\n        for agent in env.agent_iter():\n            observation, reward, termination, truncation, info = env.last()\n            \n            episode_rewards[agent] += reward\n            \n            if termination or truncation:\n                action = None\n            else:\n                if agent == 'first_0':\n                    # RIGHT PLAYER (Trained PPO Model)\n                    action, _ = ppo_model.predict(observation, deterministic=True)\n                elif agent == 'second_0':\n                    # LEFT PLAYER (Random Opponent)\n                    action, _ = opponent_agent.predict(observation, deterministic=True)\n                else:\n                    action = env.action_space(agent).sample() # Fallback random action\n            \n            env.step(action)\n            \n            # Capture frames for video (first episode only)\n            if episode == 0 and len(video_frames) < 1500: # Limit frames\n                frame = env.render()\n                if frame is not None:\n                    video_frames.append(frame)\n\n        # Tally results\n        right_score = episode_rewards['first_0']\n        left_score = episode_rewards['second_0']\n        \n        total_rewards['first_0'] += right_score\n        total_rewards['second_0'] += left_score\n        \n        if right_score > left_score:\n            wins['first_0'] += 1\n        elif left_score > right_score:\n            wins['second_0'] += 1\n\n        print(f\"Episode {episode + 1:02d}: PPO (Right)={right_score:.1f}, Random (Left)={left_score:.1f}\")\n\n    env.close()\n\n    # Report Results\n    print(\"\\n\" + \"=\"*40)\n    print(\"PPO Agent vs Random Agent RESULTS\")\n    print(\"=\"*40)\n    print(f\"Total PPO Agent (Right) wins: {wins['first_0']} / {n_episodes}\")\n    print(f\"Total Random Agent (Left) wins: {wins['second_0']} / {n_episodes}\")\n    print(f\"PPO Agent Win Rate: {(wins['first_0']/n_episodes * 100):.1f}%\")\n    print(f\"Avg PPO Agent Reward: {total_rewards['first_0']/n_episodes:.2f}\")\n    print(\"=\"*40)\n\n    # Save Video\n    if video_frames:\n        imageio.mimsave(video_path, video_frames, fps=30)\n        print(f\"Video saved as '{video_path}'\")\n    else:\n        print(\"No frames captured for video.\")\n        \n    return total_rewards\n\n# --- EXECUTE EVALUATION ---\n# Create an instance of the random opponent\nrandom_opponent = RandomAgent(env.action_space(env.possible_agents[0]))\n# Run the evaluation\nif 'trained_model' in locals():\n    # Evaluate PPO model vs Random Agent over 20 episodes\n    evaluate_agent(trained_model, random_opponent, n_episodes=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T16:53:08.021520Z","iopub.execute_input":"2025-12-12T16:53:08.022240Z","iopub.status.idle":"2025-12-12T16:58:03.094225Z","shell.execute_reply.started":"2025-12-12T16:53:08.022214Z","shell.execute_reply":"2025-12-12T16:58:03.093400Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting PPO Agent vs Random Agent Evaluation ---\nPPO Agent: Right Paddle ('first_0') | Opponent: Left Paddle ('second_0')\nEpisode 01: PPO (Right)=19.0, Random (Left)=-21.0\nEpisode 02: PPO (Right)=12.0, Random (Left)=-14.0\nEpisode 03: PPO (Right)=14.0, Random (Left)=-15.0\nEpisode 04: PPO (Right)=2.0, Random (Left)=-6.0\nEpisode 05: PPO (Right)=13.0, Random (Left)=-15.0\nEpisode 06: PPO (Right)=17.0, Random (Left)=-18.0\nEpisode 07: PPO (Right)=14.0, Random (Left)=-16.0\nEpisode 08: PPO (Right)=19.0, Random (Left)=-21.0\nEpisode 09: PPO (Right)=7.0, Random (Left)=-11.0\nEpisode 10: PPO (Right)=10.0, Random (Left)=-13.0\nEpisode 11: PPO (Right)=-15.0, Random (Left)=-5.0\nEpisode 12: PPO (Right)=8.0, Random (Left)=-14.0\nEpisode 13: PPO (Right)=16.0, Random (Left)=-17.0\nEpisode 14: PPO (Right)=6.0, Random (Left)=-11.0\nEpisode 15: PPO (Right)=13.0, Random (Left)=-17.0\nEpisode 16: PPO (Right)=1.0, Random (Left)=-4.0\nEpisode 17: PPO (Right)=7.0, Random (Left)=-12.0\nEpisode 18: PPO (Right)=18.0, Random (Left)=-19.0\nEpisode 19: PPO (Right)=20.0, Random (Left)=-20.0\n","output_type":"stream"},{"name":"stderr","text":"IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n","output_type":"stream"},{"name":"stdout","text":"Episode 20: PPO (Right)=9.0, Random (Left)=-12.0\n\n========================================\nPPO Agent vs Random Agent RESULTS\n========================================\nTotal PPO Agent (Right) wins: 19 / 20\nTotal Random Agent (Left) wins: 1 / 20\nPPO Agent Win Rate: 95.0%\nAvg PPO Agent Reward: 10.50\n========================================\nVideo saved as 'pong_ppo_vs_random.mp4'\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Testing the Agent\n\nYour agent will be tested, against other agents, in an environment similar to the following one:\n\n**Notes**:\n- It is important to consider that the agent will have to play on **both sides of the board**. That is, the agent must be able to play on the **right side** (by default in Gymnasium or Gym), but also on the **left side**.\n- You can provide a **single model** to play both sides or, alternatively, you can provide **two models**, one model for each side of the board.","metadata":{}},{"cell_type":"code","source":"import supersuit as ss\nfrom pettingzoo.atari import pong_v3\n\nenv = PongWrapper(pong_v3.env())\n\n# Load the agents\nmodel1 = loaded_model\nmodel2 = loaded_model\n\nrewards = {agent: 0 for agent in env.possible_agents}\n\n# We evaluate here using an AEC environments\nenv.reset(seed=1234)\nenv.action_space(env.possible_agents[0]).seed(123)\n\nfor agent in env.agent_iter():\n    obs, reward, termination, truncation, info = env.last()\n\n    for a in env.agents:\n        rewards[a] += env.rewards[a]\n\n    if termination or truncation:\n        break\n    else:\n        if agent == env.possible_agents[0]:\n            act = model1.predict(obs)\n        else:\n            act = model2.predict(obs)\n    env.step(act)\n\nprint(\"Final rewards:\", rewards)\nenv.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T14:49:11.572647Z","iopub.execute_input":"2025-12-11T14:49:11.572941Z","iopub.status.idle":"2025-12-11T14:49:11.922231Z","shell.execute_reply.started":"2025-12-11T14:49:11.572918Z","shell.execute_reply":"2025-12-11T14:49:11.921265Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1484192811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpettingzoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matari\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpong_v3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPongWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpong_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/4014442508.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, frame_stack)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_obs_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_space\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWrapperActType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "],"ename":"AssertionError","evalue":"","output_type":"error"}],"execution_count":14}]}