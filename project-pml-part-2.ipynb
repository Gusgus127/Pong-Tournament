{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Paradigms of Machine Learning\n\n## Project, Part 2: Pong World Tournament\n\n<u>General considerations</u>:\n\n- The proposed solution cannot use methods, functions or parameters declared **_deprecated_** in future versions.\n- This activity must be carried out on a **strictly individual** basis. Any indication of copying will be penalized with a failure for all parties involved and the possible negative evaluation of the subject in its entirety.\n- It is necessary for the student to indicate **all the sources** that she/he has used to carry out the PRA. If not, the student will be considered to have committed plagiarism, being penalized with a failure and the possible negative evaluation of the subject in its entirety.\n\n<u>Delivery format</u>:\n\n- Some exercises may require several minutes of execution, so the delivery must be done in **Notebook format** and in **HTML format**, where the code, results and comments of each exercise can be seen. You can export the notebook to HTML from the menu File $\\to$ Download as $\\to$ HTML.\n- There is a special type of cell to hold text. This type of cell will be very useful to answer the different theoretical questions posed throughout the activity. To change the cell type to this type, in the menu: Cell $\\to$ Cell Type $\\to$ Markdown.","metadata":{"id":"7xrRvDDNLUxK"}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<strong>Name and surname: Albert Saludas & Noa Solé</strong>\n</div>","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nThe [PettingZoo](https://pettingzoo.farama.org/index.html) is a simple, pythonic interface capable of representing **general multi-agent reinforcement learning** (MARL) problems. PettingZoo includes a wide variety of reference environments, helpful utilities, and tools for creating your own custom environments.\n\nThis activity uses the **AEC API**, which supports sequential turn-based environments.\n\nPettingZoo could be combined with [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/) or any other library to train the models.","metadata":{"id":"gee4aY31LUxL"}},{"cell_type":"markdown","source":"## Required libraries and dataset\n\nThe following libraries are required to properly run this activity: \n\n> !pip install swig\n\n> !pip install box2d-py\n\n> !pip install gymnasium\n\n> !pip install \"gymnasium[atari,accept-rom-license]\"\n\n> !pip install \"stable-baselines3[extra]\"\n\n> !pip install \"pettingzoo[all]\"\n\n> !pip install supersuit\n\n**Notes**:\n- **AutoROM** must be installed on the Python environment: `pip install \"autorom[accept-rom-license]\"` and then execute `AutoROM` from the command line.","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y ale-py gymnasium\n!pip install gymnasium==1.0.0\n!pip install ale-py==0.10.1\n!pip install stable-baselines3==2.4.0\n!pip install supersuit==3.9.3\n!pip install pettingzoo==1.24.3\n!pip install AutoROM==0.6.1\n!pip install multi-agent-ale-py==0.1.11\n!pip install wandb==0.19.0\n\n# Accept ROM license\n!AutoROM --accept-license","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T01:27:50.630783Z","iopub.execute_input":"2025-12-15T01:27:50.630940Z","iopub.status.idle":"2025-12-15T01:32:26.328097Z","shell.execute_reply.started":"2025-12-15T01:27:50.630924Z","shell.execute_reply":"2025-12-15T01:32:26.327347Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: ale-py 0.11.2\nUninstalling ale-py-0.11.2:\n  Successfully uninstalled ale-py-0.11.2\nFound existing installation: gymnasium 0.29.0\nUninstalling gymnasium-0.29.0:\n  Successfully uninstalled gymnasium-0.29.0\nCollecting gymnasium==1.0.0\n  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium==1.0.0) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium==1.0.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium==1.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->gymnasium==1.0.0) (2024.2.0)\nDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: gymnasium\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires ale-py>=0.10.1, which is not installed.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gymnasium-1.0.0\nCollecting ale-py==0.10.1\n  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py==0.10.1) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20->ale-py==0.10.1) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20->ale-py==0.10.1) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20->ale-py==0.10.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20->ale-py==0.10.1) (2024.2.0)\nDownloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py\nSuccessfully installed ale-py-0.10.1\nCollecting stable-baselines3==2.4.0\n  Downloading stable_baselines3-2.4.0-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (1.0.0)\nRequirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (2.6.0+cu124)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (3.1.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.4.0) (3.7.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3==2.4.0) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3==2.4.0) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.20.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.4.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.4.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3==2.4.0) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.4.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.4.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.4.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.4.0) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.4.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.20->stable-baselines3==2.4.0) (2024.2.0)\nDownloading stable_baselines3-2.4.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: stable-baselines3\n    Found existing installation: stable-baselines3 2.1.0\n    Uninstalling stable-baselines3-2.1.0:\n      Successfully uninstalled stable-baselines3-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.4.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.4.0\nCollecting supersuit==3.9.3\n  Downloading SuperSuit-3.9.3-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from supersuit==3.9.3) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from supersuit==3.9.3) (1.0.0)\nCollecting tinyscaler>=1.2.6 (from supersuit==3.9.3)\n  Downloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->supersuit==3.9.3) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->supersuit==3.9.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->supersuit==3.9.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->supersuit==3.9.3) (2024.2.0)\nDownloading SuperSuit-3.9.3-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (563 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tinyscaler, supersuit\nSuccessfully installed supersuit-3.9.3 tinyscaler-1.2.8\nCollecting pettingzoo==1.24.3\n  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3) (1.26.4)\nRequirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3) (1.0.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (3.1.2)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (4.15.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->pettingzoo==1.24.3) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->pettingzoo==1.24.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->pettingzoo==1.24.3) (2024.2.0)\nDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m566.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pettingzoo\n  Attempting uninstall: pettingzoo\n    Found existing installation: pettingzoo 1.24.0\n    Uninstalling pettingzoo-1.24.0:\n      Successfully uninstalled pettingzoo-1.24.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nkaggle-environments 1.18.0 requires pettingzoo==1.24.0, but you have pettingzoo 1.24.3 which is incompatible.\nkaggle-environments 1.18.0 requires stable-baselines3==2.1.0, but you have stable-baselines3 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pettingzoo-1.24.3\nCollecting AutoROM==0.6.1\n  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from AutoROM==0.6.1) (8.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from AutoROM==0.6.1) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM==0.6.1) (2025.10.5)\nDownloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\nInstalling collected packages: AutoROM\nSuccessfully installed AutoROM-0.6.1\nCollecting multi-agent-ale-py==0.1.11\n  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from multi-agent-ale-py==0.1.11) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->multi-agent-ale-py==0.1.11) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->multi-agent-ale-py==0.1.11) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->multi-agent-ale-py==0.1.11) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->multi-agent-ale-py==0.1.11) (2024.2.0)\nBuilding wheels for collected packages: multi-agent-ale-py\n  Building wheel for multi-agent-ale-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for multi-agent-ale-py: filename=multi_agent_ale_py-0.1.11-cp311-cp311-linux_x86_64.whl size=721821 sha256=b26d75278068b313f6a83cef8c1dec858655689a9f5ca4c0a69b68f7a5291c7f\n  Stored in directory: /root/.cache/pip/wheels/1d/81/76/771ec8e34292c8a71dd6c4a52a1c0401f4d93cbfb54e02fce4\nSuccessfully built multi-agent-ale-py\nInstalling collected packages: multi-agent-ale-py\nSuccessfully installed multi-agent-ale-py-0.1.11\nCollecting wandb==0.19.0\n  Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (8.3.0)\nCollecting docker-pycreds>=0.4.0 (from wandb==0.19.0)\n  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (3.1.45)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (4.5.0)\nCollecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb==0.19.0)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (7.1.3)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.12.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (6.0.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (2.33.2)\nCollecting setproctitle (from wandb==0.19.0)\n  Downloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.0) (4.15.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb==0.19.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.19.0) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb==0.19.0) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.0) (2025.10.5)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.19.0) (5.0.2)\nDownloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\nInstalling collected packages: setproctitle, protobuf, docker-pycreds, wandb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.21.0\n    Uninstalling wandb-0.21.0:\n      Successfully uninstalled wandb-0.21.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed docker-pycreds-0.4.0 protobuf-5.29.5 setproctitle-1.3.7 wandb-0.19.0\nAutoROM will download the Atari 2600 ROMs.\nThey will be installed to:\n\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n\t/usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms\n\nExisting ROMs will be overwritten.\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/adventure.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/adventure.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/air_raid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/air_raid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/alien.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/alien.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/amidar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/amidar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/assault.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/assault.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asterix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asterix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asteroids.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asteroids.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/backgammon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/backgammon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bank_heist.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/basic_math.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/basic_math.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/battle_zone.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/beam_rider.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/berzerk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/berzerk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/blackjack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/blackjack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bowling.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bowling.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/boxing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/boxing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/breakout.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/breakout.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/carnival.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/carnival.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/casino.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/casino.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/centipede.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/centipede.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/chopper_command.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/combat.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/combat.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crazy_climber.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crossbow.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crossbow.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/darkchambers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/defender.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/defender.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/demon_attack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/donkey_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/double_dunk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/earthworld.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/earthworld.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/elevator_action.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/enduro.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/enduro.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/entombed.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/entombed.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/et.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/et.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/fishing_derby.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/flag_capture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/freeway.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/freeway.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frogger.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frogger.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frostbite.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frostbite.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/galaxian.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/galaxian.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gopher.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gopher.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gravitar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gravitar.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hangman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hangman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/haunted_house.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hero.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hero.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/human_cannonball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ice_hockey.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/jamesbond.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/journey_escape.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/joust.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/joust.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kaboom.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kaboom.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kangaroo.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/keystone_kapers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/king_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/king_kong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/klax.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/klax.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/koolaid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/koolaid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/krull.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/krull.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kung_fu_master.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/laser_gates.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/lost_luggage.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mario_bros.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/maze_craze.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/miniature_golf.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/montezuma_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mr_do.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mr_do.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ms_pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/name_this_game.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/othello.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/othello.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pacman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/phoenix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/phoenix.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pong.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pooyan.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pooyan.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/private_eye.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/private_eye.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/qbert.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/qbert.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/riverraid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/riverraid.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/road_runner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/road_runner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/robotank.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/robotank.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/seaquest.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/seaquest.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/sir_lancelot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/skiing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/skiing.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/solaris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/solaris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_invaders.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_war.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_war.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/star_gunner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/superman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/superman.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/surround.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/surround.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tennis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tennis.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tetris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tetris.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/time_pilot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/trondead.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/trondead.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/turmoil.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/turmoil.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tutankham.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tutankham.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/up_n_down.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/venture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/venture.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_checkers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_chess.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_chess.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_cube.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_cube.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_pinball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/warlords.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/warlords.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/wizard_of_wor.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/word_zapper.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/yars_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\nInstalled /usr/local/lib/python3.11/dist-packages/AutoROM/roms/zaxxon.bin\nInstalled /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\nDone!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Configuring the environment\n\nThe [Supersuit Wrappers](https://pettingzoo.farama.org/api/wrappers/supersuit_wrappers/) are used to preprocess the data in our environment.\n\nSpecifically, the environment uses the following wrappers:\n1. The `color_reduction_v0` wrapper with `mode='B'` parameter.\n2. The `resize_v1` with parameters `x_size=84` and `y_size=84`.\n3. The `frame_stack_v1` wrapper with params `num_frames=4`.\n4. The `dtype_v0` with param  `dtype=np.float32`.\n5. The `normalize_obs_v0` wrapper with parameters `env_min=0`and `env_max=1`.","metadata":{}},{"cell_type":"markdown","source":"#### The observation Space\n\nTherefore, the **observation** from the environment has the shape:\n- (84 $\\times$ 84 $\\times$ 4)\n\nSo, each image looks like the following one:","metadata":{}},{"cell_type":"markdown","source":"<p style=\"text-align:center;\"><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZYAAAGTCAYAAAALNTQlAAAKoGlDQ1BJQ0MgUHJvZmlsZQAASImVlgdQk9kWx+/3pYeEFkA6oTfpLYCU0EPvTVRCEiCUGBKCil1ZXIEVRUUEFUFXQRSsgCwqIoptEVCwu0EWAXVdLIiKyvuAIezum/fevDNzc35zcu6559z57swfADKeyednwLIAZPKyBeG+HtTYuHgqbhiQAAUQgAlQY7KEfHpoaCBAbM7/3T72A2ja3zWbrvXv//9Xk2NzhCwAoFCEk9hCVibCZ5H1nMUXZAOAKkPiuiuy+dPcirCCAGkQ4e5pTpnl36c5aZY/zeREhnsCgCYBgCcxmYIUAEjKSJyaw0pB6pBoCFvy2FwewqkIu2ZmLmcjXIOwEZLDR3i6Pi3pL3VS/lYzSVKTyUyR8OwsM4b34gr5GcxV/+d1/G/LzBDNnWEApgcQ+IUjnojc2YP05QES5iUFh8wxlz2TP8OpIr+oOWYJPePnmM30CpDszQgOnONkrg9DUiebETnHHKF3xBwLlodLzkoWeNLnmCmYP1eUHiWJp3IYkvq5qZExc5zDjQ6eY2F6RMB8jqckLhCFS/rn8Hw95s/1kcyeKfzLvFyGZG92aqSfZHbmfP8cHn2+pjBW0hub4+U9nxMlyedne0jO4meESvI5Gb6SuDAnQrI3G/kg5/eGSu4wjekfOscgGvgCa+AAkFvK5qzMnh7Aczl/lYCbkppNpSMvi0Nl8FjmC6nWltY2AEy/09nP4P2dmfcHKSfNxwQFADgmIzA8H1taAUCTCHlyE/Mx/VMAyOgD0BbCEglyZmPo6R8M0pUMUAAqQBPoAiNghvRmD5yBO/AG/iAERII4sBSwQCrIBAKwAqwBG0E+KATbwW5QDirBIVADToDToAm0gsvgGrgFukEfeAzEYAi8AmPgI5iEIAgHkSEKpAJpQfqQKWQN0SBXyBsKhMKhOCgRSoF4kAhaA22GCqESqByqgmqhU9B56DJ0A+qBHkID0Cj0DvoCo2ASrABrwAawBUyD6XAAHAkvgVPgLDgXzoO3wWVwNXwcboQvw7fgPlgMv4LHUQAlhVJCaaPMUDSUJyoEFY9KRglQ61AFqFJUNaoe1YLqRN1FiVGvUZ/RWDQFTUWboZ3RfugoNAudhV6HLkKXo2vQjegO9F30AHoM/R1DxqhjTDFOGAYmFpOCWYHJx5RijmDOYa5i+jBDmI9YLFYJa4h1wPph47Bp2NXYIux+bAO2DduDHcSO43A4FZwpzgUXgmPisnH5uL2447hLuF7cEO4TXgqvhbfG++Dj8Tz8Jnwp/hj+Ir4XP4yfJMgS9AlOhBACm7CKUEw4TGgh3CEMESaJckRDogsxkphG3EgsI9YTrxKfEN9LSUnpSDlKhUlxpTZIlUmdlLouNSD1mSRPMiF5khJIItI20lFSG+kh6T2ZTDYgu5PjydnkbeRa8hXyM/InaYq0uTRDmi29XrpCulG6V/qNDEFGX4Yus1QmV6ZU5ozMHZnXsgRZA1lPWabsOtkK2fOy92XH5ShyVnIhcplyRXLH5G7Ijcjj5A3kveXZ8nnyh+SvyA9SUBRdiieFRdlMOUy5ShlSwCoYKjAU0hQKFU4odCmMKcor2ipGK65UrFC8oChWQikZKDGUMpSKlU4r9St9WaCxgL6As2DrgvoFvQsmlNWU3ZU5ygXKDcp9yl9UqCreKukqO1SaVJ6qolVNVMNUV6geUL2q+lpNQc1ZjaVWoHZa7ZE6rG6iHq6+Wv2Q+m31cQ1NDV8NvsZejSsarzWVNN010zR3aV7UHNWiaLlqcbV2aV3SeklVpNKpGdQyagd1TFtd209bpF2l3aU9qWOoE6WzSadB56kuUZemm6y7S7ddd0xPSy9Ib41end4jfYI+TT9Vf49+p/6EgaFBjMEWgyaDEUNlQ4ZhrmGd4RMjspGbUZZRtdE9Y6wxzTjdeL9xtwlsYmeSalJhcscUNrU35ZruN+1ZiFnouJC3sHrhfTOSGd0sx6zObMBcyTzQfJN5k/kbCz2LeIsdFp0W3y3tLDMsD1s+tpK38rfaZNVi9c7axJplXWF9z4Zs42Oz3qbZ5q2tqS3H9oDtAzuKXZDdFrt2u2/2DvYC+3r7UQc9h0SHfQ73aQq0UFoR7bojxtHDcb1jq+NnJ3unbKfTTn86mzmnOx9zHllkuIiz6PCiQRcdF6ZLlYvYleqa6HrQVeym7cZ0q3Z77q7rznY/4j5MN6an0Y/T33hYegg8znlMeDp5rvVs80J5+XoVeHV5y3tHeZd7P/PR8UnxqfMZ87XzXe3b5ofxC/Db4XefocFgMWoZY/4O/mv9OwJIAREB5QHPA00CBYEtQXCQf9DOoCfB+sG84KYQEMII2RnyNNQwNCv0lzBsWGhYRdiLcKvwNeGdEZSIZRHHIj5GekQWRz6OMooSRbVHy0QnRNdGT8R4xZTEiGMtYtfG3opTjePGNcfj4qPjj8SPL/ZevHvxUIJdQn5C/xLDJSuX3FiqujRj6YVlMsuYy84kYhJjEo8lfmWGMKuZ40mMpH1JYyxP1h7WK7Y7exd7lOPCKeEMJ7sklySPpLik7EwZTXVLLU19zfXklnPfpvmlVaZNpIekH02fyojJaMjEZyZmnufJ89J5Hcs1l69c3sM35efzxVlOWbuzxgQBgiNCSLhE2JytgAii2yIj0Q+igRzXnIqcTyuiV5xZKbeSt/L2KpNVW1cN5/rk/rwavZq1un2N9pqNawbW0tdWrYPWJa1rX6+7Pm/90AbfDTUbiRvTN/66yXJTyaYPm2M2t+Rp5G3IG/zB94e6fOl8Qf79Lc5bKn9E/8j9sWurzda9W78XsAtuFloWlhZ+LWIV3fzJ6qeyn6a2JW/rKrYvPrAdu523vX+H246aErmS3JLBnUE7G3dRdxXs+rB72e4bpballXuIe0R7xGWBZc179fZu3/u1PLW8r8KjomGf+r6t+yb2s/f3HnA/UF+pUVlY+eUg9+CDKt+qxmqD6tJD2EM5h14cjj7c+TPt59ojqkcKj3w7yjsqrgmv6ah1qK09pn6suA6uE9WNHk843n3C60RzvVl9VYNSQ+FJcFJ08uWpxFP9pwNOt5+hnak/q3923znKuYJGqHFV41hTapO4Oa6557z/+fYW55Zzv5j/crRVu7XiguKF4ovEi3kXpy7lXhpv47e9vpxyebB9WfvjK7FX7nWEdXRdDbh6/ZrPtSud9M5L112ut95wunH+Ju1m0y37W4237W6f+9Xu13Nd9l2NdxzuNHc7drf0LOq52OvWe/mu191r9xj3bvUF9/X0R/U/uJ9wX/yA/WDkYcbDt49yHk0+3vAE86TgqezT0mfqz6p/M/6tQWwvvjDgNXD7ecTzx4OswVe/C3//OpT3gvyidFhruHbEeqR11Ge0++Xil0Ov+K8mX+f/IffHvjdGb87+6f7n7bHYsaG3grdT74req7w/+sH2Q/t46Pizj5kfJycKPql8qvlM+9z5JebL8OSKr7ivZd+Mv7V8D/j+ZCpzaorPFDBnpAAKWXAyoiPeHQWAHAcABdHFxMWzOnrGoFntP0PgP/Gs1p4xewBqNgAQ5Q5AYBsABzfMylhpxE9LIUQawTY2kjWneWf0+bRhzwBgqDNNYmHYGPiHzWr3v/T9Tz9T3Rb80/8LdogCKx9ERz4AAABWZVhJZk1NACoAAAAIAAGHaQAEAAAAAQAAABoAAAAAAAOShgAHAAAAEgAAAESgAgAEAAAAAQAAAZagAwAEAAAAAQAAAZMAAAAAQVNDSUkAAABTY3JlZW5zaG90gLu45gAAAdZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDYuMC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6ZXhpZj0iaHR0cDovL25zLmFkb2JlLmNvbS9leGlmLzEuMC8iPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+NDAzPC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjQwNjwvZXhpZjpQaXhlbFhEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlVzZXJDb21tZW50PlNjcmVlbnNob3Q8L2V4aWY6VXNlckNvbW1lbnQ+CiAgICAgIDwvcmRmOkRlc2NyaXB0aW9uPgogICA8L3JkZjpSREY+CjwveDp4bXBtZXRhPgpyLKlHAAArYklEQVR4Ae3dC3AV5f3/8W8wF0BIArEkUBNFSxsVqRIVojitmjZDrQWSYbSDFYURlYiSWC9pC6PjJVRbL1gFtRTsAFIy4y1OhdEoWNuAEIs3MGJlTGpIqK1JAEnCwPPbZ///XbPJZs/Zk5PkXN47s5zdfZ7ds/va5XzOs5eTBGV0QocAAggggECYBIaEaTksBgEEEEAAAVOAYOFAQAABBBAIq0Cfg+WJJ56QU089VYYOHSpTpkyRd955J6wryMIQQAABBKJLIKEv11j+8pe/yDXXXCMrV640Q+XRRx+VyspKqaurkzFjxnhKHD9+XBobG2XkyJGSkJDgWZdCBBBAAIHIE9CX6A8ePCjjxo2TIUO6tFN0sITaXXDBBaqkpMSe/dixY8p4A1VRUWFP622goaFB3zRAjwHHAMcAx0CUHwP687xrlxhqBnZ2dkptba2Ul5fbi9CJVVBQIDU1NfY0a6Cjo0N0b3XGSliDvIZJ4OKLLw7TkrwX87e//c27AqUI9JPArFmz+mnJzsVu2bLFOcEY++qrr3pMY8L/E9Bnnrp2IQfLl19+KUYLRTIzM7suzxz/+OOPHdP0iNGKkXvuuafHdCaEJuB2+jAxMeTdGdpKMBcCAyyQlJQ0IO/oOK0zIO8Y3W/S/fOoy0mx/t0w3bJpbW21e6Pp1L9vyNIRQCDmBPQH2ED0MQc3wBsU8lfck046SU444QRpbm52rLIez8rKckzTIykpKWbfo4AJCCCAAAIxJRByiyU5OVny8vKkurraBtF3eunx/Px8exoDCCCAAALxJRByi0UzlZWVydy5c+W8884T4w4x0bcbHz58WK677rr4UmRrEUAAAQRsgT4Fy5VXXin/+c9/ZOnSpdLU1CTnnHOObNq0qccFffvdGEAAAQQQiHmBPgWL1rn55pvNPualYmAD33zzzYBbcckllwSsQwUEBksg0GMKGzduDLhqs2fP7lGn+11NPSowwZdAyNdYfL0LlRFAAAEE4kaAYImbXc2GIoAAAgMjQLAMjDPvggACCMSNAMESN7uaDUUAAQQGRoBgGRhn3gUBBBCIGwGCJW52NRuKAAIIDIwAwTIwzrwLAgggEDcCBEvc7Go2FAEEEBgYgT4/IDkwq8m7IIAAAtJvf22WByTDe3TRYgmvJ0tDAAEE4l6AYIn7QwAABBBAILwCBEt4PVkaAgggEPcCBEvcHwIAIIAAAuEVIFjC68nSEEAAgbgXIFji/hAAAAEEEAivAMESXk+WhgACCMS9AM+xxNEhMHz48DjaWjY1HgVSU1PjcbMjbptpsUTcLmGFEEAAgegWIFiie/+x9ggggEDECRAsEbdLWCEEEEAgugUIlujef6w9AgggEHECXLyPuF3Sfys0ZcqU/ls4S0YgAgSmT58eAWvBKtBi4RhAAAEEEAirAMESVk4WhgACCCBAsHAMIIAAAgiEVSBBGV1Ylxjkwtra2iQtLS3I2lRDAAEEEIhUgdbWVun6cCotlkjdU6wXAgggEKUCBEuU7jhWGwEEEIhUAYIlUvcM64UAAghEqQDBEqU7jtVGAAEEIlVg0B+QfOqpp2TYsGGR6sN6IYAAAgj0InDkyBG54YYbepTSYulBwgQEEEAAgb4IECx90WNeBBBAAIEeAr0Gy1tvvSVXXHGFjBs3ThISEuTFF190zKwff1m6dKmMHTvWPJVVUFAge/fuddRhBAEEEEAg/gR6vcZy+PBh+f73vy/z5s2ToqKiHjIPPvigLF++XJ599lkZP368LFmyRAoLC2X37t0ydOjQHvV7m3DVVVc5HqzprR7TEUAAAQQiS0A/6O52jaXXYNG/EtrbL4Xq1sqjjz4qv/nNb2TGjBnmlv75z3+WzMxMs2Wjw4IOAQQQQCA+BXo9FebFsW/fPmlqahJ9+svq9M+z6J9lr6mpsSY5Xjs6OkSnW9feUYERBBBAAIGYEAgpWHSo6E63ULp2etwq6zpdD1dUVJi/DaYDSPfZ2dndqzCOAAIIIBADAiEFSyjbXV5eLvqHyqy+oaEhlMUwDwIIIIBAhAuEFCxZWVnmZjU3Nzs2T49bZY4CYyQlJcW8SK9/AdPqu9dhHAEEEEAg+gVCChZ9F5gOkOrqaltAXzvZvn275Ofn29MYQAABBBCIP4Fe7wo7dOiQfPrpp7aIvmC/a9cuGT16tOTk5MjixYvlvvvukwkTJti3G+tnXmbOnGnPwwACCCCAQPwJ9BosO3fulEsuucQWKSsrM4fnzp0ra9askTvuuEP0sy4LFiyQlpYWmTZtmmzatMnXMyz2whlAAAEEEIgZgUH/C5Ld//JYzMiyIQgggECMC+hLIPou3+6f4yFdY4lxKzYPAQQQQKAPAgRLH/CYFQEEEECgpwDB0tOEKQgggAACfRDo9eJ9H5bpa9bS0lJJTk72NQ+VEUAAAQQGX6Czs9N1JWixuLIwEQEEEEAgVAGCJVQ55kMAAQQQcBUgWFxZmIgAAgggEKoAwRKqHPMhgAACCLgKDPoDkq5rxUQEEEAAgagR4AHJqNlVrCgCCCAQnQKcCovO/cZaI4AAAhErQLBE7K5hxRBAAIHoFCBYonO/sdYIIIBAxAoQLBG7a1gxBBBAIDoFCJbo3G+sNQIIIBCxAgRLxO4aVgwBBBCITgGCJTr3G2uNAAIIRKwAwRKxu4YVQwABBKJTgGCJzv3GWiOAAAIRK0CwROyuYcUQQACB6BQgWKJzv7HWCCCAQMQKECwRu2tYMQQQQCA6BQiW6NxvrDUCCCAQsQIES8TuGlYMAQQQiE4BgiU69xtrjQACCESsAMESsbuGFUMAAQSiU4Bgic79xlojgAACEStAsETsrmHFEEAAgegUIFiic7+x1ggggEDEChAsEbtrWDEEEEAgOgUIlujcb6w1AgggELECBEvE7hpWDAEEEIhOAYIlOvcba40AAghErIBrsFRUVMj5558vI0eOlDFjxsjMmTOlrq7OsRHt7e1SUlIiGRkZMmLECCkuLpbm5mZHHUYQQAABBOJPwDVYtm7daobGtm3b5LXXXpOjR4/Kj3/8Yzl8+LAtVFpaKlVVVVJZWSm6fmNjoxQVFdnlDCCAAAIIxKmACqI7cOCAMniUESBm7ZaWFpWUlKSMULHn3rNnj1mnpqbGnuY10NraatbXy6XHgGOAY4BjIHqPAf153rVzbbEYO9jRGTOZ46NHjzZfa2trzVZMQUGBXS83N1dycnLECBZ7WteBjo4OaWtrc/RdyxlGAAEEEIgNgYDBcvz4cVm8eLFcdNFFMnHiRHOrm5qaJDk5WdLT0x0KmZmZosvcOn3dJi0tze6zs7PdqjENAQQQQCDKBQIGi75A/+GHH8qGDRv6tKnl5eWiWz5W39DQ0KflMTMCCCCAQGQKJHqt1s033yyvvPKKvPXWW3LyySfbVbOysqSzs1OMay2OVou+K0yXuXUpKSmiezoEEEAAgdgWcG2xGBdhRIfKCy+8IG+88YaMHz/eoZCXlyfGxXuprq62p+vbkevr6yU/P9+exgACCCCAQPwJuLZY9Omv9evXy0svvWQ+y2JdN9HXSIYNG2ZeJ5k/f76UlZWJvqCfmpoqixYtMkNl6tSp8afIFiOAAAIIfCPQ9RYxa9godb0FePXq1VYVdeTIEbVw4UI1atQoNXz4cDVr1iy1f/9+uzzQgL49rbf3Ybq7Py64cAxwDETiMaA/z7t2CXrEWNEB7/Stx7oFRIcAAgggEN0C+qYsfebK6lyvsViFvCKAAAIIIOBXgGDxK0Z9BBBAAAFPAYLFk4dCBBBAAAG/AgSLXzHqI4AAAgh4ChAsnjwUIoAAAgj4FSBY/IpRHwEEEEDAU4Bg8eShEAEEEEDArwDB4leM+ggggAACngIEiycPhQgggAACfgUIFr9i1EcAAQQQ8BQgWDx5KEQAAQQQ8CtAsPgVoz4CCCCAgKcAweLJQyECCCCAgF8BgsWvGPURQAABBDwFCBZPHgoRQAABBPwKECx+xaiPAAIIIOApQLB48lCIAAIIIOBXgGDxK0Z9BBBAAAFPAYLFk4dCBBBAAAG/AgSLXzHqI4AAAgh4ChAsnjwUIoAAAgj4FSBY/IpRHwEEEEDAU4Bg8eShEAEEEEDArwDB4leM+ggggAACngIEiycPhQgggAACfgUIFr9i1EcAAQQQ8BQgWDx5KEQAAQQQ8CtAsPgVoz4CCCCAgKcAweLJQyECCCCAgF8BgsWvGPURQAABBDwFCBZPHgoRQAABBPwKECx+xaiPAAIIIOApQLB48lCIAAIIIOBXwDVYVqxYIZMmTZLU1FSzz8/Pl1dffdVednt7u5SUlEhGRoaMGDFCiouLpbm52S5nAAEEEEAgfgVcg+Xkk0+WZcuWSW1trezcuVMuvfRSmTFjhnz00UemVGlpqVRVVUllZaVs3bpVGhsbpaioKH4V2XIEEEAAgW8EVJDdqFGj1B//+EfV0tKikpKSlBEq9px79uxRxhJVTU2NPS3QQGtrqzmPno8eA44BjgGOgeg9BvTnedfOtcVi7GC7O3bsmGzYsEEOHz4s+pSYbsUcPXpUCgoK7Dq5ubmSk5MjRrDY07oPdHR0SFtbm6PvXodxBBBAAIHoF+g1WD744APz+klKSorceOON8sILL8iZZ54pTU1NkpycLOnp6Y6tz8zMNMscE7uMVFRUSFpamt1nZ2d3KWUQAQQQQCBWBHoNlu9973uya9cu2b59u9x0000yd+5c2b17d8jbXV5eLkZzye4bGhpCXhYzIoAAAghErkBib6umWyXf+c53zOK8vDzZsWOHPPbYY3LllVdKZ2enGNdaHK0WfVdYVlZWb4sT3fLRPR0CCCCAQGwL9Npi6b7Zx48fF32dRIeMcfFeqqur7Sp1dXVSX19vXoOxJzKAAAIIIBCXAq4tFn3aavr06eYF+YMHD8r69etly5YtsnnzZvMayfz586WsrExGjx5tPueyaNEiM1SmTp0al4hsNAIIIIDANwKuwXLgwAG55pprZP/+/WaQ6Icldaj86Ec/Mud85JFHZMiQIeaDkboVU1hYKE8++eQ3S2UIAQQQQCBuBRL0vceDsfX61mN9lxgdAggggEB0C+gbs/QvtVhd0NdYrBl4RQABBBBAwEuAYPHSoQwBBBBAwLcAweKbjBkQQAABBLwECBYvHcoQQAABBHwLECy+yZgBAQQQQMBLgGDx0qEMAQQQQMC3AMHim4wZEEAAAQS8BAgWLx3KEEAAAQR8CxAsvsmYAQEEEEDAS4Bg8dKhDAEEEEDAtwDB4puMGRBAAAEEvAQIFi8dyhBAAAEEfAsQLL7JmAEBBBBAwEuAYPHSoQwBBBBAwLcAweKbjBkQQAABBLwECBYvHcoQQAABBHwLECy+yZgBAQQQQMBLgGDx0qEMAQQQQMC3AMHim4wZEEAAAQS8BAgWLx3KEEAAAQR8CxAsvsmYAQEEEEDAS4Bg8dKhDAEEEEDAtwDB4puMGRBAAAEEvAQIFi8dyhBAAAEEfAsQLL7JmAEBBBBAwEsg0aswnsouueSSgJtbU1PjqNPe3u4YZwQBBBDwKzB06FDHLNOmTXOMu428/vrrbpMjZhotlojZFawIAgggEBsCBEts7Ee2AgEEEIgYAYIlYnYFK4IAAgjEhgDBEhv7ka1AAAEEIkaAi/cRsytYEQQQiEeBIUOc3+8zMjKinsG5RVG/OWwAAggggMBgCxAsg70HeH8EEEAgxgSCCpZly5ZJQkKCLF682N58/QxHSUmJ6GbbiBEjpLi4WJqbm+1yBhBAAAEE4lMgYLDs2LFDnnrqKZk0aZJDqLS0VKqqqqSyslK2bt0qjY2NUlRU5KjDCAIIIIBA/Al4BsuhQ4dkzpw58swzz8ioUaNsndbWVlm1apU8/PDDcumll0peXp6sXr1a/vGPf8i2bdvsegwggAACCMSfgGew6FNdl19+uRQUFDhkamtr5ejRo47pubm5kpOTI91/9sSasaOjQ9ra2hy9VcYrAggggEDsCPR6u/GGDRvk3XffFX0qrHvX1NQkycnJkp6e7ijKzMwUXebWVVRUyD333ONWxDQEEEAAgRgScG2xNDQ0yK233irr1q2T7j+QFuq2l5eXiz6FZvX6PegQQAABBGJPwDVY9KmuAwcOyOTJkyUxMdHs9QX65cuXm8O6ZdLZ2SktLS0OEX1XWFZWlmOaNZKSkiKpqamO3irjFQEEEEAgdgRcT4Vddtll8sEHHzi28rrrrhN9HeXOO++U7OxsSUpKkurqavM2Y12xrq5O6uvrJT8/3zEfIwgggAAC8SXgGiwjR46UiRMnOiROPPFE85kVa/r8+fOlrKxMRo8ebbZCFi1aZIbK1KlTHfMxggACCCAQXwKuwRIMwSOPPCL6N270g5H6jq/CwkJ58skng5mVOggggAACMSwQdLBs2bLFwaAv6j/xxBNm7yhgBAEEEEAgrgVcL97HtQgbjwACCCDQJwGCpU98zIwAAggg0F2AYOkuwjgCCCCAQJ8ECJY+8TEzAggggEB3AYKluwjjCCCAAAJ9EiBY+sTHzAgggAAC3QUIlu4ijCOAAAII9EmAYOkTHzMjgAACCHQXCPoBye4zxtr4rl27Am6S/oUBOgQQQAABbwFaLN4+lCKAAAII+BQgWHyCUR0BBBBAwFuAYPH2oRQBBBBAwKdAgjI6n/OEpXpbW5ukpaWFZVksBAEEEEBg8AT0XwbWf8jR6mixWBK8IoAAAgiERYBgCQsjC0EAAQQQsAQIFkuCVwQQQACBsAgQLGFhZCEIIIAAApYAwWJJ8IoAAgggEBYBgiUsjCwEAQQQQMASIFgsCV4RQAABBMIiQLCEhZGFIIAAAghYAgSLJcErAggggEBYBAiWsDCyEAQQQAABS4BgsSR4RQABBBAIiwDBEhZGFoIAAgggYAkQLJYErwgggAACYREgWMLCyEIQQAABBCwBgsWS4BUBBBBAICwCBEtYGFkIAggggIAlQLBYErwigAACCIRFgGAJCyMLQQABBBCwBAgWS4JXBBBAAIGwCBAsYWFkIQgggAACloBrsNx9992SkJDg6HNzc615pL29XUpKSiQjI0NGjBghxcXF0tzcbJczgAACCCAQvwKuwaI5zjrrLNm/f7/dv/3227ZSaWmpVFVVSWVlpWzdulUaGxulqKjILmcAAQQQQCB+BRJ72/TExETJysrqUdza2iqrVq2S9evXy6WXXmqWr169Ws444wzZtm2bTJ06tcc8TEAAAQQQiB+BXlsse/fulXHjxslpp50mc+bMkfr6elOltrZWjh49KgUFBbaSPk2Wk5MjNTU19rTuAx0dHdLW1ubou9dhHAEEEEAg+gVcg2XKlCmyZs0a2bRpk6xYsUL27dsnF198sRw8eFCampokOTlZ0tPTHVufmZlpljkmdhmpqKiQtLQ0u8/Ozu5SyiACCCCAQKwIuJ4Kmz59ur19kyZNEh00p5xyimzcuFGGDRtml/kZKC8vl7KyMnsW3XohXGwOBhBAAIGYEXBtsXTfOt06+e53vyuffvqped2ls7NTWlpaHNX0XWFu12SsSikpKZKamurorTJeEUAAAQRiRyCoYDl06JD861//krFjx0peXp4kJSVJdXW1rVBXV2deg8nPz7enMYAAAgggEKcCyqW77bbb1JYtW5RxbUX9/e9/V8aFenXSSSepAwcOmLVvvPFGZVysV2+88YbauXOnMgLF7F0W1esk4+4yZZDTY8AxwDHAMRDlx4D+PO/auV5j+fe//y0///nP5b///a9861vfkmnTppm3Euth3T3yyCMyZMgQ88FIfbdXYWGhPPnkk2YZ/yCAAAIIxLdAgk6ZwSDQF+/1XWJ0CCCAAALRLaCfb9TX0K0uqGssVmVeEUAAAQQQCCRAsAQSohwBBBBAwJcAweKLi8oIIIAAAoEECJZAQpQjgAACCPgSIFh8cVEZAQQQQCCQAMESSIhyBBBAAAFfAgSLLy4qI4AAAggEEiBYAglRjgACCCDgS8D1yXtfS6AyAhEu4PYr2rfccotjrW+//XbHOCMIIBC6AC2W0O2YEwEEEEDARYBgcUFhEgIIIIBA6AIES+h2zIkAAggg4CLAj1C6oDAptgQmT57cY4P++te/OqZ5/ZE6R0VGEECghwA/QtmDhAkIIIAAAuEU4FRYODVZFgIIIICAECwcBAgggAACYRUgWMLKycIQQAABBLh4zzGAAAIIINAnAS7e94mPmRFAAAEEAglwKiyQEOUIIIAAAr4ECBZfXFRGAAEEEAgkQLAEEqIcAQQQQMCXAMHii4vKCCCAAAKBBAiWQEKUI4AAAgj4EiBYfHFRGQEEEEAgkADBEkiIcgQQQAABXwIEiy8uKiOAAAIIBBIgWAIJUY4AAggg4EuAYPHFRWUEEEAAgUACBEsgIcoRQAABBHwJECy+uKiMAAIIIBBIgGAJJEQ5AggggIAvAYLFFxeVEUAAAQQCCfQaLF988YVcffXVkpGRIcOGDZOzzz5bdu7caS9PKSVLly6VsWPHmuUFBQWyd+9eu5wBBBBAAIH4FHANlq+++kouuugiSUpKkldffVV2794tv//972XUqFG20oMPPijLly+XlStXyvbt2+XEE0+UwsJCaW9vt+swgAACCCAQhwJGy6NHd+edd6pp06b1mG5NOH78uMrKylIPPfSQNUm1tLSolJQU9dxzz9nTvAaMvzimDG56DDgGOAY4BqL8GNCf51071xbLyy+/LOedd57Mnj1bxowZI+eee64888wzduzu27dPmpqaRJ/+srq0tDSZMmWK1NTUWJMcrx0dHdLW1uboHRUYQQABBBCICQHXYPnss89kxYoVMmHCBNm8ebPcdNNNcsstt8izzz5rbrQOFd1lZmaar9Y/etwqs6ZZrxUVFaLDx+qzs7OtIl4RQAABBGJIwDVYjFNdMnnyZHnggQfM1sqCBQvk+uuvN6+nhLrt5eXlYjSX7L6hoSHURTEfAggggEAEC7gGi77T68wzz3Ss9hlnnCH19fXmNOP6ivna3NzsqKPHrTJHgTFiXH+R1NRUR9+9DuMIIIAAAtEv4Bos+o6wuro6x9Z98skncsopp5jTxo8fbwZIdXW1XUdfP9F3h+Xn59vTGEAAAQQQiEOBrlfyreF33nlHJSYmqvvvv18Zz6aodevWqeHDh6u1a9daVdSyZctUenq6eumll9T777+vZsyYoYzAUUeOHLHreA1wVxh3xBn/3bgbCAOOgRg4BrrfFSa9ffhXVVWpiRMnmrcQ5+bmqqefftpRVd9yvGTJEmVcsDfrXHbZZcpo5TjqeI0QLHyoEiwcAxwDsXEMdA+WBP3hPxgNNX3qTN8hRocAAgggEN0CRrCY18+trXC9xmIV8ooAAggggIBfAYLFrxj1EUAAAQQ8BQgWTx4KEUAAAQT8ChAsfsWojwACCCDgKUCwePJQiAACCCDgV4Bg8StGfQQQQAABTwGCxZOHQgQQQAABvwIEi18x6iOAAAIIeAoQLJ48FCKAAAII+BUgWPyKUR8BBBBAwFOAYPHkoRABBBBAwK8AweJXjPoIIIAAAp4CBIsnD4UIIIAAAn4FCBa/YtRHAAEEEPAUIFg8eShEAAEEEPArQLD4FaM+AggggICnAMHiyUMhAggggIBfAYLFrxj1EUAAAQQ8BQgWTx4KEUAAAQT8ChAsfsWojwACCCDgKUCwePJQiAACCCDgV4Bg8StGfQQQQAABTwGCxZOHQgQQQAABvwIEi18x6iOAAAIIeAoQLJ48FCKAAAII+BUgWPyKUR8BBBBAwFOAYPHkoRABBBBAwK8AweJXjPoIIIAAAp4CBIsnD4UIIIAAAn4FCBa/YtRHAAEEEPAUIFg8eShEAAEEEPArQLD4FaM+AggggICnAMHiyUMhAggggIBfAddgOfXUUyUhIaFHX1JSYi6/vb1d9HBGRoaMGDFCiouLpbm52e97Ux8BBBBAIAYFXINlx44dsn//frt/7bXXzE2fPXu2+VpaWipVVVVSWVkpW7dulcbGRikqKopBHjYJAQQQQMC3gAqiu/XWW9Xpp5+ujh8/rlpaWlRSUpIyQsWec8+ePcp4Y1VTU2NPCzTQ2tpqzqPno8eAY4BjgGMgeo8B/XnetXNtsRg72O46Oztl7dq1Mm/ePPPUWG1trRw9elQKCgrsOrm5uZKTkyNGsNjTug90dHRIW1ubo+9eh3EEEEAAgegXCBgsL774ohitFLn22mvNrW1qapLk5GRJT093bH1mZqbost66iooKSUtLs/vs7OzeqjIdAQQQQCCKBQIGy6pVq2T69Okybty4Pm1meXm5GM0lu29oaOjT8pgZAQQQQCAyBRK9Vuvzzz+X119/XZ5//nm7WlZWlujTY7oV07XVou8K02W9dSkpKaJ7OgQQQACB2BbwbLGsXr1axowZI5dffrmtkJeXJ8bFe6murran1dXVSX19veTn59vTGEAAAQQQiE+BXlssxh1gooNl7ty5kpj4TTV9nWT+/PlSVlYmo0ePltTUVFm0aJEZKlOnTo1PRbYaAQQQQOAbga63iHUd3rx5s3kbsNEa6TrZHD5y5IhauHChGjVqlBo+fLiaNWuWMp576VHPawK3G0fvrYXG0cMt4hhwDHAM2MdA99uNE/SH/zcxM3BD+tZj3fqhQwABBBCIbgF9Y5Y+e2V1ntdYrEq8IoAAAgggEKwAwRKsFPUQQAABBIISIFiCYqISAggggECwAgRLsFLUQwABBBAISoBgCYqJSggggAACwQoQLMFKUQ8BBBBAICgBgiUoJiohgAACCAQrQLAEK0U9BBBAAIGgBAiWoJiohAACCCAQrADBEqwU9RBAAAEEghIgWIJiohICCCCAQLACBEuwUtRDAAEEEAhKgGAJiolKCCCAAALBChAswUpRDwEEEEAgKAGCJSgmKiGAAAIIBCtAsAQrRT0EEEAAgaAECJagmKiEAAIIIBCsAMESrBT1EEAAAQSCEiBYgmKiEgIIIIBAsAIES7BS1EMAAQQQCEqAYAmKiUoIIIAAAsEKECzBSlEPAQQQQCAoAYIlKCYqIYAAAggEK0CwBCtFPQQQQACBoAQIlqCYqIQAAgggEKwAwRKsFPUQQAABBIISSAyqVj9Wam1tldTU1H58BxaNAAIIINAfAm1tbZKWltZj0bRYepAwAQEEEECgLwIES1/0mBcBBBBAoIcAwdKDhAkIIIAAAn0RIFj6ose8CCCAAAI9BAiWHiRMQAABBBDoiwDB0hc95kUAAQQQ6CHgGizHjh2TJUuWyPjx42XYsGFy+umny7333itKKXsBenjp0qUyduxYs05BQYHs3bvXLmcAAQQQQCA+BVyD5be//a2sWLFC/vCHP8iePXtEjz/44IPy+OOP20p6fPny5bJy5UrZvn27nHjiiVJYWCjt7e12HQYQQAABBOJPIMFoeXzTDPn/2//Tn/5UMjMzZdWqVbZIcXGx2TJZu3at2XIZN26c3HbbbfLLX/7SrKMfdNTzrFmzRq666ip7vt4GrAdreECyNyGmI4AAApEt0NvnuGuL5cILL5Tq6mr55JNPzK1677335O2335bp06eb4/v27ZOmpibRp7+sTj99OWXKFKmpqbEmOV47OjpEr0TX3lGBEQQQQACBmBBw/UmXu+66ywyA3NxcOeGEE0Rfc7n//vtlzpw55kbrUNGdbqF07fS4VdZ1uh6uqKiQe+65p/tkxhFAAAEEYkzAtcWyceNGWbdunaxfv17effddefbZZ+V3v/ud+Rrq9peXl4s+7WX1DQ0NoS6K+RBAAAEEIljAtcVy++23i261WNdKzj77bPn888/NVsfcuXMlKyvL3KTm5mbzrjBr+/T4OeecY406XlNSUkT3dAgggAACsS3g2mL5+uuvZcgQZ5E+JXb8+HFTQ9+GrMNFX4exOn3tRN8dlp+fb03iFQEEEEAgDgVcWyxXXHGFeU0lJydHzjrrLPnnP/8pDz/8sMybN88kSkhIkMWLF8t9990nEyZMMJ930c+96DvFZs6cGYeMbDICCCCAgCXgGiz6eRUdFAsXLpQDBw6YgXHDDTeYD0RaM95xxx1y+PBhWbBggbS0tMi0adNk06ZNMnToUKsKrwgggAACcSjg+hzLQDj0dv/zQLw374EAAggg0HeB3j7HnRdS+v4+LAEBBBBAIM4FCJY4PwDYfAQQQCDcAgRLuEVZHgIIIBDnAgRLnB8AbD4CCCAQbgGCJdyiLA8BBBCIcwGCJc4PADYfAQQQCLcAwRJuUZaHAAIIxLmA6wOSA2Fi/RkYfR80HQIIIIBA9AlYn9/W57m1BYMWLAcPHjTXITs721oXXhFAAAEEolBAf57rv8lldYP25L3+QcvGxkYZOXKk6JXSAaN/Sj81NdVaN17DJKC/VeAbJkyXxeDrghLGSfiGEdNlUX3x1S0V/fmtfyey6w8XD1qLRa/EySefbG6m/lFL3elQIVhMin75B99+YbUXiq9N0S8D+PYLq73QUH27tlSshXHx3pLgFQEEEEAgLAIES1gYWQgCCCCAgCVwwt1GZ40M5qv+Q2I//OEPJTFx0M7ODebm9/t749u/xPji278C/bv0cB+/g3bxvn+ZWDoCCCCAwGAJcCpssOR5XwQQQCBGBQiWGN2xbBYCCCAwWAIEy2DJ874IIIBAjAoQLDG6Y9ksBBBAYLAECJbBkud9EUAAgRgVGPRgeeKJJ+TUU0+VoUOHypQpU+Sdd96JUer+3ayKigo5//zzzZ/IGTNmjMycOVPq6uocb9re3i4lJSWSkZEhI0aMkOLiYmlubnbUYSSwwLJly0T/WsTixYvtytjaFCEPfPHFF3L11Vebx+ewYcPk7LPPlp07d9rL0z8fsnTpUhk7dqzo8oKCAtm7d69dzkDvAseOHZMlS5bI+PHjTbvTTz9d7r33Xun645Fh9TUWNmjdhg0bVHJysvrTn/6kPvroI3X99der9PR0ZXzYDdo6ResbFxYWqtWrV6sPP/xQ7dq1S/3kJz9ROTk56tChQ/Ym3Xjjjcr4zTBVXV2tjP+waurUqerCCy+0yxkILGB88VHGFyE1adIkdeutt9ozYGtThDTwv//9T51yyinq2muvVdu3b1efffaZ2rx5s/r000/t5RmBroyfD1Evvviieu+999TPfvYzZXxQqiNHjth1GHAXuP/++5XxhVK98sorat++faqyslIZXy7VY489Zs8QTl+dWIPWXXDBBcr4Bm2/v5GqyvgxM2V8+7anMRCawIEDB5Tx/UVt3brVXEBLS4tKSkoyDyhriXv27DHr1NTUWJN49RAwfmxPTZgwQb322mvqBz/4gR0s2HqgBVl05513qmnTpvVa2/jRWpWVlaUeeughu452T0lJUc8995w9jQF3gcsvv1zNmzfPUVhUVKTmzJljTgu376CdCuvs7JTa2lqzOWs14PQPU+rmrfFBZ03iNUSB1tZWc87Ro0ebr9r66NGjDu/c3FwxWjV4B2msTyMa/0EdhnpWbIME9Kj28ssvy3nnnSezZ88WfSr33HPPlWeeecaew/iWLU1NTQ57/eOH+vQ5nxc2U68DxpkJMc5UyCeffGLWMVp88vbbb8v06dPN8XD7Dtrvp3z55Zeiz/tlZmY6MPT4xx9/7JjGiD8B/ScJ9Pn/iy66SCZOnGjOrP9TGqcdxTjV6FiY9tZldN4Cxmlbeffdd2XHjh09KmLbg8T3BOPUl6xYsULKysrkV7/6lel8yy23mMfs3Llz7WPU7fOC4zcw91133SX65/H1l0n98y36s9c4PSZGi8Wc2TIMl++gBUtgCmqEKqC/WRvXWsxvJKEug/m+EdB/J8i4niLGKTDzJpNvShgKl4D+MqRbLA888IC5SN1i0cfwypUrRQcLXd8ENm7cKOvWrZP169fLWWedJcZ1WPPLp/47Kv3hO2inwk466SQzObvflaTHjXOpfVOM47lvvvlmMS7QyZtvvmn/vRvNoU316UfjvLRDB28Hh+uIPtVlXLOSyZMnmz+Sqn8o1bh2JcuXLzfH9bc8bF3pgp6o7/Q688wzHfXPOOMMqa+vN6dZnwl8XjiIgh65/fbbRbdarrrqKvNuu1/84hdSWloq+m5S3YXbd9CCRZ+WycvLM8/7WTr6W4s+D5ifn29N4jVIAeMKnOhQeeGFF+SNN94wbyvsOqu2Ni7eO7z17cj6Py7eXaV6Dl922WXywQcfmN/y9Dc93etv1/o0gjWMbU83P1P0advut8fr6wHGnWLmYvRtsvrDT38+WJ0+tWPcQcbxa4F4vH799deOv/Coq+pTYvozV3dh93XcJjDAI/p2Y31Xx5o1a9Tu3bvVggULzNuNjfN9A7wm0f92N910k3kr5pYtW9T+/fvt3jig7I3Tt8TqW5CN4DFvNzYCRemezr9A17vC9NzY+jfsOoe+jdtoCSp9W6zxbIoyTtuo4cOHq7Vr19rV9O2w+nGEl156Sb3//vtqxowZ3G5s63gPGKe71Le//W37duPnn39eGWeN1B133GHPGE7fQb3dWG/R448/bn7Y6edZ9O3H27ZtszeUgeAFjC8d5q3D3V/1sy1Wp+/3X7hwoRo1apT5n3bWrFlmAFnlvAYv0D1YsA3erreaVVVVyrjZxPyyaVxkVk8//bSjqvHtWhkP+Snj1KNZx2hJKqOV46jDiLuA0bozb4/XXyyNh9HVaaedpn7961+rjo4Oe4Zw+vL3WHQ7kA4BBBBAIGwCg3aNJWxbwIIQQAABBCJKgGCJqN3ByiCAAALRL0CwRP8+ZAsQQACBiBIgWCJqd7AyCCCAQPQLECzRvw/ZAgQQQCCiBAiWiNodrAwCCCAQ/QL/B4hdO4LN/5FUAAAAAElFTkSuQmCC\" /></p>","metadata":{}},{"cell_type":"markdown","source":"### The Action Space\n\nAs described in the [Pong](https://pettingzoo.farama.org/environments/atari/pong/) page, action is `Discrete(6)`, so:\n- Action shape is _(1,)_\n- Action values are in range [0,5]","metadata":{}},{"cell_type":"markdown","source":"## Environment Setup and Preprocessing","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport gymnasium as gym\nimport ale_py\nfrom datetime import datetime\nimport os\nimport sys\nimport yaml\nimport wandb\nfrom wandb.integration.sb3 import WandbCallback\n\nimport supersuit as ss\nfrom pettingzoo.atari import pong_v3\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.callbacks import EvalCallback, CallbackList\nfrom stable_baselines3.common.evaluation import evaluate_policy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T01:32:26.331934Z","iopub.execute_input":"2025-12-15T01:32:26.332118Z","iopub.status.idle":"2025-12-15T01:32:53.200710Z","shell.execute_reply.started":"2025-12-15T01:32:26.332094Z","shell.execute_reply":"2025-12-15T01:32:53.199952Z"}},"outputs":[{"name":"stderr","text":"2025-12-15 01:32:35.741181: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765762356.118529      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765762356.294723      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  from pkg_resources import resource_stream, resource_exists\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class PongWrapper(gym.Wrapper):\n    \"\"\"\n    Wrapper for the environment using the supersuit library.\n    \"\"\"\n    def __init__(self, env, frame_stack=4):\n        env = ss.color_reduction_v0(env, mode=\"B\")\n        env = ss.resize_v1(env, x_size=84, y_size=84)\n        env = ss.frame_stack_v1(env, frame_stack, stack_dim=0)\n        env = ss.dtype_v0(env, dtype=np.float32)\n        env = ss.normalize_obs_v0(env, env_min=0, env_max=1)\n        env = ss.reshape_v0(env, (frame_stack, 84, 84))\n        \n        super().__init__(env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T01:32:53.201370Z","iopub.execute_input":"2025-12-15T01:32:53.201954Z","iopub.status.idle":"2025-12-15T01:32:53.207055Z","shell.execute_reply.started":"2025-12-15T01:32:53.201933Z","shell.execute_reply":"2025-12-15T01:32:53.206264Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Create training environment for single-agent Pong\ndef create_single_agent_env(n_envs=4, frame_stack=4):\n    \"\"\"Create vectorized environment for single-agent training\"\"\"\n    env = make_vec_env(\n        \"PongNoFrameskip-v4\",\n        n_envs=n_envs,\n        wrapper_class=PongWrapper,\n        wrapper_kwargs={\"frame_stack\": frame_stack},\n        env_kwargs={\"frameskip\": 4}\n    )\n    return env\n\n# Test environment\ntrain_env = create_single_agent_env(n_envs=4)\nprint(\"Observation space:\", train_env.observation_space)\nprint(\"Action space:\", train_env.action_space)\nprint(\"Number of actions:\", train_env.action_space.n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T03:35:31.394859Z","iopub.execute_input":"2025-12-15T03:35:31.395503Z","iopub.status.idle":"2025-12-15T03:35:32.016811Z","shell.execute_reply.started":"2025-12-15T03:35:31.395479Z","shell.execute_reply":"2025-12-15T03:35:32.016032Z"}},"outputs":[{"name":"stdout","text":"Observation space: Box(0.0, 1.0, (4, 84, 84), float32)\nAction space: Discrete(6)\nNumber of actions: 6\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**We choose PPO (Proximal Policy Optimization) because:**\n- It is the most stable on Atari games.\n- It works well with high-dimensional visual inputs.\n- It is widely used in the literature for Pong.\n- SB3 provides a strong implementation with CNN policies.","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"# Define parameter grid for tuning\nparam_grid = [\n    {\n        \"learning_rate\": 2.5e-4,\n        \"n_steps\": 2048,\n        \"batch_size\": 64,\n        \"gamma\": 0.99,\n        \"clip_range\": 0.2,\n    },\n    {\n        \"learning_rate\": 1e-3,\n        \"n_steps\": 1024,\n        \"batch_size\": 128,\n        \"gamma\": 0.95,\n        \"clip_range\": 0.1,\n    },\n    {\n        \"learning_rate\": 5e-4,\n        \"n_steps\": 1024,\n        \"batch_size\": 256,\n        \"gamma\": 0.99,\n        \"clip_range\": 0.3,\n    },\n]\n\ndef tune_parameters(params, trial_name):\n    \"\"\"Train and evaluate with given parameters\"\"\"\n    print(f\"\\nTrial: {trial_name}\")\n    print(f\"Parameters: {params}\")\n    \n    # Create environment\n    env = create_single_agent_env(n_envs=2)\n    \n    # Create model - IMPORTANT: Add normalize_images=False for pre-normalized images\n    model = PPO(\n        \"CnnPolicy\",\n        env,\n        learning_rate=params[\"learning_rate\"],\n        n_steps=params[\"n_steps\"],\n        batch_size=params[\"batch_size\"],\n        n_epochs=4,\n        gamma=params[\"gamma\"],\n        clip_range=params[\"clip_range\"],\n        ent_coef=0.01,\n        verbose=0,\n        policy_kwargs={\"normalize_images\": False}  # ADD THIS LINE\n    )\n    \n    # Train for shorter duration for tuning\n    model.learn(total_timesteps=200000)\n    \n    # Evaluate\n    eval_env = create_single_agent_env(n_envs=1)\n    mean_reward, std_reward = evaluate_policy(\n        model, \n        eval_env, \n        n_eval_episodes=10,\n        deterministic=True\n    )\n    \n    print(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n    \n    env.close()\n    eval_env.close()\n    \n    return mean_reward, params\n\n# Run hyperparameter tuning\nresults = []\nfor i, params in enumerate(param_grid):\n    reward, best_params = tune_parameters(params, f\"Trial_{i+1}\")\n    results.append((reward, best_params))\n\n# Select best parameters\nbest_reward, best_params = max(results, key=lambda x: x[0])\nprint(f\"\\nBest parameters: {best_params}\")\nprint(f\"Best reward: {best_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T02:40:20.210178Z","iopub.execute_input":"2025-12-12T02:40:20.210806Z","iopub.status.idle":"2025-12-12T03:06:25.044413Z","shell.execute_reply.started":"2025-12-12T02:40:20.210785Z","shell.execute_reply":"2025-12-12T03:06:25.043634Z"}},"outputs":[{"name":"stdout","text":"\nTrial: Trial_1\nParameters: {'learning_rate': 0.00025, 'n_steps': 2048, 'batch_size': 64, 'gamma': 0.99, 'clip_range': 0.2}\nMean reward: -10.20 ± 3.43\n\nTrial: Trial_2\nParameters: {'learning_rate': 0.001, 'n_steps': 1024, 'batch_size': 128, 'gamma': 0.95, 'clip_range': 0.1}\nMean reward: -15.40 ± 2.46\n\nTrial: Trial_3\nParameters: {'learning_rate': 0.0005, 'n_steps': 1024, 'batch_size': 256, 'gamma': 0.99, 'clip_range': 0.3}\nMean reward: -17.40 ± 2.58\n\nBest parameters: {'learning_rate': 0.00025, 'n_steps': 2048, 'batch_size': 64, 'gamma': 0.99, 'clip_range': 0.2}\nBest reward: -10.20\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"best_params = {\n        \"learning_rate\": 2.5e-4,\n        \"n_steps\": 2048,\n        \"batch_size\": 64,\n        \"gamma\": 0.99,\n        \"clip_range\": 0.2,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T01:37:11.921639Z","iopub.execute_input":"2025-12-15T01:37:11.921914Z","iopub.status.idle":"2025-12-15T01:37:11.926165Z","shell.execute_reply.started":"2025-12-15T01:37:11.921894Z","shell.execute_reply":"2025-12-15T01:37:11.925471Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize wandb\nwandb.init(\n    project=\"pml-pong-tournament\",\n    config=best_params,\n    name=\"ppo-pong-final\",\n    sync_tensorboard=False,\n    save_code=False,\n    mode=\"disabled\"\n)\n\n# Create final training environment\nfinal_env = create_single_agent_env(n_envs=8)\n\n# Create PPO model with best parameters - ADD normalize_images=False\nmodel = PPO(\n    \"CnnPolicy\",\n    final_env,\n    learning_rate=best_params[\"learning_rate\"],\n    n_steps=best_params[\"n_steps\"],\n    batch_size=best_params[\"batch_size\"],\n    n_epochs=4,\n    gamma=best_params[\"gamma\"],\n    clip_range=best_params[\"clip_range\"],\n    ent_coef=0.01,\n    verbose=1,\n    tensorboard_log=\"runs/ppo_pong\",\n    policy_kwargs={\"normalize_images\": False}  # ADD THIS\n)\n\n# Create evaluation callback\neval_env = create_single_agent_env(n_envs=1)\neval_callback = EvalCallback(\n    eval_env,\n    best_model_save_path=\"./models/best/\",\n    log_path=\"./logs/\",\n    eval_freq=10000,\n    deterministic=True,\n)\n\n# Train\nprint(\"Starting final training...\")\nmodel.learn(\n    total_timesteps=2000000,\n    callback=[eval_callback],\n    progress_bar=True,\n    tb_log_name=\"ppo_final\"\n)\n\n# Final evaluation\nmean_reward, std_reward = evaluate_policy(\n    model,\n    create_single_agent_env(n_envs=1),\n    n_eval_episodes=20,\n    deterministic=True\n)\n\nprint(f\"\\nFinal single-player performance:\")\nprint(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\nprint(f\"Win rate: {(mean_reward + 21) / 42 * 100:.1f}%\")\n\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T01:37:26.558321Z","iopub.execute_input":"2025-12-15T01:37:26.559099Z","iopub.status.idle":"2025-12-15T03:00:38.163075Z","shell.execute_reply.started":"2025-12-15T01:37:26.559063Z","shell.execute_reply":"2025-12-15T03:00:38.162298Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/notebook/notebookapp.py:188: DeprecationWarning: invalid escape sequence '\\/'\n  print(\"\"\"\n/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n  return LooseVersion(v) >= LooseVersion(check)\n/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_pydrive.py:21: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n  import imp  # pylint: disable=deprecated-module\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py:202: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n  settings = self._wl.settings.copy()\n","output_type":"stream"},{"name":"stdout","text":"Using cuda device\nStarting final training...\nLogging to runs/ppo_pong/ppo_final_1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d3759c0d53c44c89f4ec38238800cef"}},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 879      |\n|    ep_rew_mean     | -20.8    |\n| time/              |          |\n|    fps             | 639      |\n|    iterations      | 1        |\n|    time_elapsed    | 25       |\n|    total_timesteps | 16384    |\n---------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 896          |\n|    ep_rew_mean          | -20.6        |\n| time/                   |              |\n|    fps                  | 565          |\n|    iterations           | 2            |\n|    time_elapsed         | 57           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0054899314 |\n|    clip_fraction        | 0.0305       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.79        |\n|    explained_variance   | -7.2e-05     |\n|    learning_rate        | 0.00025      |\n|    loss                 | 0.0186       |\n|    n_updates            | 4            |\n|    policy_gradient_loss | -0.00215     |\n|    value_loss           | 0.0442       |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 928          |\n|    ep_rew_mean          | -20.3        |\n| time/                   |              |\n|    fps                  | 548          |\n|    iterations           | 3            |\n|    time_elapsed         | 89           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0063460413 |\n|    clip_fraction        | 0.0369       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.78        |\n|    explained_variance   | 0.545        |\n|    learning_rate        | 0.00025      |\n|    loss                 | -0.00164     |\n|    n_updates            | 8            |\n|    policy_gradient_loss | -0.00447     |\n|    value_loss           | 0.0569       |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 938         |\n|    ep_rew_mean          | -20.3       |\n| time/                   |             |\n|    fps                  | 540         |\n|    iterations           | 4           |\n|    time_elapsed         | 121         |\n|    total_timesteps      | 65536       |\n| train/                  |             |\n|    approx_kl            | 0.007061811 |\n|    clip_fraction        | 0.0587      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.77       |\n|    explained_variance   | 0.544       |\n|    learning_rate        | 0.00025     |\n|    loss                 | 0.00125     |\n|    n_updates            | 12          |\n|    policy_gradient_loss | -0.00778    |\n|    value_loss           | 0.0662      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=80000, episode_reward=-20.20 +/- 0.40\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=-20.20 +/- 0.40\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 942.80 +/- 37.92\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 942.80 +/- 37.92\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 943         |\n|    mean_reward          | -20.2       |\n| time/                   |             |\n|    total_timesteps      | 80000       |\n| train/                  |             |\n|    approx_kl            | 0.008662956 |\n|    clip_fraction        | 0.078       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.76       |\n|    explained_variance   | 0.62        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0105     |\n|    n_updates            | 16          |\n|    policy_gradient_loss | -0.0113     |\n|    value_loss           | 0.0554      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 956      |\n|    ep_rew_mean     | -20.2    |\n| time/              |          |\n|    fps             | 500      |\n|    iterations      | 5        |\n|    time_elapsed    | 163      |\n|    total_timesteps | 81920    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 986         |\n|    ep_rew_mean          | -20.1       |\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 6           |\n|    time_elapsed         | 195         |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.010045486 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.75       |\n|    explained_variance   | 0.602       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.00683    |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0153     |\n|    value_loss           | 0.0682      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.02e+03    |\n|    ep_rew_mean          | -19.9       |\n| time/                   |             |\n|    fps                  | 505         |\n|    iterations           | 7           |\n|    time_elapsed         | 226         |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.010764475 |\n|    clip_fraction        | 0.114       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.74       |\n|    explained_variance   | 0.53        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0184     |\n|    n_updates            | 24          |\n|    policy_gradient_loss | -0.0177     |\n|    value_loss           | 0.0807      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.08e+03    |\n|    ep_rew_mean          | -19.7       |\n| time/                   |             |\n|    fps                  | 507         |\n|    iterations           | 8           |\n|    time_elapsed         | 258         |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.011830838 |\n|    clip_fraction        | 0.136       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.73       |\n|    explained_variance   | 0.518       |\n|    learning_rate        | 0.00025     |\n|    loss                 | 0.00299     |\n|    n_updates            | 28          |\n|    policy_gradient_loss | -0.0209     |\n|    value_loss           | 0.0775      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.13e+03    |\n|    ep_rew_mean          | -19.5       |\n| time/                   |             |\n|    fps                  | 508         |\n|    iterations           | 9           |\n|    time_elapsed         | 289         |\n|    total_timesteps      | 147456      |\n| train/                  |             |\n|    approx_kl            | 0.013763504 |\n|    clip_fraction        | 0.162       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.7        |\n|    explained_variance   | 0.509       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.00799    |\n|    n_updates            | 32          |\n|    policy_gradient_loss | -0.0242     |\n|    value_loss           | 0.0843      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=160000, episode_reward=-16.20 +/- 1.72\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=160000, episode_reward=-16.20 +/- 1.72\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 2157.20 +/- 190.83\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2157.20 +/- 190.83\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 2.16e+03    |\n|    mean_reward          | -16.2       |\n| time/                   |             |\n|    total_timesteps      | 160000      |\n| train/                  |             |\n|    approx_kl            | 0.015431469 |\n|    clip_fraction        | 0.178       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.457       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0425     |\n|    n_updates            | 36          |\n|    policy_gradient_loss | -0.025      |\n|    value_loss           | 0.0706      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 1.19e+03 |\n|    ep_rew_mean     | -19.4    |\n| time/              |          |\n|    fps             | 474      |\n|    iterations      | 10       |\n|    time_elapsed    | 345      |\n|    total_timesteps | 163840   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.28e+03    |\n|    ep_rew_mean          | -19         |\n| time/                   |             |\n|    fps                  | 478         |\n|    iterations           | 11          |\n|    time_elapsed         | 376         |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.015789058 |\n|    clip_fraction        | 0.189       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.68       |\n|    explained_variance   | 0.492       |\n|    learning_rate        | 0.00025     |\n|    loss                 | 0.0025      |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0264     |\n|    value_loss           | 0.0584      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.34e+03    |\n|    ep_rew_mean          | -18.8       |\n| time/                   |             |\n|    fps                  | 481         |\n|    iterations           | 12          |\n|    time_elapsed         | 408         |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.017057318 |\n|    clip_fraction        | 0.197       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.66       |\n|    explained_variance   | 0.458       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0414     |\n|    n_updates            | 44          |\n|    policy_gradient_loss | -0.0276     |\n|    value_loss           | 0.0665      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.43e+03    |\n|    ep_rew_mean          | -18.5       |\n| time/                   |             |\n|    fps                  | 484         |\n|    iterations           | 13          |\n|    time_elapsed         | 439         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.019042812 |\n|    clip_fraction        | 0.216       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.64       |\n|    explained_variance   | 0.52        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0582     |\n|    n_updates            | 48          |\n|    policy_gradient_loss | -0.0303     |\n|    value_loss           | 0.0646      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.49e+03    |\n|    ep_rew_mean          | -18.3       |\n| time/                   |             |\n|    fps                  | 487         |\n|    iterations           | 14          |\n|    time_elapsed         | 470         |\n|    total_timesteps      | 229376      |\n| train/                  |             |\n|    approx_kl            | 0.019953854 |\n|    clip_fraction        | 0.228       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.63       |\n|    explained_variance   | 0.462       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0334     |\n|    n_updates            | 52          |\n|    policy_gradient_loss | -0.033      |\n|    value_loss           | 0.0607      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=240000, episode_reward=-15.60 +/- 1.20\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=240000, episode_reward=-15.60 +/- 1.20\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3140.80 +/- 400.93\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3140.80 +/- 400.93\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.14e+03    |\n|    mean_reward          | -15.6       |\n| time/                   |             |\n|    total_timesteps      | 240000      |\n| train/                  |             |\n|    approx_kl            | 0.021775484 |\n|    clip_fraction        | 0.242       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.61       |\n|    explained_variance   | 0.446       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0549     |\n|    n_updates            | 56          |\n|    policy_gradient_loss | -0.0339     |\n|    value_loss           | 0.0623      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 1.59e+03 |\n|    ep_rew_mean     | -18      |\n| time/              |          |\n|    fps             | 456      |\n|    iterations      | 15       |\n|    time_elapsed    | 538      |\n|    total_timesteps | 245760   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.65e+03    |\n|    ep_rew_mean          | -17.9       |\n| time/                   |             |\n|    fps                  | 460         |\n|    iterations           | 16          |\n|    time_elapsed         | 569         |\n|    total_timesteps      | 262144      |\n| train/                  |             |\n|    approx_kl            | 0.022862291 |\n|    clip_fraction        | 0.244       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.59       |\n|    explained_variance   | 0.456       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0276     |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.034      |\n|    value_loss           | 0.0618      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.73e+03    |\n|    ep_rew_mean          | -17.7       |\n| time/                   |             |\n|    fps                  | 463         |\n|    iterations           | 17          |\n|    time_elapsed         | 601         |\n|    total_timesteps      | 278528      |\n| train/                  |             |\n|    approx_kl            | 0.025287598 |\n|    clip_fraction        | 0.262       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.57       |\n|    explained_variance   | 0.367       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.093      |\n|    n_updates            | 64          |\n|    policy_gradient_loss | -0.035      |\n|    value_loss           | 0.0612      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.81e+03    |\n|    ep_rew_mean          | -17.4       |\n| time/                   |             |\n|    fps                  | 466         |\n|    iterations           | 18          |\n|    time_elapsed         | 632         |\n|    total_timesteps      | 294912      |\n| train/                  |             |\n|    approx_kl            | 0.025381753 |\n|    clip_fraction        | 0.26        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.55       |\n|    explained_variance   | 0.433       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.053      |\n|    n_updates            | 68          |\n|    policy_gradient_loss | -0.0359     |\n|    value_loss           | 0.0571      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.9e+03     |\n|    ep_rew_mean          | -17.1       |\n| time/                   |             |\n|    fps                  | 468         |\n|    iterations           | 19          |\n|    time_elapsed         | 664         |\n|    total_timesteps      | 311296      |\n| train/                  |             |\n|    approx_kl            | 0.027642477 |\n|    clip_fraction        | 0.28        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.54       |\n|    explained_variance   | 0.44        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0537     |\n|    n_updates            | 72          |\n|    policy_gradient_loss | -0.037      |\n|    value_loss           | 0.0574      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=320000, episode_reward=-13.60 +/- 2.87\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=320000, episode_reward=-13.60 +/- 2.87\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3118.60 +/- 452.37\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3118.60 +/- 452.37\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.12e+03    |\n|    mean_reward          | -13.6       |\n| time/                   |             |\n|    total_timesteps      | 320000      |\n| train/                  |             |\n|    approx_kl            | 0.028557368 |\n|    clip_fraction        | 0.273       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.53       |\n|    explained_variance   | 0.47        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0471     |\n|    n_updates            | 76          |\n|    policy_gradient_loss | -0.0355     |\n|    value_loss           | 0.0543      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 1.97e+03 |\n|    ep_rew_mean     | -16.9    |\n| time/              |          |\n|    fps             | 448      |\n|    iterations      | 20       |\n|    time_elapsed    | 731      |\n|    total_timesteps | 327680   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.02e+03    |\n|    ep_rew_mean          | -16.8       |\n| time/                   |             |\n|    fps                  | 451         |\n|    iterations           | 21          |\n|    time_elapsed         | 762         |\n|    total_timesteps      | 344064      |\n| train/                  |             |\n|    approx_kl            | 0.028820297 |\n|    clip_fraction        | 0.276       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.52       |\n|    explained_variance   | 0.481       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0557     |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.038      |\n|    value_loss           | 0.0541      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.09e+03    |\n|    ep_rew_mean          | -16.5       |\n| time/                   |             |\n|    fps                  | 454         |\n|    iterations           | 22          |\n|    time_elapsed         | 793         |\n|    total_timesteps      | 360448      |\n| train/                  |             |\n|    approx_kl            | 0.029639047 |\n|    clip_fraction        | 0.28        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.5        |\n|    explained_variance   | 0.436       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.06       |\n|    n_updates            | 84          |\n|    policy_gradient_loss | -0.0398     |\n|    value_loss           | 0.059       |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 2.14e+03  |\n|    ep_rew_mean          | -16.3     |\n| time/                   |           |\n|    fps                  | 457       |\n|    iterations           | 23        |\n|    time_elapsed         | 823       |\n|    total_timesteps      | 376832    |\n| train/                  |           |\n|    approx_kl            | 0.0306126 |\n|    clip_fraction        | 0.288     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.49     |\n|    explained_variance   | 0.435     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0684   |\n|    n_updates            | 88        |\n|    policy_gradient_loss | -0.0406   |\n|    value_loss           | 0.0524    |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.18e+03    |\n|    ep_rew_mean          | -16.2       |\n| time/                   |             |\n|    fps                  | 460         |\n|    iterations           | 24          |\n|    time_elapsed         | 854         |\n|    total_timesteps      | 393216      |\n| train/                  |             |\n|    approx_kl            | 0.031764477 |\n|    clip_fraction        | 0.289       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.49       |\n|    explained_variance   | 0.452       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0726     |\n|    n_updates            | 92          |\n|    policy_gradient_loss | -0.041      |\n|    value_loss           | 0.0535      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=400000, episode_reward=-13.00 +/- 4.05\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=400000, episode_reward=-13.00 +/- 4.05\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3149.60 +/- 321.72\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3149.60 +/- 321.72\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.15e+03   |\n|    mean_reward          | -13        |\n| time/                   |            |\n|    total_timesteps      | 400000     |\n| train/                  |            |\n|    approx_kl            | 0.03248568 |\n|    clip_fraction        | 0.3        |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.46      |\n|    explained_variance   | 0.481      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0734    |\n|    n_updates            | 96         |\n|    policy_gradient_loss | -0.0424    |\n|    value_loss           | 0.0531     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.28e+03 |\n|    ep_rew_mean     | -15.8    |\n| time/              |          |\n|    fps             | 444      |\n|    iterations      | 25       |\n|    time_elapsed    | 920      |\n|    total_timesteps | 409600   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.32e+03    |\n|    ep_rew_mean          | -15.7       |\n| time/                   |             |\n|    fps                  | 447         |\n|    iterations           | 26          |\n|    time_elapsed         | 951         |\n|    total_timesteps      | 425984      |\n| train/                  |             |\n|    approx_kl            | 0.033125304 |\n|    clip_fraction        | 0.301       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.46       |\n|    explained_variance   | 0.479       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0278     |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.0421     |\n|    value_loss           | 0.0595      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.36e+03    |\n|    ep_rew_mean          | -15.5       |\n| time/                   |             |\n|    fps                  | 450         |\n|    iterations           | 27          |\n|    time_elapsed         | 982         |\n|    total_timesteps      | 442368      |\n| train/                  |             |\n|    approx_kl            | 0.035851557 |\n|    clip_fraction        | 0.312       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.44       |\n|    explained_variance   | 0.506       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0567     |\n|    n_updates            | 104         |\n|    policy_gradient_loss | -0.0432     |\n|    value_loss           | 0.0566      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.4e+03     |\n|    ep_rew_mean          | -15.4       |\n| time/                   |             |\n|    fps                  | 452         |\n|    iterations           | 28          |\n|    time_elapsed         | 1013        |\n|    total_timesteps      | 458752      |\n| train/                  |             |\n|    approx_kl            | 0.037472658 |\n|    clip_fraction        | 0.315       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.43       |\n|    explained_variance   | 0.501       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0688     |\n|    n_updates            | 108         |\n|    policy_gradient_loss | -0.0438     |\n|    value_loss           | 0.053       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.44e+03    |\n|    ep_rew_mean          | -15.2       |\n| time/                   |             |\n|    fps                  | 454         |\n|    iterations           | 29          |\n|    time_elapsed         | 1044        |\n|    total_timesteps      | 475136      |\n| train/                  |             |\n|    approx_kl            | 0.037072014 |\n|    clip_fraction        | 0.314       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.433       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0624     |\n|    n_updates            | 112         |\n|    policy_gradient_loss | -0.0423     |\n|    value_loss           | 0.0548      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=480000, episode_reward=-8.20 +/- 2.71\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=480000, episode_reward=-8.20 +/- 2.71\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3286.80 +/- 292.38\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3286.80 +/- 292.38\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.29e+03    |\n|    mean_reward          | -8.2        |\n| time/                   |             |\n|    total_timesteps      | 480000      |\n| train/                  |             |\n|    approx_kl            | 0.040580407 |\n|    clip_fraction        | 0.324       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.457       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0562     |\n|    n_updates            | 116         |\n|    policy_gradient_loss | -0.045      |\n|    value_loss           | 0.0618      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.5e+03  |\n|    ep_rew_mean     | -14.7    |\n| time/              |          |\n|    fps             | 441      |\n|    iterations      | 30       |\n|    time_elapsed    | 1112     |\n|    total_timesteps | 491520   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.54e+03    |\n|    ep_rew_mean          | -14.5       |\n| time/                   |             |\n|    fps                  | 444         |\n|    iterations           | 31          |\n|    time_elapsed         | 1142        |\n|    total_timesteps      | 507904      |\n| train/                  |             |\n|    approx_kl            | 0.040414378 |\n|    clip_fraction        | 0.325       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | 0.526       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0926     |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.0436     |\n|    value_loss           | 0.0558      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.57e+03    |\n|    ep_rew_mean          | -14.2       |\n| time/                   |             |\n|    fps                  | 446         |\n|    iterations           | 32          |\n|    time_elapsed         | 1173        |\n|    total_timesteps      | 524288      |\n| train/                  |             |\n|    approx_kl            | 0.043093484 |\n|    clip_fraction        | 0.337       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | 0.519       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0622     |\n|    n_updates            | 124         |\n|    policy_gradient_loss | -0.0448     |\n|    value_loss           | 0.0556      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 2.63e+03   |\n|    ep_rew_mean          | -13.8      |\n| time/                   |            |\n|    fps                  | 448        |\n|    iterations           | 33         |\n|    time_elapsed         | 1204       |\n|    total_timesteps      | 540672     |\n| train/                  |            |\n|    approx_kl            | 0.04557529 |\n|    clip_fraction        | 0.335      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.36      |\n|    explained_variance   | 0.531      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0684    |\n|    n_updates            | 128        |\n|    policy_gradient_loss | -0.0439    |\n|    value_loss           | 0.0566     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.65e+03    |\n|    ep_rew_mean          | -13.6       |\n| time/                   |             |\n|    fps                  | 450         |\n|    iterations           | 34          |\n|    time_elapsed         | 1235        |\n|    total_timesteps      | 557056      |\n| train/                  |             |\n|    approx_kl            | 0.043824498 |\n|    clip_fraction        | 0.33        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | 0.519       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0719     |\n|    n_updates            | 132         |\n|    policy_gradient_loss | -0.043      |\n|    value_loss           | 0.0558      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=560000, episode_reward=-8.80 +/- 4.35\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=560000, episode_reward=-8.80 +/- 4.35\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3593.20 +/- 423.99\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3593.20 +/- 423.99\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------------\n| eval/                   |           |\n|    mean_ep_length       | 3.59e+03  |\n|    mean_reward          | -8.8      |\n| time/                   |           |\n|    total_timesteps      | 560000    |\n| train/                  |           |\n|    approx_kl            | 0.0474329 |\n|    clip_fraction        | 0.341     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.3      |\n|    explained_variance   | 0.562     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0596   |\n|    n_updates            | 136       |\n|    policy_gradient_loss | -0.0426   |\n|    value_loss           | 0.0571    |\n---------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.7e+03  |\n|    ep_rew_mean     | -13.2    |\n| time/              |          |\n|    fps             | 438      |\n|    iterations      | 35       |\n|    time_elapsed    | 1306     |\n|    total_timesteps | 573440   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.75e+03    |\n|    ep_rew_mean          | -13         |\n| time/                   |             |\n|    fps                  | 441         |\n|    iterations           | 36          |\n|    time_elapsed         | 1337        |\n|    total_timesteps      | 589824      |\n| train/                  |             |\n|    approx_kl            | 0.050209124 |\n|    clip_fraction        | 0.357       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 0.493       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0657     |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.046      |\n|    value_loss           | 0.0552      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.77e+03    |\n|    ep_rew_mean          | -12.7       |\n| time/                   |             |\n|    fps                  | 443         |\n|    iterations           | 37          |\n|    time_elapsed         | 1368        |\n|    total_timesteps      | 606208      |\n| train/                  |             |\n|    approx_kl            | 0.050100237 |\n|    clip_fraction        | 0.349       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 0.527       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.056      |\n|    n_updates            | 144         |\n|    policy_gradient_loss | -0.0458     |\n|    value_loss           | 0.0558      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.79e+03    |\n|    ep_rew_mean          | -12.5       |\n| time/                   |             |\n|    fps                  | 444         |\n|    iterations           | 38          |\n|    time_elapsed         | 1399        |\n|    total_timesteps      | 622592      |\n| train/                  |             |\n|    approx_kl            | 0.051905546 |\n|    clip_fraction        | 0.354       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.542       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0903     |\n|    n_updates            | 148         |\n|    policy_gradient_loss | -0.0455     |\n|    value_loss           | 0.0581      |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 2.84e+03  |\n|    ep_rew_mean          | -12.2     |\n| time/                   |           |\n|    fps                  | 446       |\n|    iterations           | 39        |\n|    time_elapsed         | 1430      |\n|    total_timesteps      | 638976    |\n| train/                  |           |\n|    approx_kl            | 0.0496799 |\n|    clip_fraction        | 0.351     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.31     |\n|    explained_variance   | 0.531     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0698   |\n|    n_updates            | 152       |\n|    policy_gradient_loss | -0.0459   |\n|    value_loss           | 0.0559    |\n---------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=640000, episode_reward=-3.80 +/- 5.91\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=640000, episode_reward=-3.80 +/- 5.91\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3957.40 +/- 231.00\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3957.40 +/- 231.00\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.96e+03   |\n|    mean_reward          | -3.8       |\n| time/                   |            |\n|    total_timesteps      | 640000     |\n| train/                  |            |\n|    approx_kl            | 0.05073359 |\n|    clip_fraction        | 0.347      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.31      |\n|    explained_variance   | 0.595      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0407    |\n|    n_updates            | 156        |\n|    policy_gradient_loss | -0.0452    |\n|    value_loss           | 0.053      |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.86e+03 |\n|    ep_rew_mean     | -12      |\n| time/              |          |\n|    fps             | 435      |\n|    iterations      | 40       |\n|    time_elapsed    | 1505     |\n|    total_timesteps | 655360   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.89e+03    |\n|    ep_rew_mean          | -11.8       |\n| time/                   |             |\n|    fps                  | 437         |\n|    iterations           | 41          |\n|    time_elapsed         | 1536        |\n|    total_timesteps      | 671744      |\n| train/                  |             |\n|    approx_kl            | 0.052175652 |\n|    clip_fraction        | 0.353       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.514       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0903     |\n|    n_updates            | 160         |\n|    policy_gradient_loss | -0.0469     |\n|    value_loss           | 0.0556      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.92e+03    |\n|    ep_rew_mean          | -11.5       |\n| time/                   |             |\n|    fps                  | 438         |\n|    iterations           | 42          |\n|    time_elapsed         | 1567        |\n|    total_timesteps      | 688128      |\n| train/                  |             |\n|    approx_kl            | 0.052804142 |\n|    clip_fraction        | 0.353       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.538       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0873     |\n|    n_updates            | 164         |\n|    policy_gradient_loss | -0.047      |\n|    value_loss           | 0.0519      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 2.96e+03    |\n|    ep_rew_mean          | -11.3       |\n| time/                   |             |\n|    fps                  | 440         |\n|    iterations           | 43          |\n|    time_elapsed         | 1599        |\n|    total_timesteps      | 704512      |\n| train/                  |             |\n|    approx_kl            | 0.052679148 |\n|    clip_fraction        | 0.35        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | 0.526       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0765     |\n|    n_updates            | 168         |\n|    policy_gradient_loss | -0.0456     |\n|    value_loss           | 0.0545      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=720000, episode_reward=-4.40 +/- 4.18\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=720000, episode_reward=-4.40 +/- 4.18\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4429.20 +/- 249.40\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4429.20 +/- 249.40\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4.43e+03   |\n|    mean_reward          | -4.4       |\n| time/                   |            |\n|    total_timesteps      | 720000     |\n| train/                  |            |\n|    approx_kl            | 0.05860153 |\n|    clip_fraction        | 0.361      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.27      |\n|    explained_variance   | 0.51       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0802    |\n|    n_updates            | 172        |\n|    policy_gradient_loss | -0.0491    |\n|    value_loss           | 0.0539     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 2.98e+03 |\n|    ep_rew_mean     | -11.2    |\n| time/              |          |\n|    fps             | 429      |\n|    iterations      | 44       |\n|    time_elapsed    | 1679     |\n|    total_timesteps | 720896   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.04e+03    |\n|    ep_rew_mean          | -10.9       |\n| time/                   |             |\n|    fps                  | 430         |\n|    iterations           | 45          |\n|    time_elapsed         | 1710        |\n|    total_timesteps      | 737280      |\n| train/                  |             |\n|    approx_kl            | 0.058663383 |\n|    clip_fraction        | 0.36        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.528       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0479     |\n|    n_updates            | 176         |\n|    policy_gradient_loss | -0.0467     |\n|    value_loss           | 0.0594      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.05e+03   |\n|    ep_rew_mean          | -10.8      |\n| time/                   |            |\n|    fps                  | 432        |\n|    iterations           | 46         |\n|    time_elapsed         | 1741       |\n|    total_timesteps      | 753664     |\n| train/                  |            |\n|    approx_kl            | 0.05944508 |\n|    clip_fraction        | 0.364      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.26      |\n|    explained_variance   | 0.556      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0718    |\n|    n_updates            | 180        |\n|    policy_gradient_loss | -0.0479    |\n|    value_loss           | 0.0526     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.1e+03     |\n|    ep_rew_mean          | -10.4       |\n| time/                   |             |\n|    fps                  | 434         |\n|    iterations           | 47          |\n|    time_elapsed         | 1772        |\n|    total_timesteps      | 770048      |\n| train/                  |             |\n|    approx_kl            | 0.061900616 |\n|    clip_fraction        | 0.367       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.506       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0669     |\n|    n_updates            | 184         |\n|    policy_gradient_loss | -0.0472     |\n|    value_loss           | 0.0562      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.12e+03   |\n|    ep_rew_mean          | -10.3      |\n| time/                   |            |\n|    fps                  | 436        |\n|    iterations           | 48         |\n|    time_elapsed         | 1803       |\n|    total_timesteps      | 786432     |\n| train/                  |            |\n|    approx_kl            | 0.06480807 |\n|    clip_fraction        | 0.372      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.24      |\n|    explained_variance   | 0.538      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.047     |\n|    n_updates            | 188        |\n|    policy_gradient_loss | -0.0497    |\n|    value_loss           | 0.0499     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=800000, episode_reward=-4.60 +/- 1.62\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=800000, episode_reward=-4.60 +/- 1.62\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4536.20 +/- 409.56\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4536.20 +/- 409.56\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 4.54e+03    |\n|    mean_reward          | -4.6        |\n| time/                   |             |\n|    total_timesteps      | 800000      |\n| train/                  |             |\n|    approx_kl            | 0.062639795 |\n|    clip_fraction        | 0.371       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | 0.507       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.09       |\n|    n_updates            | 192         |\n|    policy_gradient_loss | -0.0494     |\n|    value_loss           | 0.0544      |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.14e+03 |\n|    ep_rew_mean     | -10.3    |\n| time/              |          |\n|    fps             | 426      |\n|    iterations      | 49       |\n|    time_elapsed    | 1883     |\n|    total_timesteps | 802816   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.15e+03   |\n|    ep_rew_mean          | -10.5      |\n| time/                   |            |\n|    fps                  | 427        |\n|    iterations           | 50         |\n|    time_elapsed         | 1914       |\n|    total_timesteps      | 819200     |\n| train/                  |            |\n|    approx_kl            | 0.06347805 |\n|    clip_fraction        | 0.37       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.25      |\n|    explained_variance   | 0.498      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0848    |\n|    n_updates            | 196        |\n|    policy_gradient_loss | -0.0497    |\n|    value_loss           | 0.0455     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.19e+03    |\n|    ep_rew_mean          | -10.4       |\n| time/                   |             |\n|    fps                  | 429         |\n|    iterations           | 51          |\n|    time_elapsed         | 1944        |\n|    total_timesteps      | 835584      |\n| train/                  |             |\n|    approx_kl            | 0.063010365 |\n|    clip_fraction        | 0.361       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.546       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0566     |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.0496     |\n|    value_loss           | 0.0504      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.2e+03    |\n|    ep_rew_mean          | -10.3      |\n| time/                   |            |\n|    fps                  | 431        |\n|    iterations           | 52         |\n|    time_elapsed         | 1975       |\n|    total_timesteps      | 851968     |\n| train/                  |            |\n|    approx_kl            | 0.06264588 |\n|    clip_fraction        | 0.363      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.27      |\n|    explained_variance   | 0.518      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0815    |\n|    n_updates            | 204        |\n|    policy_gradient_loss | -0.0493    |\n|    value_loss           | 0.0512     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.22e+03   |\n|    ep_rew_mean          | -10.3      |\n| time/                   |            |\n|    fps                  | 432        |\n|    iterations           | 53         |\n|    time_elapsed         | 2006       |\n|    total_timesteps      | 868352     |\n| train/                  |            |\n|    approx_kl            | 0.06454983 |\n|    clip_fraction        | 0.373      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.24      |\n|    explained_variance   | 0.589      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0854    |\n|    n_updates            | 208        |\n|    policy_gradient_loss | -0.0484    |\n|    value_loss           | 0.0494     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=880000, episode_reward=-6.40 +/- 2.80\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=880000, episode_reward=-6.40 +/- 2.80\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4270.20 +/- 460.81\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4270.20 +/- 460.81\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 4.27e+03    |\n|    mean_reward          | -6.4        |\n| time/                   |             |\n|    total_timesteps      | 880000      |\n| train/                  |             |\n|    approx_kl            | 0.070197105 |\n|    clip_fraction        | 0.378       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.502       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0812     |\n|    n_updates            | 212         |\n|    policy_gradient_loss | -0.0513     |\n|    value_loss           | 0.0488      |\n-----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.24e+03 |\n|    ep_rew_mean     | -10.2    |\n| time/              |          |\n|    fps             | 424      |\n|    iterations      | 54       |\n|    time_elapsed    | 2084     |\n|    total_timesteps | 884736   |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.3e+03    |\n|    ep_rew_mean          | -10        |\n| time/                   |            |\n|    fps                  | 426        |\n|    iterations           | 55         |\n|    time_elapsed         | 2115       |\n|    total_timesteps      | 901120     |\n| train/                  |            |\n|    approx_kl            | 0.07124176 |\n|    clip_fraction        | 0.378      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.22      |\n|    explained_variance   | 0.592      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.072     |\n|    n_updates            | 216        |\n|    policy_gradient_loss | -0.0505    |\n|    value_loss           | 0.0487     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.31e+03   |\n|    ep_rew_mean          | -10        |\n| time/                   |            |\n|    fps                  | 427        |\n|    iterations           | 56         |\n|    time_elapsed         | 2145       |\n|    total_timesteps      | 917504     |\n| train/                  |            |\n|    approx_kl            | 0.07331077 |\n|    clip_fraction        | 0.378      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.21      |\n|    explained_variance   | 0.482      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0865    |\n|    n_updates            | 220        |\n|    policy_gradient_loss | -0.0493    |\n|    value_loss           | 0.0526     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.35e+03    |\n|    ep_rew_mean          | -9.83       |\n| time/                   |             |\n|    fps                  | 429         |\n|    iterations           | 57          |\n|    time_elapsed         | 2176        |\n|    total_timesteps      | 933888      |\n| train/                  |             |\n|    approx_kl            | 0.072049335 |\n|    clip_fraction        | 0.383       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | 0.505       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0924     |\n|    n_updates            | 224         |\n|    policy_gradient_loss | -0.0513     |\n|    value_loss           | 0.0538      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.38e+03   |\n|    ep_rew_mean          | -9.65      |\n| time/                   |            |\n|    fps                  | 430        |\n|    iterations           | 58         |\n|    time_elapsed         | 2207       |\n|    total_timesteps      | 950272     |\n| train/                  |            |\n|    approx_kl            | 0.06975812 |\n|    clip_fraction        | 0.381      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.22      |\n|    explained_variance   | 0.519      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0731    |\n|    n_updates            | 228        |\n|    policy_gradient_loss | -0.0503    |\n|    value_loss           | 0.0523     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=960000, episode_reward=1.00 +/- 4.05\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=960000, episode_reward=1.00 +/- 4.05\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4542.00 +/- 313.22\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4542.00 +/- 313.22\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 4.54e+03    |\n|    mean_reward          | 1           |\n| time/                   |             |\n|    total_timesteps      | 960000      |\n| train/                  |             |\n|    approx_kl            | 0.068983346 |\n|    clip_fraction        | 0.367       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | 0.545       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0894     |\n|    n_updates            | 232         |\n|    policy_gradient_loss | -0.0482     |\n|    value_loss           | 0.057       |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.4e+03  |\n|    ep_rew_mean     | -9.56    |\n| time/              |          |\n|    fps             | 422      |\n|    iterations      | 59       |\n|    time_elapsed    | 2287     |\n|    total_timesteps | 966656   |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.42e+03    |\n|    ep_rew_mean          | -9.34       |\n| time/                   |             |\n|    fps                  | 424         |\n|    iterations           | 60          |\n|    time_elapsed         | 2318        |\n|    total_timesteps      | 983040      |\n| train/                  |             |\n|    approx_kl            | 0.076204695 |\n|    clip_fraction        | 0.385       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.19       |\n|    explained_variance   | 0.562       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0688     |\n|    n_updates            | 236         |\n|    policy_gradient_loss | -0.0496     |\n|    value_loss           | 0.0529      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.42e+03    |\n|    ep_rew_mean          | -9.18       |\n| time/                   |             |\n|    fps                  | 425         |\n|    iterations           | 61          |\n|    time_elapsed         | 2348        |\n|    total_timesteps      | 999424      |\n| train/                  |             |\n|    approx_kl            | 0.073309556 |\n|    clip_fraction        | 0.371       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | 0.599       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0576     |\n|    n_updates            | 240         |\n|    policy_gradient_loss | -0.0473     |\n|    value_loss           | 0.055       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.47e+03   |\n|    ep_rew_mean          | -8.8       |\n| time/                   |            |\n|    fps                  | 426        |\n|    iterations           | 62         |\n|    time_elapsed         | 2379       |\n|    total_timesteps      | 1015808    |\n| train/                  |            |\n|    approx_kl            | 0.07850176 |\n|    clip_fraction        | 0.38       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.15      |\n|    explained_variance   | 0.595      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0603    |\n|    n_updates            | 244        |\n|    policy_gradient_loss | -0.0478    |\n|    value_loss           | 0.0578     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.48e+03    |\n|    ep_rew_mean          | -8.61       |\n| time/                   |             |\n|    fps                  | 428         |\n|    iterations           | 63          |\n|    time_elapsed         | 2410        |\n|    total_timesteps      | 1032192     |\n| train/                  |             |\n|    approx_kl            | 0.076289766 |\n|    clip_fraction        | 0.388       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.18       |\n|    explained_variance   | 0.571       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0812     |\n|    n_updates            | 248         |\n|    policy_gradient_loss | -0.051      |\n|    value_loss           | 0.0523      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1040000, episode_reward=-4.60 +/- 7.39\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1040000, episode_reward=-4.60 +/- 7.39\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3759.20 +/- 663.20\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3759.20 +/- 663.20\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.76e+03   |\n|    mean_reward          | -4.6       |\n| time/                   |            |\n|    total_timesteps      | 1040000    |\n| train/                  |            |\n|    approx_kl            | 0.07603753 |\n|    clip_fraction        | 0.382      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.15      |\n|    explained_variance   | 0.574      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.066     |\n|    n_updates            | 252        |\n|    policy_gradient_loss | -0.047     |\n|    value_loss           | 0.0624     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.5e+03  |\n|    ep_rew_mean     | -8.28    |\n| time/              |          |\n|    fps             | 422      |\n|    iterations      | 64       |\n|    time_elapsed    | 2482     |\n|    total_timesteps | 1048576  |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.51e+03    |\n|    ep_rew_mean          | -8.13       |\n| time/                   |             |\n|    fps                  | 423         |\n|    iterations           | 65          |\n|    time_elapsed         | 2513        |\n|    total_timesteps      | 1064960     |\n| train/                  |             |\n|    approx_kl            | 0.080028534 |\n|    clip_fraction        | 0.382       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | 0.586       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0704     |\n|    n_updates            | 256         |\n|    policy_gradient_loss | -0.0476     |\n|    value_loss           | 0.0547      |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 3.53e+03  |\n|    ep_rew_mean          | -7.75     |\n| time/                   |           |\n|    fps                  | 424       |\n|    iterations           | 66        |\n|    time_elapsed         | 2544      |\n|    total_timesteps      | 1081344   |\n| train/                  |           |\n|    approx_kl            | 0.0793896 |\n|    clip_fraction        | 0.383     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.15     |\n|    explained_variance   | 0.57      |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0523   |\n|    n_updates            | 260       |\n|    policy_gradient_loss | -0.0498   |\n|    value_loss           | 0.058     |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.56e+03    |\n|    ep_rew_mean          | -7.42       |\n| time/                   |             |\n|    fps                  | 426         |\n|    iterations           | 67          |\n|    time_elapsed         | 2575        |\n|    total_timesteps      | 1097728     |\n| train/                  |             |\n|    approx_kl            | 0.083683625 |\n|    clip_fraction        | 0.387       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.14       |\n|    explained_variance   | 0.577       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0711     |\n|    n_updates            | 264         |\n|    policy_gradient_loss | -0.0489     |\n|    value_loss           | 0.0566      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.6e+03     |\n|    ep_rew_mean          | -7.23       |\n| time/                   |             |\n|    fps                  | 427         |\n|    iterations           | 68          |\n|    time_elapsed         | 2606        |\n|    total_timesteps      | 1114112     |\n| train/                  |             |\n|    approx_kl            | 0.077817366 |\n|    clip_fraction        | 0.385       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | 0.576       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0773     |\n|    n_updates            | 268         |\n|    policy_gradient_loss | -0.0503     |\n|    value_loss           | 0.0536      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1120000, episode_reward=0.00 +/- 5.93\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1120000, episode_reward=0.00 +/- 5.93\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3861.40 +/- 187.57\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3861.40 +/- 187.57\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.86e+03   |\n|    mean_reward          | 0          |\n| time/                   |            |\n|    total_timesteps      | 1120000    |\n| train/                  |            |\n|    approx_kl            | 0.08843693 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.14      |\n|    explained_variance   | 0.612      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0688    |\n|    n_updates            | 272        |\n|    policy_gradient_loss | -0.0506    |\n|    value_loss           | 0.0569     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.61e+03 |\n|    ep_rew_mean     | -6.83    |\n| time/              |          |\n|    fps             | 421      |\n|    iterations      | 69       |\n|    time_elapsed    | 2679     |\n|    total_timesteps | 1130496  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.62e+03   |\n|    ep_rew_mean          | -6.64      |\n| time/                   |            |\n|    fps                  | 423        |\n|    iterations           | 70         |\n|    time_elapsed         | 2710       |\n|    total_timesteps      | 1146880    |\n| train/                  |            |\n|    approx_kl            | 0.07996707 |\n|    clip_fraction        | 0.383      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.17      |\n|    explained_variance   | 0.564      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0563    |\n|    n_updates            | 276        |\n|    policy_gradient_loss | -0.0495    |\n|    value_loss           | 0.0568     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.63e+03   |\n|    ep_rew_mean          | -6.46      |\n| time/                   |            |\n|    fps                  | 424        |\n|    iterations           | 71         |\n|    time_elapsed         | 2741       |\n|    total_timesteps      | 1163264    |\n| train/                  |            |\n|    approx_kl            | 0.08574912 |\n|    clip_fraction        | 0.397      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.14      |\n|    explained_variance   | 0.573      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0755    |\n|    n_updates            | 280        |\n|    policy_gradient_loss | -0.0511    |\n|    value_loss           | 0.0549     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.65e+03    |\n|    ep_rew_mean          | -6.09       |\n| time/                   |             |\n|    fps                  | 425         |\n|    iterations           | 72          |\n|    time_elapsed         | 2771        |\n|    total_timesteps      | 1179648     |\n| train/                  |             |\n|    approx_kl            | 0.083415516 |\n|    clip_fraction        | 0.388       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | 0.538       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0744     |\n|    n_updates            | 284         |\n|    policy_gradient_loss | -0.0496     |\n|    value_loss           | 0.061       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.64e+03   |\n|    ep_rew_mean          | -6.08      |\n| time/                   |            |\n|    fps                  | 426        |\n|    iterations           | 73         |\n|    time_elapsed         | 2802       |\n|    total_timesteps      | 1196032    |\n| train/                  |            |\n|    approx_kl            | 0.09155286 |\n|    clip_fraction        | 0.392      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.13      |\n|    explained_variance   | 0.583      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0699    |\n|    n_updates            | 288        |\n|    policy_gradient_loss | -0.0504    |\n|    value_loss           | 0.0601     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1200000, episode_reward=2.20 +/- 6.27\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1200000, episode_reward=2.20 +/- 6.27\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3685.60 +/- 568.51\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3685.60 +/- 568.51\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 3.69e+03    |\n|    mean_reward          | 2.2         |\n| time/                   |             |\n|    total_timesteps      | 1200000     |\n| train/                  |             |\n|    approx_kl            | 0.085510954 |\n|    clip_fraction        | 0.383       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.11       |\n|    explained_variance   | 0.564       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0629     |\n|    n_updates            | 292         |\n|    policy_gradient_loss | -0.0479     |\n|    value_loss           | 0.0621      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.65e+03 |\n|    ep_rew_mean     | -5.66    |\n| time/              |          |\n|    fps             | 421      |\n|    iterations      | 74       |\n|    time_elapsed    | 2874     |\n|    total_timesteps | 1212416  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.65e+03   |\n|    ep_rew_mean          | -5.61      |\n| time/                   |            |\n|    fps                  | 422        |\n|    iterations           | 75         |\n|    time_elapsed         | 2905       |\n|    total_timesteps      | 1228800    |\n| train/                  |            |\n|    approx_kl            | 0.09200615 |\n|    clip_fraction        | 0.401      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.12      |\n|    explained_variance   | 0.538      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0823    |\n|    n_updates            | 296        |\n|    policy_gradient_loss | -0.051     |\n|    value_loss           | 0.0596     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.66e+03    |\n|    ep_rew_mean          | -5.41       |\n| time/                   |             |\n|    fps                  | 424         |\n|    iterations           | 76          |\n|    time_elapsed         | 2936        |\n|    total_timesteps      | 1245184     |\n| train/                  |             |\n|    approx_kl            | 0.093739375 |\n|    clip_fraction        | 0.396       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.12       |\n|    explained_variance   | 0.559       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0317     |\n|    n_updates            | 300         |\n|    policy_gradient_loss | -0.0503     |\n|    value_loss           | 0.057       |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.67e+03   |\n|    ep_rew_mean          | -5.08      |\n| time/                   |            |\n|    fps                  | 425        |\n|    iterations           | 77         |\n|    time_elapsed         | 2967       |\n|    total_timesteps      | 1261568    |\n| train/                  |            |\n|    approx_kl            | 0.09414235 |\n|    clip_fraction        | 0.393      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.12      |\n|    explained_variance   | 0.543      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0707    |\n|    n_updates            | 304        |\n|    policy_gradient_loss | -0.0502    |\n|    value_loss           | 0.0584     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.64e+03   |\n|    ep_rew_mean          | -4.98      |\n| time/                   |            |\n|    fps                  | 426        |\n|    iterations           | 78         |\n|    time_elapsed         | 2998       |\n|    total_timesteps      | 1277952    |\n| train/                  |            |\n|    approx_kl            | 0.09583263 |\n|    clip_fraction        | 0.399      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.14      |\n|    explained_variance   | 0.583      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0804    |\n|    n_updates            | 308        |\n|    policy_gradient_loss | -0.0524    |\n|    value_loss           | 0.0601     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1280000, episode_reward=4.60 +/- 3.72\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1280000, episode_reward=4.60 +/- 3.72\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4213.20 +/- 349.30\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4213.20 +/- 349.30\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"-----------------------------------------\n| eval/                   |             |\n|    mean_ep_length       | 4.21e+03    |\n|    mean_reward          | 4.6         |\n| time/                   |             |\n|    total_timesteps      | 1280000     |\n| train/                  |             |\n|    approx_kl            | 0.093883514 |\n|    clip_fraction        | 0.391       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.11       |\n|    explained_variance   | 0.609       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0796     |\n|    n_updates            | 312         |\n|    policy_gradient_loss | -0.048      |\n|    value_loss           | 0.0558      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.65e+03 |\n|    ep_rew_mean     | -4.67    |\n| time/              |          |\n|    fps             | 420      |\n|    iterations      | 79       |\n|    time_elapsed    | 3076     |\n|    total_timesteps | 1294336  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.66e+03   |\n|    ep_rew_mean          | -4.5       |\n| time/                   |            |\n|    fps                  | 421        |\n|    iterations           | 80         |\n|    time_elapsed         | 3107       |\n|    total_timesteps      | 1310720    |\n| train/                  |            |\n|    approx_kl            | 0.09346437 |\n|    clip_fraction        | 0.401      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.12      |\n|    explained_variance   | 0.572      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.1       |\n|    n_updates            | 316        |\n|    policy_gradient_loss | -0.0515    |\n|    value_loss           | 0.0492     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.67e+03   |\n|    ep_rew_mean          | -3.93      |\n| time/                   |            |\n|    fps                  | 422        |\n|    iterations           | 81         |\n|    time_elapsed         | 3138       |\n|    total_timesteps      | 1327104    |\n| train/                  |            |\n|    approx_kl            | 0.09860952 |\n|    clip_fraction        | 0.388      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.599      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.068     |\n|    n_updates            | 320        |\n|    policy_gradient_loss | -0.0498    |\n|    value_loss           | 0.0551     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.71e+03   |\n|    ep_rew_mean          | -3.94      |\n| time/                   |            |\n|    fps                  | 423        |\n|    iterations           | 82         |\n|    time_elapsed         | 3169       |\n|    total_timesteps      | 1343488    |\n| train/                  |            |\n|    approx_kl            | 0.09649306 |\n|    clip_fraction        | 0.394      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.1       |\n|    explained_variance   | 0.552      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0486    |\n|    n_updates            | 324        |\n|    policy_gradient_loss | -0.0516    |\n|    value_loss           | 0.053      |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.72e+03   |\n|    ep_rew_mean          | -3.63      |\n| time/                   |            |\n|    fps                  | 424        |\n|    iterations           | 83         |\n|    time_elapsed         | 3200       |\n|    total_timesteps      | 1359872    |\n| train/                  |            |\n|    approx_kl            | 0.09986133 |\n|    clip_fraction        | 0.389      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.11      |\n|    explained_variance   | 0.54       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0531    |\n|    n_updates            | 328        |\n|    policy_gradient_loss | -0.051     |\n|    value_loss           | 0.0555     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1360000, episode_reward=1.40 +/- 6.41\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1360000, episode_reward=1.40 +/- 6.41\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3871.00 +/- 166.78\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3871.00 +/- 166.78\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.87e+03   |\n|    mean_reward          | 1.4        |\n| time/                   |            |\n|    total_timesteps      | 1360000    |\n| train/                  |            |\n|    approx_kl            | 0.09839423 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.1       |\n|    explained_variance   | 0.551      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0469    |\n|    n_updates            | 332        |\n|    policy_gradient_loss | -0.0506    |\n|    value_loss           | 0.0574     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.73e+03 |\n|    ep_rew_mean     | -3.54    |\n| time/              |          |\n|    fps             | 420      |\n|    iterations      | 84       |\n|    time_elapsed    | 3274     |\n|    total_timesteps | 1376256  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.72e+03   |\n|    ep_rew_mean          | -3.44      |\n| time/                   |            |\n|    fps                  | 421        |\n|    iterations           | 85         |\n|    time_elapsed         | 3305       |\n|    total_timesteps      | 1392640    |\n| train/                  |            |\n|    approx_kl            | 0.09605089 |\n|    clip_fraction        | 0.388      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.1       |\n|    explained_variance   | 0.549      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0612    |\n|    n_updates            | 336        |\n|    policy_gradient_loss | -0.0506    |\n|    value_loss           | 0.0604     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.71e+03    |\n|    ep_rew_mean          | -3.38       |\n| time/                   |             |\n|    fps                  | 422         |\n|    iterations           | 86          |\n|    time_elapsed         | 3336        |\n|    total_timesteps      | 1409024     |\n| train/                  |             |\n|    approx_kl            | 0.096785165 |\n|    clip_fraction        | 0.388       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.611       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0885     |\n|    n_updates            | 340         |\n|    policy_gradient_loss | -0.0497     |\n|    value_loss           | 0.0567      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.73e+03    |\n|    ep_rew_mean          | -3.3        |\n| time/                   |             |\n|    fps                  | 423         |\n|    iterations           | 87          |\n|    time_elapsed         | 3367        |\n|    total_timesteps      | 1425408     |\n| train/                  |             |\n|    approx_kl            | 0.101449326 |\n|    clip_fraction        | 0.392       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | 0.568       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0901     |\n|    n_updates            | 344         |\n|    policy_gradient_loss | -0.0509     |\n|    value_loss           | 0.0591      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1440000, episode_reward=0.00 +/- 3.03\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1440000, episode_reward=0.00 +/- 3.03\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4616.00 +/- 105.69\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4616.00 +/- 105.69\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4.62e+03   |\n|    mean_reward          | 0          |\n| time/                   |            |\n|    total_timesteps      | 1440000    |\n| train/                  |            |\n|    approx_kl            | 0.09808618 |\n|    clip_fraction        | 0.385      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.07      |\n|    explained_variance   | 0.597      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0422    |\n|    n_updates            | 348        |\n|    policy_gradient_loss | -0.0478    |\n|    value_loss           | 0.0568     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.72e+03 |\n|    ep_rew_mean     | -3.44    |\n| time/              |          |\n|    fps             | 418      |\n|    iterations      | 88       |\n|    time_elapsed    | 3449     |\n|    total_timesteps | 1441792  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.7e+03    |\n|    ep_rew_mean          | -3.64      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 89         |\n|    time_elapsed         | 3480       |\n|    total_timesteps      | 1458176    |\n| train/                  |            |\n|    approx_kl            | 0.09894496 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.08      |\n|    explained_variance   | 0.568      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0647    |\n|    n_updates            | 352        |\n|    policy_gradient_loss | -0.0503    |\n|    value_loss           | 0.0591     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.69e+03   |\n|    ep_rew_mean          | -3.77      |\n| time/                   |            |\n|    fps                  | 419        |\n|    iterations           | 90         |\n|    time_elapsed         | 3511       |\n|    total_timesteps      | 1474560    |\n| train/                  |            |\n|    approx_kl            | 0.10036651 |\n|    clip_fraction        | 0.396      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.08      |\n|    explained_variance   | 0.545      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0667    |\n|    n_updates            | 356        |\n|    policy_gradient_loss | -0.0522    |\n|    value_loss           | 0.055      |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.72e+03   |\n|    ep_rew_mean          | -3.54      |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 91         |\n|    time_elapsed         | 3542       |\n|    total_timesteps      | 1490944    |\n| train/                  |            |\n|    approx_kl            | 0.10864601 |\n|    clip_fraction        | 0.398      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.06      |\n|    explained_variance   | 0.587      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0824    |\n|    n_updates            | 360        |\n|    policy_gradient_loss | -0.0528    |\n|    value_loss           | 0.052      |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.74e+03   |\n|    ep_rew_mean          | -3.63      |\n| time/                   |            |\n|    fps                  | 421        |\n|    iterations           | 92         |\n|    time_elapsed         | 3573       |\n|    total_timesteps      | 1507328    |\n| train/                  |            |\n|    approx_kl            | 0.10640672 |\n|    clip_fraction        | 0.399      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.07      |\n|    explained_variance   | 0.608      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0834    |\n|    n_updates            | 364        |\n|    policy_gradient_loss | -0.0502    |\n|    value_loss           | 0.0537     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1520000, episode_reward=5.40 +/- 4.84\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1520000, episode_reward=5.40 +/- 4.84\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4149.00 +/- 740.74\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4149.00 +/- 740.74\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4.15e+03   |\n|    mean_reward          | 5.4        |\n| time/                   |            |\n|    total_timesteps      | 1520000    |\n| train/                  |            |\n|    approx_kl            | 0.10995318 |\n|    clip_fraction        | 0.392      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.05      |\n|    explained_variance   | 0.546      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0798    |\n|    n_updates            | 368        |\n|    policy_gradient_loss | -0.0517    |\n|    value_loss           | 0.056      |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"New best mean reward!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.76e+03 |\n|    ep_rew_mean     | -3.59    |\n| time/              |          |\n|    fps             | 417      |\n|    iterations      | 93       |\n|    time_elapsed    | 3650     |\n|    total_timesteps | 1523712  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.75e+03   |\n|    ep_rew_mean          | -3.48      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 94         |\n|    time_elapsed         | 3680       |\n|    total_timesteps      | 1540096    |\n| train/                  |            |\n|    approx_kl            | 0.11095088 |\n|    clip_fraction        | 0.393      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.07      |\n|    explained_variance   | 0.59       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0717    |\n|    n_updates            | 372        |\n|    policy_gradient_loss | -0.0523    |\n|    value_loss           | 0.0511     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.77e+03   |\n|    ep_rew_mean          | -3.46      |\n| time/                   |            |\n|    fps                  | 419        |\n|    iterations           | 95         |\n|    time_elapsed         | 3711       |\n|    total_timesteps      | 1556480    |\n| train/                  |            |\n|    approx_kl            | 0.11470592 |\n|    clip_fraction        | 0.395      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.03      |\n|    explained_variance   | 0.592      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0553    |\n|    n_updates            | 376        |\n|    policy_gradient_loss | -0.0507    |\n|    value_loss           | 0.0497     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.8e+03     |\n|    ep_rew_mean          | -3.25       |\n| time/                   |             |\n|    fps                  | 420         |\n|    iterations           | 96          |\n|    time_elapsed         | 3741        |\n|    total_timesteps      | 1572864     |\n| train/                  |             |\n|    approx_kl            | 0.101202756 |\n|    clip_fraction        | 0.399       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | 0.615       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0676     |\n|    n_updates            | 380         |\n|    policy_gradient_loss | -0.0504     |\n|    value_loss           | 0.0513      |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.81e+03   |\n|    ep_rew_mean          | -3.19      |\n| time/                   |            |\n|    fps                  | 421        |\n|    iterations           | 97         |\n|    time_elapsed         | 3772       |\n|    total_timesteps      | 1589248    |\n| train/                  |            |\n|    approx_kl            | 0.10569372 |\n|    clip_fraction        | 0.394      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.05      |\n|    explained_variance   | 0.627      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.084     |\n|    n_updates            | 384        |\n|    policy_gradient_loss | -0.0508    |\n|    value_loss           | 0.0512     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1600000, episode_reward=-1.20 +/- 5.00\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1600000, episode_reward=-1.20 +/- 5.00\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 4208.40 +/- 470.72\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 4208.40 +/- 470.72\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 4.21e+03   |\n|    mean_reward          | -1.2       |\n| time/                   |            |\n|    total_timesteps      | 1600000    |\n| train/                  |            |\n|    approx_kl            | 0.10078054 |\n|    clip_fraction        | 0.395      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.06      |\n|    explained_variance   | 0.629      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.057     |\n|    n_updates            | 388        |\n|    policy_gradient_loss | -0.0512    |\n|    value_loss           | 0.0532     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.83e+03 |\n|    ep_rew_mean     | -2.81    |\n| time/              |          |\n|    fps             | 417      |\n|    iterations      | 98       |\n|    time_elapsed    | 3849     |\n|    total_timesteps | 1605632  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.82e+03   |\n|    ep_rew_mean          | -2.69      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 99         |\n|    time_elapsed         | 3880       |\n|    total_timesteps      | 1622016    |\n| train/                  |            |\n|    approx_kl            | 0.10969329 |\n|    clip_fraction        | 0.397      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.04      |\n|    explained_variance   | 0.604      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.068     |\n|    n_updates            | 392        |\n|    policy_gradient_loss | -0.0513    |\n|    value_loss           | 0.0592     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.81e+03    |\n|    ep_rew_mean          | -2.89       |\n| time/                   |             |\n|    fps                  | 418         |\n|    iterations           | 100         |\n|    time_elapsed         | 3911        |\n|    total_timesteps      | 1638400     |\n| train/                  |             |\n|    approx_kl            | 0.110736236 |\n|    clip_fraction        | 0.394       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.547       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0737     |\n|    n_updates            | 396         |\n|    policy_gradient_loss | -0.0521     |\n|    value_loss           | 0.059       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.83e+03    |\n|    ep_rew_mean          | -2.74       |\n| time/                   |             |\n|    fps                  | 419         |\n|    iterations           | 101         |\n|    time_elapsed         | 3941        |\n|    total_timesteps      | 1654784     |\n| train/                  |             |\n|    approx_kl            | 0.110579595 |\n|    clip_fraction        | 0.402       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.03       |\n|    explained_variance   | 0.601       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0856     |\n|    n_updates            | 400         |\n|    policy_gradient_loss | -0.0504     |\n|    value_loss           | 0.0542      |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.82e+03    |\n|    ep_rew_mean          | -2.8        |\n| time/                   |             |\n|    fps                  | 420         |\n|    iterations           | 102         |\n|    time_elapsed         | 3972        |\n|    total_timesteps      | 1671168     |\n| train/                  |             |\n|    approx_kl            | 0.109900035 |\n|    clip_fraction        | 0.394       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.591       |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0558     |\n|    n_updates            | 404         |\n|    policy_gradient_loss | -0.0514     |\n|    value_loss           | 0.0551      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1680000, episode_reward=1.20 +/- 4.26\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1680000, episode_reward=1.20 +/- 4.26\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3804.00 +/- 287.35\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3804.00 +/- 287.35\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.8e+03    |\n|    mean_reward          | 1.2        |\n| time/                   |            |\n|    total_timesteps      | 1680000    |\n| train/                  |            |\n|    approx_kl            | 0.10728255 |\n|    clip_fraction        | 0.398      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.03      |\n|    explained_variance   | 0.561      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0852    |\n|    n_updates            | 408        |\n|    policy_gradient_loss | -0.0509    |\n|    value_loss           | 0.056      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.82e+03 |\n|    ep_rew_mean     | -3.06    |\n| time/              |          |\n|    fps             | 417      |\n|    iterations      | 103      |\n|    time_elapsed    | 4045     |\n|    total_timesteps | 1687552  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.82e+03   |\n|    ep_rew_mean          | -3.32      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 104        |\n|    time_elapsed         | 4076       |\n|    total_timesteps      | 1703936    |\n| train/                  |            |\n|    approx_kl            | 0.10824324 |\n|    clip_fraction        | 0.398      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.04      |\n|    explained_variance   | 0.578      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0536    |\n|    n_updates            | 412        |\n|    policy_gradient_loss | -0.0517    |\n|    value_loss           | 0.0544     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.82e+03   |\n|    ep_rew_mean          | -3.37      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 105        |\n|    time_elapsed         | 4107       |\n|    total_timesteps      | 1720320    |\n| train/                  |            |\n|    approx_kl            | 0.11195864 |\n|    clip_fraction        | 0.394      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.03      |\n|    explained_variance   | 0.603      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0543    |\n|    n_updates            | 416        |\n|    policy_gradient_loss | -0.0514    |\n|    value_loss           | 0.0556     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.82e+03   |\n|    ep_rew_mean          | -3.26      |\n| time/                   |            |\n|    fps                  | 419        |\n|    iterations           | 106        |\n|    time_elapsed         | 4137       |\n|    total_timesteps      | 1736704    |\n| train/                  |            |\n|    approx_kl            | 0.10945052 |\n|    clip_fraction        | 0.395      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.04      |\n|    explained_variance   | 0.606      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.09      |\n|    n_updates            | 420        |\n|    policy_gradient_loss | -0.0519    |\n|    value_loss           | 0.0581     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.85e+03   |\n|    ep_rew_mean          | -3.1       |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 107        |\n|    time_elapsed         | 4168       |\n|    total_timesteps      | 1753088    |\n| train/                  |            |\n|    approx_kl            | 0.11821074 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.02      |\n|    explained_variance   | 0.615      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0566    |\n|    n_updates            | 424        |\n|    policy_gradient_loss | -0.052     |\n|    value_loss           | 0.0534     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1760000, episode_reward=3.80 +/- 8.03\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1760000, episode_reward=3.80 +/- 8.03\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3878.20 +/- 773.75\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3878.20 +/- 773.75\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.88e+03   |\n|    mean_reward          | 3.8        |\n| time/                   |            |\n|    total_timesteps      | 1760000    |\n| train/                  |            |\n|    approx_kl            | 0.11794004 |\n|    clip_fraction        | 0.4        |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.04      |\n|    explained_variance   | 0.572      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0788    |\n|    n_updates            | 428        |\n|    policy_gradient_loss | -0.0516    |\n|    value_loss           | 0.054      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.84e+03 |\n|    ep_rew_mean     | -3.13    |\n| time/              |          |\n|    fps             | 417      |\n|    iterations      | 108      |\n|    time_elapsed    | 4241     |\n|    total_timesteps | 1769472  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.86e+03   |\n|    ep_rew_mean          | -3.11      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 109        |\n|    time_elapsed         | 4272       |\n|    total_timesteps      | 1785856    |\n| train/                  |            |\n|    approx_kl            | 0.11972782 |\n|    clip_fraction        | 0.402      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.01      |\n|    explained_variance   | 0.587      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0762    |\n|    n_updates            | 432        |\n|    policy_gradient_loss | -0.0541    |\n|    value_loss           | 0.0561     |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.86e+03    |\n|    ep_rew_mean          | -3.22       |\n| time/                   |             |\n|    fps                  | 418         |\n|    iterations           | 110         |\n|    time_elapsed         | 4302        |\n|    total_timesteps      | 1802240     |\n| train/                  |             |\n|    approx_kl            | 0.110706106 |\n|    clip_fraction        | 0.397       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.03       |\n|    explained_variance   | 0.56        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.0698     |\n|    n_updates            | 436         |\n|    policy_gradient_loss | -0.0527     |\n|    value_loss           | 0.0607      |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 3.85e+03  |\n|    ep_rew_mean          | -3.04     |\n| time/                   |           |\n|    fps                  | 419       |\n|    iterations           | 111       |\n|    time_elapsed         | 4333      |\n|    total_timesteps      | 1818624   |\n| train/                  |           |\n|    approx_kl            | 0.1196074 |\n|    clip_fraction        | 0.403     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.02     |\n|    explained_variance   | 0.562     |\n|    learning_rate        | 0.00025   |\n|    loss                 | -0.0662   |\n|    n_updates            | 440       |\n|    policy_gradient_loss | -0.0535   |\n|    value_loss           | 0.0576    |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 3.86e+03    |\n|    ep_rew_mean          | -2.75       |\n| time/                   |             |\n|    fps                  | 420         |\n|    iterations           | 112         |\n|    time_elapsed         | 4364        |\n|    total_timesteps      | 1835008     |\n| train/                  |             |\n|    approx_kl            | 0.123447984 |\n|    clip_fraction        | 0.398       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.01       |\n|    explained_variance   | 0.57        |\n|    learning_rate        | 0.00025     |\n|    loss                 | -0.059      |\n|    n_updates            | 444         |\n|    policy_gradient_loss | -0.0522     |\n|    value_loss           | 0.0557      |\n-----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1840000, episode_reward=-1.40 +/- 4.22\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1840000, episode_reward=-1.40 +/- 4.22\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3766.80 +/- 398.50\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3766.80 +/- 398.50\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.77e+03   |\n|    mean_reward          | -1.4       |\n| time/                   |            |\n|    total_timesteps      | 1840000    |\n| train/                  |            |\n|    approx_kl            | 0.11745512 |\n|    clip_fraction        | 0.396      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.01      |\n|    explained_variance   | 0.632      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.102     |\n|    n_updates            | 448        |\n|    policy_gradient_loss | -0.0521    |\n|    value_loss           | 0.052      |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.88e+03 |\n|    ep_rew_mean     | -2.53    |\n| time/              |          |\n|    fps             | 417      |\n|    iterations      | 113      |\n|    time_elapsed    | 4435     |\n|    total_timesteps | 1851392  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.86e+03   |\n|    ep_rew_mean          | -2.33      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 114        |\n|    time_elapsed         | 4465       |\n|    total_timesteps      | 1867776    |\n| train/                  |            |\n|    approx_kl            | 0.11519313 |\n|    clip_fraction        | 0.392      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.02      |\n|    explained_variance   | 0.58       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0689    |\n|    n_updates            | 452        |\n|    policy_gradient_loss | -0.0527    |\n|    value_loss           | 0.0544     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.81e+03   |\n|    ep_rew_mean          | -2.23      |\n| time/                   |            |\n|    fps                  | 419        |\n|    iterations           | 115        |\n|    time_elapsed         | 4495       |\n|    total_timesteps      | 1884160    |\n| train/                  |            |\n|    approx_kl            | 0.12157867 |\n|    clip_fraction        | 0.393      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.989     |\n|    explained_variance   | 0.586      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0628    |\n|    n_updates            | 456        |\n|    policy_gradient_loss | -0.0518    |\n|    value_loss           | 0.0586     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.8e+03    |\n|    ep_rew_mean          | -2.12      |\n| time/                   |            |\n|    fps                  | 419        |\n|    iterations           | 116        |\n|    time_elapsed         | 4526       |\n|    total_timesteps      | 1900544    |\n| train/                  |            |\n|    approx_kl            | 0.11928855 |\n|    clip_fraction        | 0.393      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.985     |\n|    explained_variance   | 0.596      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0743    |\n|    n_updates            | 460        |\n|    policy_gradient_loss | -0.0487    |\n|    value_loss           | 0.0615     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.77e+03   |\n|    ep_rew_mean          | -2.24      |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 117        |\n|    time_elapsed         | 4556       |\n|    total_timesteps      | 1916928    |\n| train/                  |            |\n|    approx_kl            | 0.12131005 |\n|    clip_fraction        | 0.394      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.985     |\n|    explained_variance   | 0.589      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0413    |\n|    n_updates            | 464        |\n|    policy_gradient_loss | -0.0506    |\n|    value_loss           | 0.0566     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=1920000, episode_reward=5.40 +/- 4.96\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1920000, episode_reward=5.40 +/- 4.96\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3668.80 +/- 252.91\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3668.80 +/- 252.91\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.67e+03   |\n|    mean_reward          | 5.4        |\n| time/                   |            |\n|    total_timesteps      | 1920000    |\n| train/                  |            |\n|    approx_kl            | 0.12902647 |\n|    clip_fraction        | 0.395      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.964     |\n|    explained_variance   | 0.593      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0732    |\n|    n_updates            | 468        |\n|    policy_gradient_loss | -0.0505    |\n|    value_loss           | 0.0563     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.76e+03 |\n|    ep_rew_mean     | -2.07    |\n| time/              |          |\n|    fps             | 417      |\n|    iterations      | 118      |\n|    time_elapsed    | 4626     |\n|    total_timesteps | 1933312  |\n---------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.74e+03   |\n|    ep_rew_mean          | -2.15      |\n| time/                   |            |\n|    fps                  | 418        |\n|    iterations           | 119        |\n|    time_elapsed         | 4657       |\n|    total_timesteps      | 1949696    |\n| train/                  |            |\n|    approx_kl            | 0.11937965 |\n|    clip_fraction        | 0.386      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.965     |\n|    explained_variance   | 0.58       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0295    |\n|    n_updates            | 472        |\n|    policy_gradient_loss | -0.0487    |\n|    value_loss           | 0.0593     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.73e+03   |\n|    ep_rew_mean          | -2.23      |\n| time/                   |            |\n|    fps                  | 419        |\n|    iterations           | 120        |\n|    time_elapsed         | 4687       |\n|    total_timesteps      | 1966080    |\n| train/                  |            |\n|    approx_kl            | 0.13134244 |\n|    clip_fraction        | 0.395      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.963     |\n|    explained_variance   | 0.604      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0783    |\n|    n_updates            | 476        |\n|    policy_gradient_loss | -0.0482    |\n|    value_loss           | 0.0641     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.71e+03   |\n|    ep_rew_mean          | -2.49      |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 121        |\n|    time_elapsed         | 4717       |\n|    total_timesteps      | 1982464    |\n| train/                  |            |\n|    approx_kl            | 0.12203725 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.965     |\n|    explained_variance   | 0.61       |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0732    |\n|    n_updates            | 480        |\n|    policy_gradient_loss | -0.0522    |\n|    value_loss           | 0.0588     |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 3.73e+03   |\n|    ep_rew_mean          | -2.27      |\n| time/                   |            |\n|    fps                  | 420        |\n|    iterations           | 122        |\n|    time_elapsed         | 4748       |\n|    total_timesteps      | 1998848    |\n| train/                  |            |\n|    approx_kl            | 0.13584077 |\n|    clip_fraction        | 0.394      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.943     |\n|    explained_variance   | 0.621      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.0798    |\n|    n_updates            | 484        |\n|    policy_gradient_loss | -0.0502    |\n|    value_loss           | 0.0571     |\n----------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Eval num_timesteps=2000000, episode_reward=2.80 +/- 7.11\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=2000000, episode_reward=2.80 +/- 7.11\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Episode length: 3814.00 +/- 467.93\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3814.00 +/- 467.93\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"----------------------------------------\n| eval/                   |            |\n|    mean_ep_length       | 3.81e+03   |\n|    mean_reward          | 2.8        |\n| time/                   |            |\n|    total_timesteps      | 2000000    |\n| train/                  |            |\n|    approx_kl            | 0.11971767 |\n|    clip_fraction        | 0.391      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.99      |\n|    explained_variance   | 0.617      |\n|    learning_rate        | 0.00025    |\n|    loss                 | -0.101     |\n|    n_updates            | 488        |\n|    policy_gradient_loss | -0.0515    |\n|    value_loss           | 0.0603     |\n----------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 3.73e+03 |\n|    ep_rew_mean     | -2.07    |\n| time/              |          |\n|    fps             | 418      |\n|    iterations      | 123      |\n|    time_elapsed    | 4819     |\n|    total_timesteps | 2015232  |\n---------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"\nFinal single-player performance:\nMean reward: 5.20 ± 6.12\nWin rate: 62.4%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"mean_reward, std_reward = evaluate_policy(\n    model,\n    create_single_agent_env(n_envs=1),\n    n_eval_episodes=100,\n    deterministic=True\n)\n\nprint(f\"Evaluation over 100 episodes:\")\nprint(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\nprint(f\"Win rate: {(mean_reward + 21) / 42 * 100:.1f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T03:19:55.620439Z","iopub.execute_input":"2025-12-15T03:19:55.621301Z","iopub.status.idle":"2025-12-15T03:32:47.110768Z","shell.execute_reply.started":"2025-12-15T03:19:55.621267Z","shell.execute_reply":"2025-12-15T03:32:47.109842Z"}},"outputs":[{"name":"stdout","text":"\\Evaluation over 100 episodes:\nMean reward: 5.06 ± 5.08\nWin rate: 62.0%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_eval_results(log_path, title=\"PPO Pong Evaluation\"):\n    data = np.load(os.path.join(log_path, \"evaluations.npz\"))\n    timesteps = data[\"timesteps\"]\n    rewards = data[\"results\"].mean(axis=1)\n\n    plt.figure(figsize=(8, 5))\n    plt.plot(timesteps, rewards, linewidth=2)\n    plt.fill_between(\n        timesteps,\n        rewards - data[\"results\"].std(axis=1),\n        rewards + data[\"results\"].std(axis=1),\n        alpha=0.2,\n    )\n    plt.xlabel(\"Timesteps\")\n    plt.ylabel(\"Mean Reward\")\n    plt.title(title)\n    plt.grid(True)\n    plt.savefig(\"./training_comparison_plot.png\")\n    plt.show()\n\nplot_eval_results(\"./logs/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T03:33:22.971596Z","iopub.execute_input":"2025-12-15T03:33:22.972174Z","iopub.status.idle":"2025-12-15T03:33:23.231233Z","shell.execute_reply.started":"2025-12-15T03:33:22.972150Z","shell.execute_reply":"2025-12-15T03:33:23.230423Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import numpy as np\nimport supersuit as ss\nfrom pettingzoo.atari import pong_v3\nfrom stable_baselines3 import PPO\nimport imageio\nimport warnings\nimport os\nimport random\nimport logging\nimport sys\nimport importlib\n\nwarnings.filterwarnings('ignore')\n\nMODEL_PATH = \"models/best/best_model.zip\" \n\n# Helper function to create the environment (copied from your utils.py/wrappers.py)\ndef make_env(render_mode=\"rgb_array\"):\n    \"\"\"Creates the pre-processed Pong environment.\"\"\"\n    env = pong_v3.env(num_players=2, render_mode=render_mode)\n    # Apply the same SuperSuit wrappers as used in training/tournament setup\n    env = ss.sticky_actions_v0(env, repeat_action_probability=0.25)\n    env = ss.color_reduction_v0(env, mode=\"B\")\n    env = ss.resize_v1(env, x_size=84, y_size=84)\n    env = ss.frame_stack_v1(env, 4, stack_dim=0)\n    env = ss.dtype_v0(env, dtype=np.float32)\n    env = ss.normalize_obs_v0(env, env_min=0, env_max=1)\n    env = ss.reshape_v0(env, (4, 84, 84))\n    \n    # Resetting the environment with seed as done in the professor's setup\n    MAX_INT = int(10e6)\n    seed = random.randint(0, MAX_INT)\n    env.reset(seed=seed)\n    env.action_space(env.possible_agents[0]).seed(seed)\n    \n    return env\n\n# 1. Load Your Model\ntrained_model = PPO.load(MODEL_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T03:05:46.886945Z","iopub.execute_input":"2025-12-15T03:05:46.887233Z","iopub.status.idle":"2025-12-15T03:05:47.187440Z","shell.execute_reply.started":"2025-12-15T03:05:46.887210Z","shell.execute_reply":"2025-12-15T03:05:47.186827Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class RandomAgent:\n    \"\"\"\n    A simple agent that chooses a random action.\n    It takes an observation but ignores it, matching the expected \n    interface for tournament agents (which often come from SB3/RLlib).\n    \"\"\"\n    def __init__(self, action_space):\n        self.action_space = action_space\n\n    def predict(self, observation, deterministic=True):\n        \"\"\"\n        Returns a random action. The 'deterministic' argument is ignored.\n        Returns: (action, None) to match SB3's .predict() signature.\n        \"\"\"\n        # .sample() gets a random action from the discrete action space\n        action = self.action_space.sample()\n        return action, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T03:06:15.318809Z","iopub.execute_input":"2025-12-15T03:06:15.319080Z","iopub.status.idle":"2025-12-15T03:06:15.323581Z","shell.execute_reply.started":"2025-12-15T03:06:15.319057Z","shell.execute_reply":"2025-12-15T03:06:15.322748Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate_agent(ppo_model, opponent_agent, n_episodes=20, video_path='pong_ppo_vs_random.mp4'):\n    \"\"\"\n    Evaluates the PPO model against a specified opponent agent.\n    PPO model plays first_0 (Right), Opponent plays second_0 (Left).\n    \"\"\"\n    env = make_env(render_mode=\"rgb_array\")\n    \n    total_rewards = {'first_0': 0, 'second_0': 0}\n    wins = {'first_0': 0, 'second_0': 0}\n    video_frames = []\n    \n    print(\"\\n--- Starting PPO Agent vs Random Agent Evaluation ---\")\n    print(f\"PPO Agent: Right Paddle ('first_0') | Opponent: Left Paddle ('second_0')\")\n\n    for episode in range(n_episodes):\n        env.reset()\n        episode_rewards = {'first_0': 0, 'second_0': 0}\n        \n        # PettingZoo Agent Iteration Loop\n        for agent in env.agent_iter():\n            observation, reward, termination, truncation, info = env.last()\n            \n            episode_rewards[agent] += reward\n            \n            if termination or truncation:\n                action = None\n            else:\n                if agent == 'first_0':\n                    # RIGHT PLAYER (Trained PPO Model)\n                    action, _ = ppo_model.predict(observation, deterministic=True)\n                elif agent == 'second_0':\n                    # LEFT PLAYER (Random Opponent)\n                    action, _ = opponent_agent.predict(observation, deterministic=True)\n                else:\n                    action = env.action_space(agent).sample() # Fallback random action\n            \n            env.step(action)\n            \n            # Capture frames for video (first episode only)\n            if episode == 0 and len(video_frames) < 1500: # Limit frames\n                frame = env.render()\n                if frame is not None:\n                    video_frames.append(frame)\n\n        # Tally results\n        right_score = episode_rewards['first_0']\n        left_score = episode_rewards['second_0']\n        \n        total_rewards['first_0'] += right_score\n        total_rewards['second_0'] += left_score\n        \n        if right_score > left_score:\n            wins['first_0'] += 1\n        elif left_score > right_score:\n            wins['second_0'] += 1\n\n        print(f\"Episode {episode + 1:02d}: PPO (Right)={right_score:.1f}, Random (Left)={left_score:.1f}\")\n\n    env.close()\n\n    # Report Results\n    print(\"\\n\" + \"=\"*40)\n    print(\"PPO Agent vs Random Agent RESULTS\")\n    print(\"=\"*40)\n    print(f\"Total PPO Agent (Right) wins: {wins['first_0']} / {n_episodes}\")\n    print(f\"Total Random Agent (Left) wins: {wins['second_0']} / {n_episodes}\")\n    print(f\"PPO Agent Win Rate: {(wins['first_0']/n_episodes * 100):.1f}%\")\n    print(f\"Avg PPO Agent Reward: {total_rewards['first_0']/n_episodes:.2f}\")\n    print(\"=\"*40)\n\n    # Save Video\n    if video_frames:\n        imageio.mimsave(video_path, video_frames, fps=30)\n        print(f\"Video saved as '{video_path}'\")\n    else:\n        print(\"No frames captured for video.\")\n        \n    return total_rewards\n\n# --- EXECUTE EVALUATION ---\n# Create an instance of the random opponent\nenv = make_env(render_mode=\"rgb_array\")\nrandom_opponent = RandomAgent(env.action_space(env.possible_agents[0]))\n# Run the evaluation\nevaluate_agent(trained_model, random_opponent, n_episodes=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T03:11:00.289358Z","iopub.execute_input":"2025-12-15T03:11:00.289904Z","iopub.status.idle":"2025-12-15T03:16:06.490092Z","shell.execute_reply.started":"2025-12-15T03:11:00.289876Z","shell.execute_reply":"2025-12-15T03:16:06.489395Z"}},"outputs":[{"name":"stdout","text":"PPO Agent vs Random Agent Evaluation\nPPO Agent: Right Paddle ('first_0') | Opponent: Left Paddle ('second_0')\nEpisode 01: PPO (Right)=-5.0, Random (Left)=5.0\nEpisode 02: PPO (Right)=5.0, Random (Left)=-6.0\nEpisode 03: PPO (Right)=5.0, Random (Left)=-5.0\nEpisode 04: PPO (Right)=5.0, Random (Left)=-9.0\nEpisode 05: PPO (Right)=7.0, Random (Left)=-7.0\nEpisode 06: PPO (Right)=13.0, Random (Left)=-14.0\nEpisode 07: PPO (Right)=3.0, Random (Left)=-3.0\nEpisode 08: PPO (Right)=-15.0, Random (Left)=14.0\nEpisode 09: PPO (Right)=-12.0, Random (Left)=12.0\nEpisode 10: PPO (Right)=13.0, Random (Left)=-14.0\nEpisode 11: PPO (Right)=-10.0, Random (Left)=10.0\nEpisode 12: PPO (Right)=20.0, Random (Left)=-20.0\nEpisode 13: PPO (Right)=5.0, Random (Left)=-7.0\nEpisode 14: PPO (Right)=-17.0, Random (Left)=16.0\nEpisode 15: PPO (Right)=-2.0, Random (Left)=-1.0\nEpisode 16: PPO (Right)=20.0, Random (Left)=-20.0\nEpisode 17: PPO (Right)=11.0, Random (Left)=-11.0\nEpisode 18: PPO (Right)=-15.0, Random (Left)=14.0\nEpisode 19: PPO (Right)=-1.0, Random (Left)=0.0\nEpisode 20: PPO (Right)=-3.0, Random (Left)=2.0\nPPO Agent vs Random Agent RESULTS\nTotal PPO Agent (Right) wins: 9 / 20\nTotal Random Agent (Left) wins: 11 / 20\nPPO Agent Win Rate: 45.0%\nAvg PPO Agent Reward: -2.20\n","output_type":"stream"},{"name":"stderr","text":"IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n","output_type":"stream"},{"name":"stdout","text":"Video saved as 'pong_ppo_vs_random.mp4'\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'first_0': 27, 'second_0': -44}"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Testing the Agent\n\nYour agent will be tested, against other agents, in an environment similar to the following one:\n\n**Notes**:\n- It is important to consider that the agent will have to play on **both sides of the board**. That is, the agent must be able to play on the **right side** (by default in Gymnasium or Gym), but also on the **left side**.\n- You can provide a **single model** to play both sides or, alternatively, you can provide **two models**, one model for each side of the board.","metadata":{}},{"cell_type":"code","source":"import supersuit as ss\nfrom pettingzoo.atari import pong_v3\n\nenv = PongWrapper(pong_v3.env())\n\n# Load the agents\nmodel1 = loaded_model\nmodel2 = loaded_model\n\nrewards = {agent: 0 for agent in env.possible_agents}\n\n# We evaluate here using an AEC environments\nenv.reset(seed=1234)\nenv.action_space(env.possible_agents[0]).seed(123)\n\nfor agent in env.agent_iter():\n    obs, reward, termination, truncation, info = env.last()\n\n    for a in env.agents:\n        rewards[a] += env.rewards[a]\n\n    if termination or truncation:\n        break\n    else:\n        if agent == env.possible_agents[0]:\n            act = model1.predict(obs)\n        else:\n            act = model2.predict(obs)\n    env.step(act)\n\nprint(\"Final rewards:\", rewards)\nenv.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}